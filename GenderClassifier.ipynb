{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenderClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AtMSG7sL9HYG"
      ],
      "authorship_tag": "ABX9TyOPZz/tpjc8FeZBFouOmZZ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kregier/AudioLanguageClassifer/blob/main/GenderClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZbzZU528CFC"
      },
      "source": [
        "# Introduction\n",
        "This notebook reads in audio files, splits the files into 10s segments, adds random noise to the training files, extracts vggish embeddings, and runs the embeddings through a binary gender classifier.\n",
        "\n",
        "This classifier is trained on the entire audio database - speakers from around 200 different languages, reading passages in English.\n",
        "\n",
        "## Goal:\n",
        "Identify the gender of the speaker from an audio file.\n",
        "\n",
        "## Process\n",
        "Split data into train and test sets\n",
        "For **all** audio files, segment into 10s segments.\n",
        "For **training** data, copy segments and add random noise.\n",
        "\n",
        "Load the VGGish model.\n",
        "\n",
        "Create dataset generators to process the files in batches. The data generator runs the segments through the VGGish model and extract the feature embeddings, which are used as input to the classifier model.\n",
        "\n",
        "## Run the model\n",
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk7thhCF9AOH"
      },
      "source": [
        "# Set up the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xa-k5JMcp-T",
        "outputId": "199817c3-35df-489d-b06a-ca00bbcdd65b"
      },
      "source": [
        "# Set up the environment\n",
        "#!pip install pyAudioAnalysis\n",
        "#!pip install hmmlearn\n",
        "#!pip install eyed3\n",
        "#!pip install pydub\n",
        "!pip install soundfile\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "#import librosa.display\n",
        "import soundfile as sf\n",
        "\n",
        "#from pyAudioAnalysis import audioSegmentation as aS\n",
        "\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"All set up!\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n",
            "All set up!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW0o53ahyps3"
      },
      "source": [
        "To run the model on Colab GPU, go to Runtime/ Change runtime type and select GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9wr2_htJx2eu",
        "outputId": "cff9bd70-4571-4f6a-b910-5833fa221f07"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4cJFozydMso",
        "outputId": "56482c1b-708d-41b9-8b73-7c7b60906c69"
      },
      "source": [
        "# Set up the data import using Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt_J-8ftdNUG",
        "outputId": "fd26e645-990e-48ac-ac4e-95823bf17526"
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "\n",
        "# Change working directory\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n",
            "augment  kaggle.json  processed.csv\t   recordings\n",
            "data\t model\t      reading-passage.txt  speakers_all.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROTRUAKB1iUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267bcd6d-70fe-4d8a-f54c-67537622851f"
      },
      "source": [
        "# Import custom functions that I wrote\n",
        "import augment\n",
        "from augment import Augment\n",
        "\n",
        "from imp import reload\n",
        "#reload(augment)\n",
        "#reload(augment.Augment)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Module imported\n",
            "Augment scripts reloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqUiAU8F4Fmq"
      },
      "source": [
        "# Set constants\n",
        "SAMP_RATE = 16000  #Defined in augment package\n",
        "BATCH_SIZE = 32  #Defined in augment package\n",
        "CLF = 'gender'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtMSG7sL9HYG"
      },
      "source": [
        "#  Load the data\n",
        "## Load the metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cKxnjY8RdTqX",
        "outputId": "ad2e463e-6647-44f8-96f1-dccc3f2988d6"
      },
      "source": [
        "meta = pd.read_csv('processed.csv', index_col='speakerid')\n",
        "meta.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>age_onset</th>\n",
              "      <th>birthplace</th>\n",
              "      <th>filename</th>\n",
              "      <th>native_language</th>\n",
              "      <th>sex</th>\n",
              "      <th>country</th>\n",
              "      <th>file_missing?</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speakerid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>virginia, south africa</td>\n",
              "      <td>afrikaans1</td>\n",
              "      <td>afrikaans</td>\n",
              "      <td>female</td>\n",
              "      <td>south africa</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>pretoria, south africa</td>\n",
              "      <td>afrikaans2</td>\n",
              "      <td>afrikaans</td>\n",
              "      <td>male</td>\n",
              "      <td>south africa</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>diekabo, ivory coast</td>\n",
              "      <td>agni1</td>\n",
              "      <td>agni</td>\n",
              "      <td>male</td>\n",
              "      <td>ivory coast</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>prishtina, kosovo</td>\n",
              "      <td>albanian1</td>\n",
              "      <td>albanian</td>\n",
              "      <td>male</td>\n",
              "      <td>kosovo</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>33.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>tirana, albania</td>\n",
              "      <td>albanian2</td>\n",
              "      <td>albanian</td>\n",
              "      <td>male</td>\n",
              "      <td>albania</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            age  age_onset  ...       country file_missing?\n",
              "speakerid                   ...                            \n",
              "1          27.0        9.0  ...  south africa         False\n",
              "2          40.0        5.0  ...  south africa         False\n",
              "3          25.0       15.0  ...   ivory coast         False\n",
              "4          19.0        6.0  ...        kosovo         False\n",
              "5          33.0       15.0  ...       albania         False\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0gDNEAffZr3",
        "outputId": "6d037997-f89b-4262-95b9-7ac3576cbbd4"
      },
      "source": [
        "meta.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2134, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9ON_j6ufccQ",
        "outputId": "56496f8b-6292-4abf-e579-4b95c7a2fd93"
      },
      "source": [
        "meta.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                0\n",
              "age_onset          0\n",
              "birthplace         0\n",
              "filename           0\n",
              "native_language    0\n",
              "sex                0\n",
              "country            0\n",
              "file_missing?      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDOdw5ML7p0R"
      },
      "source": [
        "# Data processing\n",
        "## Split into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWbf-iG-f4Fg"
      },
      "source": [
        "# Split data into training and testing sets for gender analysis\n",
        "data = meta[['filename','sex']]\n",
        "x_train_names, x_test_names, y_train, y_test = train_test_split(\n",
        "    data['filename'], data['sex'], test_size=0.25, random_state=38, \n",
        "    stratify=data['sex'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLFCykeWgYIE",
        "outputId": "bc25f8f5-1a7f-4ab9-9d0d-a6ddc21c74e2"
      },
      "source": [
        "print(\"Number of training files: \", x_train_names.shape)\n",
        "print(\"Number of testing files: \", x_test_names.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (1600,)\n",
            "Number of testing files:  (534,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bqiGQgp43UG"
      },
      "source": [
        "## Segment the audio files into 10s segments\n",
        "This takes a bit of time, but should only need to be done once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMmLG7nmvrNR"
      },
      "source": [
        "# Check if training data has been segmented. If not, segment each audio file.\n",
        "train_file_list = os.listdir('data/gender/train')\n",
        "\n",
        "for i in range(len(x_train_names)):\n",
        "  # get a filename\n",
        "  filename = x_train_names.iloc[i]\n",
        "  # Check to see if the filename has already been segmented\n",
        "  if any(file.startswith(filename) for file in train_file_list):\n",
        "    pass\n",
        "  else: \n",
        "    augment.Augment.segment_audio(x_train_names.iloc[i], y_train.iloc[i], split='train', clf=CLF)\n",
        "    print('{} segmented'.format(filename))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cm0gVfT8BnX"
      },
      "source": [
        "# Check if testing data has been segmented. If not, segment each audio file.\n",
        "test_file_list = os.listdir('data/gender/test')\n",
        "for i in range(len(x_test_names)):\n",
        "  filename = x_test_names.iloc[i]\n",
        "  if any(file.startswith(filename) for file in test_file_list):\n",
        "    pass\n",
        "  else: \n",
        "    augment.Augment.segment_audio(x_test_names.iloc[i], y_test.iloc[i], split='test', clf=CLF)\n",
        "    print('{} segmented'.format(filename))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjCpxCi8zws0",
        "outputId": "71d2f97a-993e-4cb6-b39e-899b5aa4ffed"
      },
      "source": [
        "# Generate a list training filenames + segment index to input to add_noise() function\n",
        "x_train_seg = [x.split('o.wav')[0] for x in os.listdir('data/gender/train') if x.endswith('o.wav')]\n",
        "print(len(x_train_seg))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1XxR0Cspo_3",
        "outputId": "3e16b44b-03f0-43d9-d580-94fafc70fb5d"
      },
      "source": [
        "print(x_train_seg[:BATCH_SIZE])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['russian31.M.0', 'portuguese34.M.0', 'portuguese34.M.1', 'danish3.F.0', 'taiwanese7.F.0', 'taiwanese7.F.1', 'taiwanese7.F.2', 'taiwanese7.F.3', 'swedish17.F.0', 'swedish17.F.1', 'spanish62.F.0', 'spanish62.F.1', 'spanish62.F.2', 'ngemba1.M.0', 'ngemba1.M.1', 'ngemba1.M.2', 'romanian4.F.0', 'romanian4.F.1', 'arabic23.M.0', 'arabic23.M.1', 'bengali13.F.0', 'bengali13.F.1', 'hungarian6.F.0', 'hungarian6.F.1', 'hungarian6.F.2', 'spanish122.F.0', 'spanish122.F.1', 'russian24.F.0', 'russian24.F.1', 'russian24.F.2', 'korean25.F.0', 'korean25.F.1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CP0XPay-E_P",
        "outputId": "747ca51d-56ac-4909-b33b-6a88eb13369f"
      },
      "source": [
        "# Generate a list testing filenames + segment index\n",
        "x_test_seg = [x.split('o.wav')[0] for x in os.listdir('data/gender/test') if x.endswith('o.wav')]\n",
        "print(len(x_test_seg))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5bb6bRr48DW"
      },
      "source": [
        "## Add noise to segments in training set\n",
        "Not necesary for testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF-Y8Cw5-Qw_"
      },
      "source": [
        "# Check if training data has been augmented with noise. If not, add noise to each segment.\n",
        "noise_train_list = os.listdir('data/gender/train')\n",
        "for i in range(len(x_train_seg)):\n",
        "  filename = x_train_seg[i]\n",
        "  if any((file.startswith(filename)& file.endswith('n.wav')) for file in noise_train_list):\n",
        "    pass\n",
        "  else: \n",
        "    augment.Augment.noisy_data(x_train_seg[i], split='train', clf=CLF)\n",
        "    print('{} augmented'.format(filename))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VjqfFBUsNC_",
        "outputId": "3f983924-267a-4a1c-8ab0-ffab5bcb5dd4"
      },
      "source": [
        "# Verify there are equal numbers for original segments and noisy segments.\n",
        "x_train_noise = [x.split('n.wav')[0] for x in os.listdir('data/gender/train') if x.endswith('n.wav')]\n",
        "print(len(x_train_seg) == len(x_train_noise))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHVgrYax8JH6"
      },
      "source": [
        "## Format input lists for generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvKTeG2Y5coZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af234a77-832e-4bd0-ba8b-b97c562dd579"
      },
      "source": [
        "x_train_filenames = os.listdir('data/gender/train')\n",
        "x_train_filepaths = ['data/gender/train/{}'.format(i) for i in x_train_filenames]\n",
        "print(x_train_filepaths[:5])\n",
        "print(len(x_train_filepaths))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data/gender/train/english167.M.0n.wav', 'data/gender/train/english167.M.1n.wav', 'data/gender/train/english66.M.0n.wav', 'data/gender/train/english66.M.1n.wav', 'data/gender/train/hausa6.M.0n.wav']\n",
            "6920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwnbSFto6HE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb21ec2-9858-4fdb-c042-acf284088eab"
      },
      "source": [
        "x_test_filenames = os.listdir('data/gender/test')\n",
        "x_test_filepaths = ['data/gender/test/{}'.format(i) for i in x_test_filenames]\n",
        "#print(x_test_filepaths[:5])\n",
        "print(len(x_test_filepaths))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79KyX8405PAA"
      },
      "source": [
        "## Load VGGish model\n",
        "Generate a dataset to check the funtionality of the generator before applying to the larger dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oMS5_gt5Wjw"
      },
      "source": [
        "# Using a SavedModel from the TFHub in Keras\n",
        "# https://www.tensorflow.org/hub/tf2_saved_model\n",
        "# VGGish model, from https://tfhub.dev/google/vggish/1\n",
        "\n",
        "# Link to the model on TFHub\n",
        "hub_url = 'https://tfhub.dev/google/vggish/1'\n",
        "\n",
        "# Load the model as a Keras model\n",
        "vggish_model = hub.KerasLayer(hub_url)\n",
        "vggish_model.trainable = False"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu1WdPXFfLbX",
        "outputId": "347b92de-0dcb-4750-97f7-5e0a73904ca7"
      },
      "source": [
        "# Run one file through the model to get output shape\n",
        "#import librosa\n",
        "audio, sr = librosa.load(x_train_filepaths[0], SAMP_RATE)\n",
        "sample = vggish_model(audio)\n",
        "print(sample.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0exZz1a9bU5"
      },
      "source": [
        "## Create and test the data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I6lNqnLccZf"
      },
      "source": [
        "def tf_data_generator(file_list, batch_size=32):\n",
        "    \"\"\" Create a dataset generator. \n",
        "    Iterate through a list of filenames and process in batches.\n",
        "    Extract audio features from vggish model.\n",
        "    WARNING: This generator forms an infinite loop, \n",
        "    so you need to specify how long to run the generator \n",
        "    before fitting and evaluating a model.\n",
        "\n",
        "    Arguments:\n",
        "    file_list - list of filenames to iterate\n",
        "    vggish_model  - pass the instantiated model to the function\n",
        "    batch_size - how many files to process at a time\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    while True: #infinite loop\n",
        "        if i*batch_size >= len(file_list):\n",
        "            i=0\n",
        "            np.random.shuffle(file_list)\n",
        "        else:\n",
        "            file_chunk = file_list[i*batch_size:(i+1)*batch_size]\n",
        "            data = []\n",
        "            labels = []\n",
        "            label_classes = tf.constant(['M', 'F'])\n",
        "            for file in file_chunk:\n",
        "                # Read data\n",
        "                audio, sr = librosa.load(file, sr=16000)\n",
        "                # Apply transformations\n",
        "                embed = vggish_model(audio)\n",
        "                data.append(embed)\n",
        "                # Extract labels from filename\n",
        "                bytes_string = file\n",
        "                string_name = str(bytes_string, 'utf-8')\n",
        "                split_str = string_name.split('.')\n",
        "                #print(split_str)\n",
        "                pattern = tf.constant(split_str[1])\n",
        "                #print(pattern)\n",
        "                for j in range(len(label_classes)):\n",
        "                    if re.match(pattern.numpy(), label_classes[j].numpy()):\n",
        "                        labels.append(j)\n",
        "\n",
        "            data = np.asarray(data)\n",
        "            labels = np.asarray(labels)\n",
        "\n",
        "            yield data, labels\n",
        "            i += 1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyvCAY586sCe"
      },
      "source": [
        "dataset_check = tf.data.Dataset.from_generator(tf_data_generator,\n",
        "                                         args = [x_train_filepaths[:2*BATCH_SIZE], BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPTsMyTG62kr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2410ad8a-b61a-4661-cfbb-b8e3079dea25"
      },
      "source": [
        "# Check shape and size of dataset batches\n",
        "for data, labels in dataset_check.take(2):\n",
        "  print(data.shape)\n",
        "  print(labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 10, 128)\n",
            "tf.Tensor(\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 0. 0. 1. 1. 1. 0.], shape=(32,), dtype=float32)\n",
            "(32, 10, 128)\n",
            "tf.Tensor(\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1.], shape=(32,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2ZFvHaj6_kZ"
      },
      "source": [
        "## Generate training, validation and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI4fDRxr6-y7"
      },
      "source": [
        "x_train, x_val = train_test_split(x_train_filepaths, test_size=.25, random_state=38)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2-6WLsx7Q_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "759b15a2-8c85-4f15-f5b2-859a806ca5b0"
      },
      "source": [
        "# Print sizes of data splits\n",
        "print(\"Number of training samples: \", len(x_train))\n",
        "print(\"Number of validation samples: \", len(x_val))\n",
        "print(\"Number of testing samples: \", len(x_test_seg))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples:  5190\n",
            "Number of validation samples:  1730\n",
            "Number of testing samples:  1206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr-IEyoZ7XdK"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [x_train, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) ) \n",
        "validation_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [x_val, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) )\n",
        "test_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [x_test_filepaths, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) ) "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOR2NJG489J-"
      },
      "source": [
        "# Build and compile the classifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBsNAF7S9ApA"
      },
      "source": [
        "# Look for a GPU parameter in the model parameters, add to model.\n",
        "\n",
        "genderClf = tf.keras.models.Sequential([tf.keras.layers.Dense(128, activation = 'relu', input_shape=(10, 128)),\n",
        "                              tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "                              tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "                              tf.keras.layers.AveragePooling1D(pool_size=10, strides=None, padding=\"valid\", data_format=\"channels_last\")\n",
        "                              ])\n",
        "genderClf.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "967Oz0Ec9HaA"
      },
      "source": [
        "# Add early stopping to train classifier model; default is 10 epochs\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_monitor = EarlyStopping(patience=2)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkSjY9f8f6EH"
      },
      "source": [
        "# Add model checkpoints, in case training times out on the GPU\n",
        "ckpt_path = 'model/gender/genderClf_3layer.ckpt'\n",
        "ckpt_dir = os.path.dirname(ckpt_path)\n",
        "\n",
        "ckpt = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path, save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "QqxXmAXH2CvQ",
        "outputId": "28b8af7c-9cc5-4fcd-d7fe-268ab9872922"
      },
      "source": [
        "# Load model weights from the most recent checkpoint\n",
        "latest = tf.train.latest_checkpoint(ckpt_dir)\n",
        "genderClf.load_weights(latest)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-3e9daa44b47c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load model weights from the most recent checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlatest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgenderClf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2180\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2182\u001b[0;31m       \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2183\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m         raise NotImplementedError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1318\u001b[0m         options=options)\n\u001b[1;32m   1319\u001b[0m     base.CheckpointPosition(\n\u001b[0;32m-> 1320\u001b[0;31m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[0m\u001b[1;32m   1321\u001b[0m     load_status = CheckpointLoadStatus(\n\u001b[1;32m   1322\u001b[0m         \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[0;34m(self, checkpoint_position)\u001b[0m\n\u001b[1;32m    912\u001b[0m     restore_ops.extend(\n\u001b[1;32m    913\u001b[0m         current_position.checkpoint.restore_saveables(\n\u001b[0;32m--> 914\u001b[0;31m             tensor_saveables, python_saveables))\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[0;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[1;32m    295\u001b[0m              \"expecting %s\") % (tensor_saveables.keys(), validated_names))\n\u001b[1;32m    296\u001b[0m       new_restore_ops = functional_saver.MultiDeviceSaver(\n\u001b[0;32m--> 297\u001b[0;31m           validated_saveables).restore(self.save_path_tensor, self.options)\n\u001b[0m\u001b[1;32m    298\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    338\u001b[0m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_function_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_restore_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_device_savers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m           \u001b[0mrestore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    109\u001b[0m                                           structured_restored_tensors):\n\u001b[1;32m    110\u001b[0m       restore_ops[saveable.name] = saveable.restore(\n\u001b[0;32m--> 111\u001b[0;31m           restored_tensors, restored_shapes=None)\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[1;32m    125\u001b[0m       \u001b[0mrestored_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m       return resource_variable_ops.shape_safe_assign_variable_handle(\n\u001b[0;32m--> 127\u001b[0;31m           self.handle_op, self._var_shape, restored_tensor)\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mshape_safe_assign_variable_handle\u001b[0;34m(handle, shape, value, name)\u001b[0m\n\u001b[1;32m    309\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0mvalue_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m   \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m   return gen_resource_variable_ops.assign_variable_op(handle,\n\u001b[1;32m    313\u001b[0m                                                       \u001b[0mvalue_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \"\"\"\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shapes (64,) and (1,) are incompatible"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_gicYd09NOd"
      },
      "source": [
        "**Important:**\n",
        "\n",
        "Before fitting model, specify the number of epochs and stept to fit, to avoid infinite looping of the generators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYz6G6YP9MvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59bf2499-c540-4eaf-b568-b6a9598884ee"
      },
      "source": [
        "# Calculate how many dataset batches to generate, since generator is infinite\n",
        "steps_per_epoch = np.int(np.ceil(len(x_train)/BATCH_SIZE))\n",
        "val_steps = np.int(np.ceil(len(x_val)/BATCH_SIZE))\n",
        "eval_steps = np.int(np.ceil(len(x_test_filepaths)/BATCH_SIZE))\n",
        "\n",
        "print(\"steps_per_epoch = \", steps_per_epoch)\n",
        "print(\"validation_steps = \", val_steps)\n",
        "print(\"evaluation_steps = \", eval_steps)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "steps_per_epoch =  163\n",
            "validation_steps =  55\n",
            "evaluation_steps =  38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-UcLPC-9gcx"
      },
      "source": [
        "# Fit the classifier\n",
        "# Load the saved model from HDFS\n",
        "# new_model = tf.keras.model.load_model('model/gender/genderClassifier.h5')\n",
        "# new_model.summary()\n",
        "\n",
        "if os.path.isdir('model/gender/genderClf_3layer'):\n",
        "  genderClf = tf.keras.models.load_model('model/gender/genderClf_3layer')\n",
        "  history = pd.read_csv('model/gender/genderClf_3layer.history.csv')\n",
        "else:\n",
        "  history = genderClf.fit(train_dataset, \n",
        "                        steps_per_epoch=steps_per_epoch, \n",
        "                        epochs=20,\n",
        "                        validation_data=validation_dataset, \n",
        "                        validation_steps = val_steps,\n",
        "                        callbacks=[early_stopping_monitor, ckpt], \n",
        "                        batch_size=BATCH_SIZE)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_gp30nXjaNu"
      },
      "source": [
        "## Save the trained model for future use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PKWV9P36nKO",
        "outputId": "ef7c4d38-e792-4035-9381-d23a10ecf008"
      },
      "source": [
        "genderClf.save('model/gender/genderClf_3layer')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/gender/genderClf_3layer/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/gender/genderClf_3layer/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPl_xw78um3C"
      },
      "source": [
        "hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "# save to csv: \n",
        "hist_csv_file = 'model/gender/genderClf_3layer.history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ-ViISq9unG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "219deba6-81a6-4d72-9a74-f0bd77d0092e"
      },
      "source": [
        "genderClf.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10, 128)           16512     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10, 64)            8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10, 1)             65        \n",
            "_________________________________________________________________\n",
            "average_pooling1d (AveragePo (None, 1, 1)              0         \n",
            "=================================================================\n",
            "Total params: 24,833\n",
            "Trainable params: 24,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLnQvJb79wkF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "cfe71f0e-2839-4924-be85-dcd3b1d14937"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-38c894c7c43f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RunVjc0E9ySu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "fb96a0e1-0555-4403-8755-d444c9751001"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nziXtEg692u_"
      },
      "source": [
        "## Evaluate the trained classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLuIzbBN0beD",
        "outputId": "a92bf7b5-3543-4675-d8b8-f13b383d3519"
      },
      "source": [
        "val_loss, val_acc = genderClf.evaluate(validation_dataset, steps=val_steps)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 1149s 21s/step - loss: 0.0515 - accuracy: 0.9902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CuvQGRQ-Bdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690c01c0-6fd3-4548-b770-9c76671b4284"
      },
      "source": [
        "test_loss, test_acc = genderClf.evaluate(test_dataset, steps=eval_steps)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38/38 [==============================] - 746s 20s/step - loss: 0.0788 - accuracy: 0.9768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv0n90pM-OpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "646ff37a-fff9-41ce-d9e5-589e342f5d20"
      },
      "source": [
        "y_pred = genderClf.predict(test_dataset, steps=eval_steps)\n",
        "print(y_pred.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1206, 1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI1TunDE-Y40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9465383-e104-4462-b78b-b77c33b2dbb7"
      },
      "source": [
        "# Probably need to reshape y_pred to format for classification report\n",
        "y_pred = tf.squeeze(y_pred)\n",
        "print(y_pred.shape)\n",
        "print(y_pred[:10])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1206,)\n",
            "tf.Tensor(\n",
            "[6.67009153e-04 4.68287726e-06 1.08570261e-02 9.74181574e-04\n",
            " 2.89576419e-04 1.06606975e-01 1.08457659e-03 1.93000915e-06\n",
            " 4.39342739e-06 9.99995708e-01], shape=(10,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GivRzbiK-q_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fddca98b-b5cf-40e6-e574-71e262b76513"
      },
      "source": [
        "gen_pred_3  = []\n",
        "for i in y_pred:\n",
        "  if i < 0.5:\n",
        "    gen_pred_3.append(0)\n",
        "  else: gen_pred_3.append(1)\n",
        "\n",
        "print(gen_pred_3[:25])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3NRbdwIB8dP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f2cc969-c330-4548-b717-cd2a9cb6b82e"
      },
      "source": [
        "# Get 1D array of labels from test_dataset\n",
        "y_lab = np.concatenate([y for x, y in test_dataset.take(eval_steps)], axis=0)\n",
        "print(len(y_lab))\n",
        "print(y_lab[:25])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1206\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
            " 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7DwygfW_NAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be31d84-6691-4868-8594-d9d706ec8f40"
      },
      "source": [
        "tf.math.confusion_matrix(y_lab, gen_pred_3)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[601,   9],\n",
              "       [ 19, 577]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-gD0xbu96O4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "555eae98-f8d5-4419-8829-57d0a6937bfc"
      },
      "source": [
        "classification_report(y_lab, gen_pred_3)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n         0.0       0.97      0.99      0.98       610\\n         1.0       0.98      0.97      0.98       596\\n\\n    accuracy                           0.98      1206\\n   macro avg       0.98      0.98      0.98      1206\\nweighted avg       0.98      0.98      0.98      1206\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGX1vdI0-ARp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9d5288-7463-45f2-c97d-679a6040ef40"
      },
      "source": [
        "confusion_matrix(y_lab, gen_pred_3)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[601,   9],\n",
              "       [ 19, 577]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT9XULYn0EWF"
      },
      "source": [
        "# Create a run a simpler, two layer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_7tXB580Iqj"
      },
      "source": [
        "genderClf_2layer = tf.keras.models.Sequential([\n",
        "                              tf.keras.layers.Dense(128, activation = 'relu', input_shape=(10, 128)),\n",
        "                              tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "                              tf.keras.layers.AveragePooling1D(pool_size=10, strides=None, padding=\"valid\", data_format=\"channels_last\")\n",
        "                              ])\n",
        "genderClf_2layer.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltrrMn0a00vR"
      },
      "source": [
        "# Add early stopping to train classifier model; default is 10 epochs\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_monitor = EarlyStopping(patience=2)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzqOIzYj01vV"
      },
      "source": [
        "# Add model checkpoints, in case training times out on the GPU\n",
        "ckpt_path = 'model/gender/genderClf_2layer.ckpt'\n",
        "ckpt_dir = os.path.dirname(ckpt_path)\n",
        "\n",
        "ckpt = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path, save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOb9R_Hh1hUE",
        "outputId": "824feba2-66c3-47dc-a847-5968bf7a6bb5"
      },
      "source": [
        "# If a trained model already exists, load it.\n",
        "# If model checkpoints exist, load them.\n",
        "# Else train a new model\n",
        "\n",
        "if os.path.isdir('model/gender/genderClf_2layer'):\n",
        "  genderClf = tf.keras.models.load_model('/model/gender/genderClf_2layer')\n",
        "  hist_2df = pd.read_csv('model/gender/genderClf_2layer.history.csv')\n",
        "else:\n",
        "  if os.path.isfile('model/gender/genderClf_2layer.ckpt'):\n",
        "    # Load model weights from the most recent checkpoint\n",
        "    latest = tf.train.latest_checkpoint(ckpt_dir)\n",
        "    genderClf_2layer.load_weights(latest)\n",
        "  hist_2 = genderClf_2layer.fit(train_dataset, \n",
        "                        steps_per_epoch=steps_per_epoch, \n",
        "                        epochs=5, \n",
        "                        validation_data=validation_dataset, \n",
        "                        validation_steps = val_steps,\n",
        "                        callbacks=[early_stopping_monitor, ckpt], \n",
        "                        batch_size=BATCH_SIZE)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "163/163 [==============================] - 4265s 26s/step - loss: 0.1452 - accuracy: 0.9682 - val_loss: 0.0622 - val_accuracy: 0.9884\n",
            "Epoch 2/5\n",
            "163/163 [==============================] - 2998s 18s/step - loss: 0.0641 - accuracy: 0.9888 - val_loss: 0.0570 - val_accuracy: 0.9890\n",
            "Epoch 3/5\n",
            "163/163 [==============================] - 2803s 17s/step - loss: 0.0615 - accuracy: 0.9888 - val_loss: 0.0544 - val_accuracy: 0.9884\n",
            "Epoch 4/5\n",
            "163/163 [==============================] - 2797s 17s/step - loss: 0.0602 - accuracy: 0.9881 - val_loss: 0.0530 - val_accuracy: 0.9890\n",
            "Epoch 5/5\n",
            "163/163 [==============================] - 2787s 17s/step - loss: 0.0586 - accuracy: 0.9894 - val_loss: 0.0554 - val_accuracy: 0.9879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAsqALzz8j7Q",
        "outputId": "9e422dd4-890f-4396-b74a-ae7ceea482ce"
      },
      "source": [
        "  hist_2 = genderClf_2layer.fit(train_dataset, \n",
        "                        steps_per_epoch=steps_per_epoch, \n",
        "                        epochs=10, \n",
        "                        validation_data=validation_dataset, \n",
        "                        validation_steps = val_steps,\n",
        "                        callbacks=[early_stopping_monitor, ckpt], \n",
        "                        batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "163/163 [==============================] - 2941s 18s/step - loss: 0.0583 - accuracy: 0.9892 - val_loss: 0.0521 - val_accuracy: 0.9902\n",
            "Epoch 2/10\n",
            "163/163 [==============================] - 2802s 17s/step - loss: 0.0576 - accuracy: 0.9892 - val_loss: 0.0518 - val_accuracy: 0.9902\n",
            "Epoch 3/10\n",
            "163/163 [==============================] - 2806s 17s/step - loss: 0.0571 - accuracy: 0.9892 - val_loss: 0.0514 - val_accuracy: 0.9908\n",
            "Epoch 4/10\n",
            "163/163 [==============================] - 2778s 17s/step - loss: 0.0572 - accuracy: 0.9898 - val_loss: 0.0527 - val_accuracy: 0.9890\n",
            "Epoch 5/10\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9890 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN5V6-m62rwW",
        "outputId": "22009c26-1781-42f6-de06-38138379558e"
      },
      "source": [
        "# Save the trained model and model history for use later\n",
        "genderClf_2layer.save('model/gender/genderClf_2layer')\n",
        "\n",
        "hist2_df = pd.DataFrame(hist_2.history) \n",
        "\n",
        "# save to csv: \n",
        "hist_csv_file = 'model/gender/genderClf_2layer.history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist2_df.to_csv(f)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/gender/genderClf_2layer/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/gender/genderClf_2layer/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "gOi74fu22bsY",
        "outputId": "1534b650-22cb-4fda-a4a2-4ecdb97dd63c"
      },
      "source": [
        "hist2_df.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.145186</td>\n",
              "      <td>0.968208</td>\n",
              "      <td>0.062173</td>\n",
              "      <td>0.988439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.064087</td>\n",
              "      <td>0.988825</td>\n",
              "      <td>0.057022</td>\n",
              "      <td>0.989017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.061530</td>\n",
              "      <td>0.988825</td>\n",
              "      <td>0.054381</td>\n",
              "      <td>0.988439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.060174</td>\n",
              "      <td>0.988054</td>\n",
              "      <td>0.053013</td>\n",
              "      <td>0.989017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.058634</td>\n",
              "      <td>0.989403</td>\n",
              "      <td>0.055375</td>\n",
              "      <td>0.987861</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy\n",
              "0  0.145186  0.968208  0.062173      0.988439\n",
              "1  0.064087  0.988825  0.057022      0.989017\n",
              "2  0.061530  0.988825  0.054381      0.988439\n",
              "3  0.060174  0.988054  0.053013      0.989017\n",
              "4  0.058634  0.989403  0.055375      0.987861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "qUkZSoVo3GGm",
        "outputId": "f8963c49-85c5-48a8-f46e-d2a9e1b7ffbe"
      },
      "source": [
        "plt.plot(hist2_df['accuracy'])\n",
        "plt.plot(hist2_df['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "nhKOGPuT3WxR",
        "outputId": "da6a80e5-7cd2-44fa-ed63-2a9308a449d3"
      },
      "source": [
        "plt.plot(hist2_df['loss'])\n",
        "plt.plot(hist2_df['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne6dxuAC3ut7"
      },
      "source": [
        "## Evaluate the 2 layer classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzE2Jvbd3uA5",
        "outputId": "73c0f0a6-d5a5-4216-9746-f7bb05aff007"
      },
      "source": [
        "val_loss, val_acc = genderClf_2layer.evaluate(validation_dataset, steps=val_steps)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 690s 13s/step - loss: 0.0554 - accuracy: 0.9879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPqnY7AY3x_V",
        "outputId": "c628edb4-2120-4b31-8456-fa4058a0fb99"
      },
      "source": [
        "test_loss, test_acc = genderClf_2layer.evaluate(test_dataset, steps=eval_steps)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38/38 [==============================] - 712s 19s/step - loss: 0.0808 - accuracy: 0.9776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdyilK0U4Acg",
        "outputId": "9b07599c-b693-46df-bea3-25bfb503b8b5"
      },
      "source": [
        "y_pred_2 = genderClf_2layer.predict(test_dataset, steps=eval_steps)\n",
        "print(y_pred_2.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1206, 1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRvQsAnR4KO4",
        "outputId": "8aff57f6-5037-4514-a069-4072ecc21572"
      },
      "source": [
        "gen_pred_2  = []\n",
        "for i in y_pred_2:\n",
        "  if i < 0.5:\n",
        "    gen_pred_2.append(0)\n",
        "  else: gen_pred_2.append(1)\n",
        "\n",
        "print(gen_pred_2)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTAtRAPO66H2",
        "outputId": "4166f35d-6a93-46f8-e0db-0fa11daa6dc2"
      },
      "source": [
        "tf.math.confusion_matrix(y_lab, gen_pred_2)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[603,   7],\n",
              "       [ 20, 576]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    }
  ]
}