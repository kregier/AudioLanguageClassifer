{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenderClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQqZbUL/z4iwRsA7mNXwKz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kregier/AudioLanguageClassifer/blob/main/GenderClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4PrfB_OcusN"
      },
      "source": [
        "Identify the gender of the speaker from an audio file.\n",
        "\n",
        "Split data into train and test sets\n",
        "For **all** audio files, segment into 10s segments.\n",
        "For **training** data, copy segments and add random noise.\n",
        "\n",
        "Load the VGGish model.\n",
        "\n",
        "Create dataset generators to process the files in batches. The data generator runs the segments through the VGGish model and extract the feature embeddings, which are used as input to the classifier model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xa-k5JMcp-T",
        "outputId": "0cf7c004-04c7-4ebd-9439-f6609a7d72bf"
      },
      "source": [
        "# Set up the environment\n",
        "#!pip install pyAudioAnalysis\n",
        "#!pip install hmmlearn\n",
        "#!pip install eyed3\n",
        "#!pip install pydub\n",
        "!pip install soundfile\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "#import librosa.display\n",
        "import soundfile as sf\n",
        "\n",
        "#from pyAudioAnalysis import audioSegmentation as aS\n",
        "\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"All set up!\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n",
            "All set up!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4cJFozydMso",
        "outputId": "f29d9906-1279-4343-f043-812960276959"
      },
      "source": [
        "# Set up the data import using Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt_J-8ftdNUG",
        "outputId": "578f997b-c171-48bf-a1d9-ea5bab68f938"
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "\n",
        "# Change working directory\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n",
            "augment  kaggle.json\treading-passage.txt  speakers_all.csv\n",
            "data\t processed.csv\trecordings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROTRUAKB1iUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d961d2-31ee-49d1-93a9-96474539bc97"
      },
      "source": [
        "# Import custom functions that I wrote\n",
        "import augment\n",
        "from augment import Augment\n",
        "\n",
        "from imp import reload\n",
        "#reload(augment)\n",
        "#reload(augment.Augment)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Module imported\n",
            "Augment scripts reloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqUiAU8F4Fmq"
      },
      "source": [
        "# Set constants\n",
        "SAMP_RATE = 16000  #Defined in augment package\n",
        "BATCH_SIZE = 32  #Defined in augment package\n",
        "CLF = 'gender'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "cKxnjY8RdTqX",
        "outputId": "fef8fa64-80f7-4b33-ff60-e25ccb0efe63"
      },
      "source": [
        "meta = pd.read_csv('processed.csv', index_col='speakerid')\n",
        "meta.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>age_onset</th>\n",
              "      <th>birthplace</th>\n",
              "      <th>filename</th>\n",
              "      <th>native_language</th>\n",
              "      <th>sex</th>\n",
              "      <th>country</th>\n",
              "      <th>file_missing?</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speakerid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>virginia, south africa</td>\n",
              "      <td>afrikaans1</td>\n",
              "      <td>afrikaans</td>\n",
              "      <td>female</td>\n",
              "      <td>south africa</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>pretoria, south africa</td>\n",
              "      <td>afrikaans2</td>\n",
              "      <td>afrikaans</td>\n",
              "      <td>male</td>\n",
              "      <td>south africa</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>diekabo, ivory coast</td>\n",
              "      <td>agni1</td>\n",
              "      <td>agni</td>\n",
              "      <td>male</td>\n",
              "      <td>ivory coast</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>prishtina, kosovo</td>\n",
              "      <td>albanian1</td>\n",
              "      <td>albanian</td>\n",
              "      <td>male</td>\n",
              "      <td>kosovo</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>33.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>tirana, albania</td>\n",
              "      <td>albanian2</td>\n",
              "      <td>albanian</td>\n",
              "      <td>male</td>\n",
              "      <td>albania</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            age  age_onset  ...       country file_missing?\n",
              "speakerid                   ...                            \n",
              "1          27.0        9.0  ...  south africa         False\n",
              "2          40.0        5.0  ...  south africa         False\n",
              "3          25.0       15.0  ...   ivory coast         False\n",
              "4          19.0        6.0  ...        kosovo         False\n",
              "5          33.0       15.0  ...       albania         False\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0gDNEAffZr3",
        "outputId": "58193b1a-0337-4f3f-a5f9-67303771ef1b"
      },
      "source": [
        "meta.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2134, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9ON_j6ufccQ",
        "outputId": "90f684b9-9dcd-41b7-a81f-15690475501b"
      },
      "source": [
        "meta.isnull().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                0\n",
              "age_onset          0\n",
              "birthplace         0\n",
              "filename           0\n",
              "native_language    0\n",
              "sex                0\n",
              "country            0\n",
              "file_missing?      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDOdw5ML7p0R"
      },
      "source": [
        "# Data processing\n",
        "## Split into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWbf-iG-f4Fg"
      },
      "source": [
        "# Split data into training and testing sets for gender analysis\n",
        "data = meta[['filename','sex']]\n",
        "x_train_names, x_test_names, y_train, y_test = train_test_split(\n",
        "    data['filename'], data['sex'], test_size=0.25, random_state=38, \n",
        "    stratify=data['sex'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLFCykeWgYIE",
        "outputId": "caf61fd8-cc4b-4e3c-ab71-2c882dc7558c"
      },
      "source": [
        "print(\"Number of training files: \", x_train_names.shape)\n",
        "print(\"Number of testing files: \", x_test_names.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (1600,)\n",
            "Number of testing files:  (534,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bqiGQgp43UG"
      },
      "source": [
        "## Segment the audio files into 10s segments\n",
        "This takes a bit of time, but should only need to be done once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMmLG7nmvrNR"
      },
      "source": [
        "# Check if training data has been segmented. If not, segment each audio file.\n",
        "train_file_list = os.listdir('data/gender/train')\n",
        "\n",
        "for i in range(len(x_train_names)):\n",
        "  # get a filename\n",
        "  filename = x_train_names.iloc[i]\n",
        "  # Check to see if the filename has already been segmented\n",
        "  # if any(file.startswith(filename) for file in os.listdir('data/gender/train')):\n",
        "  if any(file.startswith(filename) for file in train_file_list):\n",
        "    pass\n",
        "  else: \n",
        "    augment.Augment.segment_audio(x_train_names.iloc[i], y_train.iloc[i], split='train', clf=CLF)\n",
        "    print('{} segmented'.format(filename))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cm0gVfT8BnX"
      },
      "source": [
        "# Check if testing data has been segmented. If not, segment each audio file.\n",
        "test_file_list = os.listdir('data/gender/test')\n",
        "for i in range(len(x_test_names)):\n",
        "  filename = x_test_names.iloc[i]\n",
        "  # if any(file.startswith(filename) for file in os.listdir('data/gender/test')):\n",
        "  if any(file.startswith(filename) for file in test_file_list):\n",
        "    pass\n",
        "  else: \n",
        "    augment.Augment.segment_audio(x_test_names.iloc[i], y_test.iloc[i], split='test', clf=CLF)\n",
        "    print('{} segmented'.format(filename))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjCpxCi8zws0",
        "outputId": "ccc58001-7ebc-4cb9-82c6-73aee505d557"
      },
      "source": [
        "# Generate a list training filenames + segment index to input to add_noise() function\n",
        "x_train_seg = [x.split('o.wav')[0] for x in os.listdir('data/gender/train') if x.endswith('o.wav')]\n",
        "print(len(x_train_seg))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1XxR0Cspo_3",
        "outputId": "fe473b45-9f5d-4714-cbd4-2f5687764e2d"
      },
      "source": [
        "print(x_train_seg[:BATCH_SIZE])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['russian31.M.0', 'portuguese34.M.0', 'portuguese34.M.1', 'danish3.F.0', 'taiwanese7.F.0', 'taiwanese7.F.1', 'taiwanese7.F.2', 'taiwanese7.F.3', 'swedish17.F.0', 'swedish17.F.1', 'spanish62.F.0', 'spanish62.F.1', 'spanish62.F.2', 'ngemba1.M.0', 'ngemba1.M.1', 'ngemba1.M.2', 'romanian4.F.0', 'romanian4.F.1', 'arabic23.M.0', 'arabic23.M.1', 'bengali13.F.0', 'bengali13.F.1', 'hungarian6.F.0', 'hungarian6.F.1', 'hungarian6.F.2', 'spanish122.F.0', 'spanish122.F.1', 'russian24.F.0', 'russian24.F.1', 'russian24.F.2', 'korean25.F.0', 'korean25.F.1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CP0XPay-E_P",
        "outputId": "4ec70a95-9798-4578-f6d6-c77872620b43"
      },
      "source": [
        "# Generate a list testing filenames + segment index\n",
        "x_test_seg = [x.split('o.wav')[0] for x in os.listdir('data/gender/test') if x.endswith('o.wav')]\n",
        "print(len(x_test_seg))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5bb6bRr48DW"
      },
      "source": [
        "## Add noise to segments in training set\n",
        "Not necesary for testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF-Y8Cw5-Qw_"
      },
      "source": [
        "# Check if training data has been augmented with noise. If not, add noise to each segment.\n",
        "noise_train_list = os.listdir('data/gender/train')\n",
        "for i in range(len(x_train_seg)):\n",
        "  filename = x_train_seg[i]\n",
        "  # if any((file.startswith(filename)& file.endswith('n.wav')) for file in os.listdir('data/gender/train')):\n",
        "  if any((file.startswith(filename)& file.endswith('n.wav')) for file in noise_train_list):\n",
        "    pass\n",
        "  else: \n",
        "    augment.Augment.noisy_data(x_train_seg[i], split='train', clf=CLF)\n",
        "    print('{} augmented'.format(filename))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VjqfFBUsNC_",
        "outputId": "30835720-6706-4f25-f157-a4850dfeac84"
      },
      "source": [
        "# Verify there are equal numbers for original segments and noisy segments.\n",
        "x_train_noise = [x.split('n.wav')[0] for x in os.listdir('data/gender/train') if x.endswith('n.wav')]\n",
        "print(len(x_train_seg) == len(x_train_noise))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHVgrYax8JH6"
      },
      "source": [
        "## Format input lists for generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvKTeG2Y5coZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ecb2c4-2f28-4ebd-8059-7de599880a17"
      },
      "source": [
        "x_train_filenames = os.listdir('data/gender/train')\n",
        "x_train_temp = [file for file in os.listdir('data/gender/train')if file.endswith('o.wav')]\n",
        "print(x_train_filenames[:BATCH_SIZE])\n",
        "print(x_train_temp[:BATCH_SIZE])\n",
        "\n",
        "x_train_filepaths = ['data/gender/train/{}'.format(i) for i in x_train_filenames]\n",
        "#print(x_train_filepaths[:5])\n",
        "print(len(x_train_filepaths))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['english167.M.0n.wav', 'english167.M.1n.wav', 'english66.M.0n.wav', 'english66.M.1n.wav', 'hausa6.M.0n.wav', 'hausa6.M.1n.wav', 'susu1.M.0n.wav', 'susu1.M.1n.wav', 'german8.M.0n.wav', 'tamil6.F.0n.wav', 'tamil6.F.1n.wav', 'english171.M.0n.wav', 'czech5.F.0n.wav', 'czech5.F.1n.wav', 'czech5.F.2n.wav', 'portuguese5.M.0n.wav', 'portuguese5.M.1n.wav', 'portuguese5.M.2n.wav', 'english275.F.0n.wav', 'english275.F.1n.wav', 'english430.F.0n.wav', 'english430.F.1n.wav', 'english93.F.0n.wav', 'english93.F.1n.wav', 'bengali6.M.0n.wav', 'bengali6.M.1n.wav', 'mandarin62.M.0n.wav', 'mandarin62.M.1n.wav', 'turkish13.F.0n.wav', 'turkish13.F.1n.wav', 'english557.F.0n.wav', 'english326.M.0n.wav']\n",
            "['russian31.M.0o.wav', 'portuguese34.M.0o.wav', 'portuguese34.M.1o.wav', 'danish3.F.0o.wav', 'taiwanese7.F.0o.wav', 'taiwanese7.F.1o.wav', 'taiwanese7.F.2o.wav', 'taiwanese7.F.3o.wav', 'swedish17.F.0o.wav', 'swedish17.F.1o.wav', 'spanish62.F.0o.wav', 'spanish62.F.1o.wav', 'spanish62.F.2o.wav', 'ngemba1.M.0o.wav', 'ngemba1.M.1o.wav', 'ngemba1.M.2o.wav', 'romanian4.F.0o.wav', 'romanian4.F.1o.wav', 'arabic23.M.0o.wav', 'arabic23.M.1o.wav', 'bengali13.F.0o.wav', 'bengali13.F.1o.wav', 'hungarian6.F.0o.wav', 'hungarian6.F.1o.wav', 'hungarian6.F.2o.wav', 'spanish122.F.0o.wav', 'spanish122.F.1o.wav', 'russian24.F.0o.wav', 'russian24.F.1o.wav', 'russian24.F.2o.wav', 'korean25.F.0o.wav', 'korean25.F.1o.wav']\n",
            "6920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwnbSFto6HE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e56aa32-a1b6-47cd-9da4-ed63f5746194"
      },
      "source": [
        "x_test_filenames = os.listdir('data/gender/test')\n",
        "#print(x_test_filenames)\n",
        "\n",
        "x_test_filepaths = ['data/gender/test/{}'.format(i) for i in x_test_filenames]\n",
        "#print(x_test_filepaths[:5])\n",
        "print(len(x_test_filepaths))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79KyX8405PAA"
      },
      "source": [
        "## Load VGGish model\n",
        "Generate a dataset to check the funtionality of the generator before applying to the larger dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oMS5_gt5Wjw"
      },
      "source": [
        "# Using a SavedModel from the TFHub in Keras\n",
        "# https://www.tensorflow.org/hub/tf2_saved_model\n",
        "# VGGish model, from https://tfhub.dev/google/vggish/1\n",
        "\n",
        "# Link to the model on TFHub\n",
        "hub_url = 'https://tfhub.dev/google/vggish/1'\n",
        "\n",
        "# Load the model as a Keras model\n",
        "vggish_model = hub.KerasLayer(hub_url)\n",
        "vggish_model.trainable = False"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu1WdPXFfLbX",
        "outputId": "ae4d8104-04b5-4ae2-c742-1ab917256956"
      },
      "source": [
        "# Run one file through the model to get output shape\n",
        "#import librosa\n",
        "audio, sr = librosa.load(x_train_filepaths[0], SAMP_RATE)\n",
        "sample = vggish_model(audio)\n",
        "print(sample.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I6lNqnLccZf"
      },
      "source": [
        "def tf_data_generator(file_list, batch_size=32):\n",
        "    \"\"\" Create a dataset generator. \n",
        "    Iterate through a list of filenames and process in batches.\n",
        "    Extract audio features from vggish model.\n",
        "    WARNING: This generator forms an infinite loop, \n",
        "    so you need to specify how long to run the generator \n",
        "    before fitting and evaluating a model.\n",
        "\n",
        "    Arguments:\n",
        "    file_list - list of filenames to iterate\n",
        "    vggish_model  - pass the instantiated model to the function\n",
        "    batch_size - how many files to process at a time\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    while True: #infinite loop\n",
        "        if i*batch_size >= len(file_list):\n",
        "            i=0\n",
        "            np.random.shuffle(file_list)\n",
        "        else:\n",
        "            file_chunk = file_list[i*batch_size:(i+1)*batch_size]\n",
        "            data = []\n",
        "            labels = []\n",
        "            label_classes = tf.constant(['M', 'F'])\n",
        "            for file in file_chunk:\n",
        "                # Read data\n",
        "                audio, sr = librosa.load(file, sr=16000)\n",
        "                # Apply transformations\n",
        "                embed = vggish_model(audio)\n",
        "                data.append(embed)\n",
        "                # Extract labels from filename\n",
        "                bytes_string = file\n",
        "                string_name = str(bytes_string, 'utf-8')\n",
        "                split_str = string_name.split('.')\n",
        "                #print(split_str)\n",
        "                pattern = tf.constant(split_str[1])\n",
        "                #print(pattern)\n",
        "                for j in range(len(label_classes)):\n",
        "                    if re.match(pattern.numpy(), label_classes[j].numpy()):\n",
        "                        labels.append(j)\n",
        "\n",
        "            data = np.asarray(data)\n",
        "            labels = np.asarray(labels)\n",
        "\n",
        "            yield data, labels\n",
        "            i += 1"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cRNQDhpaOrV"
      },
      "source": [
        "#reload(augment.TFGenerator)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eIqh0hQpZhl",
        "outputId": "d62a6a16-ce72-47bb-8106-0c1f3d127450"
      },
      "source": [
        "x_train_filepaths[:2*BATCH_SIZE]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/gender/train/english167.M.0n.wav',\n",
              " 'data/gender/train/english167.M.1n.wav',\n",
              " 'data/gender/train/english66.M.0n.wav',\n",
              " 'data/gender/train/english66.M.1n.wav',\n",
              " 'data/gender/train/hausa6.M.0n.wav',\n",
              " 'data/gender/train/hausa6.M.1n.wav',\n",
              " 'data/gender/train/susu1.M.0n.wav',\n",
              " 'data/gender/train/susu1.M.1n.wav',\n",
              " 'data/gender/train/german8.M.0n.wav',\n",
              " 'data/gender/train/tamil6.F.0n.wav',\n",
              " 'data/gender/train/tamil6.F.1n.wav',\n",
              " 'data/gender/train/english171.M.0n.wav',\n",
              " 'data/gender/train/czech5.F.0n.wav',\n",
              " 'data/gender/train/czech5.F.1n.wav',\n",
              " 'data/gender/train/czech5.F.2n.wav',\n",
              " 'data/gender/train/portuguese5.M.0n.wav',\n",
              " 'data/gender/train/portuguese5.M.1n.wav',\n",
              " 'data/gender/train/portuguese5.M.2n.wav',\n",
              " 'data/gender/train/english275.F.0n.wav',\n",
              " 'data/gender/train/english275.F.1n.wav',\n",
              " 'data/gender/train/english430.F.0n.wav',\n",
              " 'data/gender/train/english430.F.1n.wav',\n",
              " 'data/gender/train/english93.F.0n.wav',\n",
              " 'data/gender/train/english93.F.1n.wav',\n",
              " 'data/gender/train/bengali6.M.0n.wav',\n",
              " 'data/gender/train/bengali6.M.1n.wav',\n",
              " 'data/gender/train/mandarin62.M.0n.wav',\n",
              " 'data/gender/train/mandarin62.M.1n.wav',\n",
              " 'data/gender/train/turkish13.F.0n.wav',\n",
              " 'data/gender/train/turkish13.F.1n.wav',\n",
              " 'data/gender/train/english557.F.0n.wav',\n",
              " 'data/gender/train/english326.M.0n.wav',\n",
              " 'data/gender/train/french62.F.0n.wav',\n",
              " 'data/gender/train/french62.F.1n.wav',\n",
              " 'data/gender/train/english474.F.0n.wav',\n",
              " 'data/gender/train/english474.F.1n.wav',\n",
              " 'data/gender/train/english383.F.0n.wav',\n",
              " 'data/gender/train/english383.F.1n.wav',\n",
              " 'data/gender/train/taiwanese4.F.0n.wav',\n",
              " 'data/gender/train/taiwanese4.F.1n.wav',\n",
              " 'data/gender/train/taiwanese4.F.2n.wav',\n",
              " 'data/gender/train/bosnian7.F.0n.wav',\n",
              " 'data/gender/train/bosnian7.F.1n.wav',\n",
              " 'data/gender/train/bosnian7.F.2n.wav',\n",
              " 'data/gender/train/cantonese6.M.0n.wav',\n",
              " 'data/gender/train/cantonese6.M.1n.wav',\n",
              " 'data/gender/train/cantonese6.M.2n.wav',\n",
              " 'data/gender/train/farsi5.M.0n.wav',\n",
              " 'data/gender/train/farsi5.M.1n.wav',\n",
              " 'data/gender/train/farsi5.M.2n.wav',\n",
              " 'data/gender/train/icelandic3.F.0n.wav',\n",
              " 'data/gender/train/icelandic3.F.1n.wav',\n",
              " 'data/gender/train/icelandic3.F.2n.wav',\n",
              " 'data/gender/train/kirghiz1.F.0n.wav',\n",
              " 'data/gender/train/kirghiz1.F.1n.wav',\n",
              " 'data/gender/train/kirghiz1.F.2n.wav',\n",
              " 'data/gender/train/korean44.M.0n.wav',\n",
              " 'data/gender/train/korean44.M.1n.wav',\n",
              " 'data/gender/train/korean44.M.2n.wav',\n",
              " 'data/gender/train/arabic80.M.0n.wav',\n",
              " 'data/gender/train/arabic80.M.1n.wav',\n",
              " 'data/gender/train/arabic80.M.2n.wav',\n",
              " 'data/gender/train/macedonian23.F.0n.wav',\n",
              " 'data/gender/train/macedonian23.F.1n.wav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyvCAY586sCe"
      },
      "source": [
        "#from augment.TFGenerator import tf_data_generator\n",
        "\n",
        "dataset_check = tf.data.Dataset.from_generator(tf_data_generator,\n",
        "                                         args = [x_train_filepaths[:2*BATCH_SIZE], BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) )"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPTsMyTG62kr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddbd3e46-1f2f-44f6-ec9e-24f9fae4d5fb"
      },
      "source": [
        "for data, labels in dataset_check.take(2):\n",
        "  print(data.shape)\n",
        "  print(labels)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 10, 128)\n",
            "tf.Tensor(\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 0. 0. 1. 1. 1. 0.], shape=(32,), dtype=float32)\n",
            "(32, 10, 128)\n",
            "tf.Tensor(\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1.], shape=(32,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2ZFvHaj6_kZ"
      },
      "source": [
        "## Generate training, validation and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI4fDRxr6-y7"
      },
      "source": [
        "x_train, x_val = train_test_split(x_train_filepaths, test_size=.25, random_state=38)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2-6WLsx7Q_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c19787b-134c-48c5-bc2e-f19b69cc0316"
      },
      "source": [
        "# Print sizes of data splits\n",
        "print(\"Number of training samples: \", len(x_train))\n",
        "print(\"Number of validation samples: \", len(x_val))\n",
        "print(\"Number of testing samples: \", len(x_test_seg))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples:  5190\n",
            "Number of validation samples:  1730\n",
            "Number of testing samples:  1206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr-IEyoZ7XdK"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [x_train, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) ) \n",
        "validation_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [x_val, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) )\n",
        "test_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [x_test_filepaths, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) ) "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOR2NJG489J-"
      },
      "source": [
        "# Build and compile the classifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBsNAF7S9ApA"
      },
      "source": [
        "genderClf = tf.keras.models.Sequential([tf.keras.layers.Dense(128, activation = 'relu', input_shape=(10, 128)),\n",
        "                              tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "                              tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "                              tf.keras.layers.AveragePooling1D(pool_size=10, strides=None, padding=\"valid\", data_format=\"channels_last\")\n",
        "                              ])\n",
        "genderClf.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "967Oz0Ec9HaA"
      },
      "source": [
        "# Add early stopping to train classifier model; default is 10 epochs\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_monitor = EarlyStopping(patience=2)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkSjY9f8f6EH"
      },
      "source": [
        "# Add model checkpoints, in case training times out on the GPU\n",
        "ckpt_path = 'model/gender/cp.ckpt'\n",
        "ckpt_dir = os.path.dirname(ckpt_path)\n",
        "\n",
        "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=ckpt_path,\n",
        "    save_weights_only=True) #,\n",
        "#    monitor='val_acc',\n",
        "#    mode='max',\n",
        "#    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_gicYd09NOd"
      },
      "source": [
        "**Important:**\n",
        "\n",
        "Before fitting model, specify the number of epochs and stept to fit, to avoid infinite looping of the generators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYz6G6YP9MvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1545f3bc-8796-4e97-c72a-28a155181c70"
      },
      "source": [
        "# Calculate how many dataset batches to generate, since generator is infinite\n",
        "steps_per_epoch = np.int(np.ceil(len(x_train)/BATCH_SIZE))\n",
        "val_steps = np.int(np.ceil(len(x_val)/BATCH_SIZE))\n",
        "eval_steps = np.int(np.ceil(len(x_test_filepaths)/BATCH_SIZE))\n",
        "\n",
        "print(\"steps_per_epoch = \", steps_per_epoch)\n",
        "print(\"validation_steps = \", val_steps)\n",
        "print(\"evaluation_steps = \", eval_steps)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "steps_per_epoch =  163\n",
            "validation_steps =  55\n",
            "evaluation_steps =  38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zam7234JNHfi",
        "outputId": "e7951268-a57b-4c93-f257-72d0c8319059"
      },
      "source": [
        "for data, labels in train_dataset.take(2):\n",
        "  print(data.shape)\n",
        "  print(labels)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 10, 128)\n",
            "tf.Tensor(\n",
            "[1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 1. 0. 1. 0.], shape=(32,), dtype=float32)\n",
            "(32, 10, 128)\n",
            "tf.Tensor(\n",
            "[1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 1. 0. 1.], shape=(32,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwr3FJ3EO6nZ",
        "outputId": "b3729485-9a62-4d98-8162-2361ab17b7f8"
      },
      "source": [
        "for data, labels in validation_dataset.take(2):\n",
        "  print(data.shape)\n",
        "  print(labels)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 10, 128)\n",
            "tf.Tensor(\n",
            "[0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 1.], shape=(32,), dtype=float32)\n",
            "(32, 10, 128)\n",
            "tf.Tensor(\n",
            "[0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1.\n",
            " 0. 1. 1. 0. 1. 0. 1. 0.], shape=(32,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-UcLPC-9gcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2757fb60-9e97-45dd-8b0c-3fca5f1c451a"
      },
      "source": [
        "# Fit the classifier\n",
        "history = genderClf.fit(train_dataset, \n",
        "                        steps_per_epoch=steps_per_epoch, \n",
        "                        epochs=5, \n",
        "                        validation_data=validation_dataset, \n",
        "                        validation_steps = val_steps,\n",
        "                        callbacks=[early_stopping_monitor, ckpt], \n",
        "                        batch_size=BATCH_SIZE)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "163/163 [==============================] - 6278s 39s/step - loss: 0.1006 - accuracy: 0.9840 - val_loss: 0.0569 - val_accuracy: 0.9867\n",
            "Epoch 2/5\n",
            "163/163 [==============================] - 4430s 27s/step - loss: 0.0611 - accuracy: 0.9873 - val_loss: 0.0526 - val_accuracy: 0.9873\n",
            "Epoch 3/5\n",
            "163/163 [==============================] - 4462s 27s/step - loss: 0.0604 - accuracy: 0.9884 - val_loss: 0.0528 - val_accuracy: 0.9896\n",
            "Epoch 4/5\n",
            "163/163 [==============================] - 4452s 27s/step - loss: 0.0577 - accuracy: 0.9890 - val_loss: 0.0618 - val_accuracy: 0.9867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PKWV9P36nKO",
        "outputId": "66cf9a54-1b5b-4acc-f27c-ff78e5c90d84"
      },
      "source": [
        "genderClf.save('genderClf1')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: genderClf1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: genderClf1/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ-ViISq9unG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39abb4a-cb0a-43b0-c118-0174a86849e9"
      },
      "source": [
        "genderClf.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10, 128)           16512     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10, 64)            8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10, 1)             65        \n",
            "_________________________________________________________________\n",
            "average_pooling1d (AveragePo (None, 1, 1)              0         \n",
            "=================================================================\n",
            "Total params: 24,833\n",
            "Trainable params: 24,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLnQvJb79wkF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "fae9ae06-293f-470e-c054-e0163d03023e"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "#plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RunVjc0E9ySu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1fabbdc4-45c5-4b14-ceb9-da395ca8a2e5"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "#plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nziXtEg692u_"
      },
      "source": [
        "## Evaluate the trained classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CuvQGRQ-Bdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efaf1736-018b-45bb-ae09-39f1e82f2d95"
      },
      "source": [
        "test_loss, test_acc = genderClf.evaluate(test_dataset, steps=eval_steps)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38/38 [==============================] - 1000s 26s/step - loss: 0.0898 - accuracy: 0.9751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv0n90pM-OpD"
      },
      "source": [
        "y_pred = genderClf.predict(test_dataset, steps=eval_steps)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI1TunDE-Y40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c425a60f-f794-4fbc-a03b-d6d2acbe45f1"
      },
      "source": [
        "print(y_pred.shape)\n",
        "# Probably need to reshape to format for classification report\n",
        "#y_pred = y_pred [:, 0, 0]\n",
        "#print(y_pred.shape)\n",
        "#print(y_pred)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1206, 1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GivRzbiK-q_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cdbabb4-bb42-4a66-8d4f-72baaf0f39d8"
      },
      "source": [
        "gen_pred  = []\n",
        "for i in y_pred:\n",
        "  if i < 0.5:\n",
        "    gen_pred.append(0)\n",
        "  else: gen_pred.append(1)\n",
        "\n",
        "print(gen_pred)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3NRbdwIB8dP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "b0da02de-84c2-4220-a71a-2089bf607081"
      },
      "source": [
        "# Get 1D array of labels from test_dataset\n",
        "y_lab = np.concatenate([y for x, y in test_dataset.take[32]], axis=0)\n",
        "print(len(y_lab))\n",
        "print(y_lab[10])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-1c73206c452e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get 1D array of labels from test_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_lab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_lab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_lab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7DwygfW_NAd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "74514e9d-4692-41dc-9cea-d09b3771b485"
      },
      "source": [
        "tf.math.confusion_matrix(y_lab, gen_pred)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-b15a83c47fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_lab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_lab' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-gD0xbu96O4"
      },
      "source": [
        "classification_report(y_lab, gen_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGX1vdI0-ARp"
      },
      "source": [
        "confusion_matrix(y_lab, gen_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_fP2b7FiN8_"
      },
      "source": [
        "# Load model weights from a previous checkpoint\n",
        "# model.load_weights(checkpoint_filepath)\n",
        "\n",
        "# Load model weights from the most recent checkpoint\n",
        "# latest = tf.train.latest_checkpoint(ckpt_dir)\n",
        "# model.load_weights(latest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_gp30nXjaNu"
      },
      "source": [
        "# Save the final model for future use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6reUPaePmJmV",
        "outputId": "fb8f6cce-f80b-4ba3-f361-f4be69d1f418"
      },
      "source": [
        "# Save the model using SavedModel format - default for tf2\n",
        "genderClf.save('model/genderClassifier')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/genderClassifier/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/genderClassifier/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-Jo6TEvDKbs",
        "outputId": "f212f09f-d5f4-42eb-f0d0-144b78cb1f76"
      },
      "source": [
        "# Creates the directory 'model/gender/genderClassifier/'\n",
        "!ls 'model/genderClassifier/'"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/genderClassifier/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/genderClassifier/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "assets\tsaved_model.pb\tvariables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNHJpkkinWCm"
      },
      "source": [
        "# Load the SavedModel\n",
        "# new_model = tf.keras.model.load_model('model/gender/genderClassifier')\n",
        "# new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLGTgiexhQaT"
      },
      "source": [
        "# Save the model - using HDFS\n",
        "# genderClf.save('model/gender/genderClassifier.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFu-pFoEhyoo"
      },
      "source": [
        "# Load the saved model from HDFS\n",
        "# new_model = tf.keras.model.load_model('model/gender/genderClassifier.h5')\n",
        "# new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}