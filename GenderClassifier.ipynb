{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenderClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJmn4Y2+Vznx6qvFvmp+5t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kregier/AudioLanguageClassifer/blob/main/GenderClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4PrfB_OcusN"
      },
      "source": [
        "Identify the gender of the speaker from an audio file.\n",
        "\n",
        "Split data into train and test sets\n",
        "For **all** audio files, segment into 10s segments.\n",
        "For **training** data, copy segments and add random noise.\n",
        "\n",
        "Load the VGGish model.\n",
        "\n",
        "Create dataset generators to process the files in batches. The data generator runs the segments through the VGGish model and extract the feature embeddings, which are used as input to the classifier model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xa-k5JMcp-T",
        "outputId": "1b6a6449-3cee-46c7-8da4-e4c37f3d3b8a"
      },
      "source": [
        "# Set up the environment\n",
        "!pip install pyAudioAnalysis\n",
        "!pip install hmmlearn\n",
        "!pip install eyed3\n",
        "!pip install pydub\n",
        "!pip install soundfile\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "from pyAudioAnalysis import audioSegmentation as aS\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"All set up!\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyAudioAnalysis in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: hmmlearn in /usr/local/lib/python3.6/dist-packages (0.2.4)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn) (0.17.0)\n",
            "Requirement already satisfied: eyed3 in /usr/local/lib/python3.6/dist-packages (0.9.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from eyed3) (0.7)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.6/dist-packages (from eyed3) (1.0.7)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.6/dist-packages (from eyed3) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from deprecation->eyed3) (20.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->deprecation->eyed3) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->deprecation->eyed3) (2.4.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.6/dist-packages (0.24.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "All set up!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4cJFozydMso",
        "outputId": "83aa15d2-9a1b-41e7-df74-47b87ca0b919"
      },
      "source": [
        "# Set up the data import using Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt_J-8ftdNUG",
        "outputId": "32ecffe0-4c8d-4f41-f5a5-8fdf49caa40a"
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "\n",
        "# Change working directory\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n",
            "augment  kaggle.json\treading-passage.txt  speakers_all.csv\n",
            "data\t processed.csv\trecordings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROTRUAKB1iUT"
      },
      "source": [
        "# Import custom functions that I wrote\n",
        "import augment"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqUiAU8F4Fmq"
      },
      "source": [
        "# Set constants\n",
        "#SAMP_RATE = 16000  #Defined in augment package\n",
        "#BATCH_SIZE = 32  #Defined in augment package\n",
        "CLF = 'gender'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "cKxnjY8RdTqX",
        "outputId": "86545708-ddb5-4dd2-ab77-3a0e5db5a348"
      },
      "source": [
        "meta = pd.read_csv('processed.csv', index_col='speakerid')\n",
        "meta.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>age_onset</th>\n",
              "      <th>birthplace</th>\n",
              "      <th>filename</th>\n",
              "      <th>native_language</th>\n",
              "      <th>sex</th>\n",
              "      <th>country</th>\n",
              "      <th>file_missing?</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speakerid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>virginia, south africa</td>\n",
              "      <td>afrikaans1</td>\n",
              "      <td>afrikaans</td>\n",
              "      <td>female</td>\n",
              "      <td>south africa</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>pretoria, south africa</td>\n",
              "      <td>afrikaans2</td>\n",
              "      <td>afrikaans</td>\n",
              "      <td>male</td>\n",
              "      <td>south africa</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>diekabo, ivory coast</td>\n",
              "      <td>agni1</td>\n",
              "      <td>agni</td>\n",
              "      <td>male</td>\n",
              "      <td>ivory coast</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>prishtina, kosovo</td>\n",
              "      <td>albanian1</td>\n",
              "      <td>albanian</td>\n",
              "      <td>male</td>\n",
              "      <td>kosovo</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>33.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>tirana, albania</td>\n",
              "      <td>albanian2</td>\n",
              "      <td>albanian</td>\n",
              "      <td>male</td>\n",
              "      <td>albania</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            age  age_onset  ...       country file_missing?\n",
              "speakerid                   ...                            \n",
              "1          27.0        9.0  ...  south africa         False\n",
              "2          40.0        5.0  ...  south africa         False\n",
              "3          25.0       15.0  ...   ivory coast         False\n",
              "4          19.0        6.0  ...        kosovo         False\n",
              "5          33.0       15.0  ...       albania         False\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0gDNEAffZr3",
        "outputId": "de2c3265-80d0-408c-86a0-ea2fe642bdf7"
      },
      "source": [
        "meta.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2134, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9ON_j6ufccQ",
        "outputId": "de76cd53-5c4b-4156-9f14-bce469033382"
      },
      "source": [
        "meta.isnull().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                0\n",
              "age_onset          0\n",
              "birthplace         0\n",
              "filename           0\n",
              "native_language    0\n",
              "sex                0\n",
              "country            0\n",
              "file_missing?      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDOdw5ML7p0R"
      },
      "source": [
        "# Data processing\n",
        "## Split into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWbf-iG-f4Fg"
      },
      "source": [
        "# Split data into training and testing sets for gender analysis\n",
        "data = meta[['filename','sex']]\n",
        "x_train_names, x_test_names, y_train, y_test = train_test_split(\n",
        "    data['filename'], data['sex'], test_size=0.25, random_state=38, \n",
        "    stratify=data['sex'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLFCykeWgYIE",
        "outputId": "1f0d1cc0-43c7-423d-ccfc-c2558266e896"
      },
      "source": [
        "print(\"Number of training files: \", x_train_names.shape)\n",
        "print(\"Number of testing files: \", x_test_names.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (1600,)\n",
            "Number of testing files:  (534,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bqiGQgp43UG"
      },
      "source": [
        "## Segment the audio files into 10s segments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "xVcgbStM3z7E",
        "outputId": "dc6eb612-258e-48a0-e265-d5c55d75720e"
      },
      "source": [
        "x_train_seg = segment_data(x_train_names, y_train, split='train', clf=CLF)\n",
        "print(len(x_train_seg))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8f3f04eb4ce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train_seg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCLF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_seg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/Kaggle/augment/__init__.py\u001b[0m in \u001b[0;36msegment_data\u001b[0;34m(x_names, y_values, split, clf)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Add gender label to filename for later processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0msex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'female'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}.F'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_names' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpdODDg64qSj"
      },
      "source": [
        "x_test_seg = segment_data(x_test_names, y_test, split='test', clf=CLF)\n",
        "print(len(x_test_seg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5bb6bRr48DW"
      },
      "source": [
        "## Add noise to segments in training set\n",
        "Not necesary for testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC10mapA4_Lp"
      },
      "source": [
        "noisy_data(x_train_seg, split='train', clf=CLF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHVgrYax8JH6"
      },
      "source": [
        "## Format input lists for generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvKTeG2Y5coZ"
      },
      "source": [
        "x_train_filenames = os.listdir('.data/gender/train')\n",
        "print(x_train_filenames[:5])\n",
        "\n",
        "x_train_filepaths = ['./data/gender/train/{}'.format(i) for i in x_train_filenames]\n",
        "print(x_train_filepaths[:5])\n",
        "print(len(x_train_filepaths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwnbSFto6HE8"
      },
      "source": [
        "x_test_filenames = os.listdir('./data/gender/test')\n",
        "print(x_test_filenames)\n",
        "\n",
        "x_test_filepaths = ['./data/gender/test/{}'.format(i) for i in x_test_filenames]\n",
        "print(x_test_filepaths[:5])\n",
        "print(len(x_test_filepaths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79KyX8405PAA"
      },
      "source": [
        "## Load VGGish model\n",
        "Generate a dataset to check the funtionality of the generator before applying to the larger dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oMS5_gt5Wjw"
      },
      "source": [
        "# Using a SavedModel from the TFHub in Keras\n",
        "# https://www.tensorflow.org/hub/tf2_saved_model\n",
        "# VGGish model, from https://tfhub.dev/google/vggish/1\n",
        "\n",
        "# Link to the model on TFHub\n",
        "hub_url = 'https://tfhub.dev/google/vggish/1'\n",
        "\n",
        "# Load the model as a Keras model\n",
        "vggish_model = hub.KerasLayer(hub_url)\n",
        "vggish_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyvCAY586sCe"
      },
      "source": [
        "dataset_check = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [x_train_filepaths[:2*BATCH_SIZE], BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPTsMyTG62kr"
      },
      "source": [
        "for data, labels in dataset_check.take(2):\n",
        "  print(data.shape)\n",
        "  print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2ZFvHaj6_kZ"
      },
      "source": [
        "## Generate training, validation and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI4fDRxr6-y7"
      },
      "source": [
        "x_train, x_val = train_test_split(x_train_filepaths, test_size=.25, random_state=38)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2-6WLsx7Q_z"
      },
      "source": [
        "# Print sizes of data splits\n",
        "print(\"Number of training samples: \", len(x_train))\n",
        "print(\"Number of training samples: \", len(x_val))\n",
        "print(\"Number of training samples: \", len(x_test_seg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr-IEyoZ7XdK"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [x_train, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) ) \n",
        "validation_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [x_val, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) )\n",
        "test_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [x_test_filepaths, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOR2NJG489J-"
      },
      "source": [
        "# Build and compile the classifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBsNAF7S9ApA"
      },
      "source": [
        "genderClf = tf.keras.models.Sequential([tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "                              tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "                              tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "                              tf.keras.layers.AveragePooling1D(pool_size=10, strides=None, padding=\"valid\", data_format=\"channels_last\")\n",
        "                              ])\n",
        "genderClf.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ-ViISq9unG"
      },
      "source": [
        "genderClf.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "967Oz0Ec9HaA"
      },
      "source": [
        "# Add early stopping to train classifier model; default is 10 epochs\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_monitor = EarlyStopping(patience=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_gicYd09NOd"
      },
      "source": [
        "**Important:**\n",
        "\n",
        "Before fitting model, specify the number of epochs and stept to fit, to avoid infinite looping of the generators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYz6G6YP9MvG"
      },
      "source": [
        "# Calculate how many dataset batches to generate, since generator is infinite\n",
        "steps_per_epoch = np.int(np.ceil(len(x_train)/BATCH_SIZE))\n",
        "val_steps = np.int(np.ceil(len(x_val)/BATCH_SIZE))\n",
        "eval_steps = np.int(np.ceil(len(x_test_filepaths)/BATCH_SIZE))\n",
        "\n",
        "print(\"steps_per_epoch = \", steps_per_epoch)\n",
        "print(\"validation_steps = \", val_steps)\n",
        "print(\"steps = \", eval_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-UcLPC-9gcx"
      },
      "source": [
        "# Fit the classifier\n",
        "history = genderClf.fit(train_dataset,\n",
        "                        steps_per_epoch=steps_per_epoch,\n",
        "                        epochs=20,\n",
        "                        validation_data=validation_dataset,\n",
        "                        validation_steps = val_steps,\n",
        "                        callbacks=[early_stopping_monitor], \n",
        "                        batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLnQvJb79wkF"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "#plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RunVjc0E9ySu"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "#plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nziXtEg692u_"
      },
      "source": [
        "## Evaluate the trained classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CuvQGRQ-Bdg"
      },
      "source": [
        "test_loss, test_acc = genderClf.evaluate(test_dataset, steps=eval_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv0n90pM-OpD"
      },
      "source": [
        "y_pred = genderClf.predict(test_dataset, steps=eval_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI1TunDE-Y40"
      },
      "source": [
        "print(y_pred.shape)\n",
        "# Probably need to reshape to format for classification report\n",
        "#y_pred = y_pred [:, 0, 0]\n",
        "#print(y_pred.shape)\n",
        "#print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GivRzbiK-q_8"
      },
      "source": [
        "gen_pred  = []\n",
        "for i in y_pred:\n",
        "  if i < 0.5:\n",
        "    gen_pred.append(0)\n",
        "  else: gen_pred.append(1)\n",
        "\n",
        "print(y_pred_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3NRbdwIB8dP"
      },
      "source": [
        "# Get 1D array of labels from test_dataset\n",
        "y_lab = np.concatenate([y for x, y in x_test_dataset], axis=0)\n",
        "print(len(y_lab))\n",
        "print(y_lab[10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7DwygfW_NAd"
      },
      "source": [
        "tf.math.confusion_matrix(y_lab, gen_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-gD0xbu96O4"
      },
      "source": [
        "classification_report(y_lab, gen_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGX1vdI0-ARp"
      },
      "source": [
        "confusion_matrix(y_lab, gen_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}