{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenderClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9bVws9RDfnjjuURV4Mk3P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kregier/AudioLanguageClassifer/blob/main/GenderClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZbzZU528CFC"
      },
      "source": [
        "# Introduction\n",
        "This notebook reads in audio files, splits the files into 10s segments, adds random noise to the training files, extracts vggish embeddings, and runs the embeddings through a binary gender classifier.\n",
        "\n",
        "This classifier is trained on the entire audio database - speakers from around 200 different languages, reading passages in English.\n",
        "\n",
        "## Goal:\n",
        "Identify the gender of the speaker from an audio file.\n",
        "\n",
        "## Process\n",
        "Split data into train and test sets\n",
        "For **all** audio files, segment into 10s segments.\n",
        "For **training** data, copy segments and add random noise.\n",
        "\n",
        "Load the VGGish model.\n",
        "\n",
        "Create dataset generators to process the files in batches. The data generator runs the segments through the VGGish model and extract the feature embeddings, which are used as input to the classifier model.\n",
        "\n",
        "## Run the model\n",
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk7thhCF9AOH"
      },
      "source": [
        "# Set up the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xa-k5JMcp-T",
        "outputId": "623f8d80-e179-43ff-83b4-6b14ebcf6279"
      },
      "source": [
        "# Set up the environment\n",
        "#!pip install pyAudioAnalysis\n",
        "#!pip install hmmlearn\n",
        "#!pip install eyed3\n",
        "#!pip install pydub\n",
        "!pip install soundfile\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "#import librosa.display\n",
        "import soundfile as sf\n",
        "\n",
        "#from pyAudioAnalysis import audioSegmentation as aS\n",
        "\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"All set up!\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n",
            "All set up!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW0o53ahyps3"
      },
      "source": [
        "To run the model on Colab GPU, go to Runtime/ Change runtime type and select GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9wr2_htJx2eu",
        "outputId": "e9fb0f80-54ab-4070-fe1a-9d2ad1e1726d"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4cJFozydMso",
        "outputId": "c240b916-af1d-4661-e362-122ad620812d"
      },
      "source": [
        "# Set up the data import using Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt_J-8ftdNUG",
        "outputId": "f0310dc5-8759-4e48-fa50-d6128747f24b"
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "\n",
        "# Change working directory\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n",
            "augment     genderClf_3layer  models\t\t   recordings\n",
            "data\t    kaggle.json       processed.csv\t   speakers_all.csv\n",
            "genderClf1  model\t      reading-passage.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROTRUAKB1iUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ffe677b-d8a6-47d4-f375-4a488825387e"
      },
      "source": [
        "# Import custom functions that I wrote\n",
        "import augment\n",
        "from augment import Augment\n",
        "\n",
        "from imp import reload\n",
        "#reload(augment)\n",
        "#reload(augment.Augment)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Module imported\n",
            "Augment scripts reloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqUiAU8F4Fmq"
      },
      "source": [
        "# Set constants\n",
        "SAMP_RATE = 16000  #Defined in augment package\n",
        "BATCH_SIZE = 32  #Defined in augment package\n",
        "CLF = 'gender'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtMSG7sL9HYG"
      },
      "source": [
        "#  Load the data\n",
        "## Load the metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "cKxnjY8RdTqX",
        "outputId": "01f1e892-5e8c-4922-cf0a-eb2b05d26123"
      },
      "source": [
        "meta = pd.read_csv('processed.csv', index_col='speakerid')\n",
        "meta.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>age_onset</th>\n",
              "      <th>birthplace</th>\n",
              "      <th>filename</th>\n",
              "      <th>native_language</th>\n",
              "      <th>sex</th>\n",
              "      <th>country</th>\n",
              "      <th>file_missing?</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speakerid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>virginia, south africa</td>\n",
              "      <td>afrikaans1</td>\n",
              "      <td>afrikaans</td>\n",
              "      <td>female</td>\n",
              "      <td>south africa</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>pretoria, south africa</td>\n",
              "      <td>afrikaans2</td>\n",
              "      <td>afrikaans</td>\n",
              "      <td>male</td>\n",
              "      <td>south africa</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>diekabo, ivory coast</td>\n",
              "      <td>agni1</td>\n",
              "      <td>agni</td>\n",
              "      <td>male</td>\n",
              "      <td>ivory coast</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>prishtina, kosovo</td>\n",
              "      <td>albanian1</td>\n",
              "      <td>albanian</td>\n",
              "      <td>male</td>\n",
              "      <td>kosovo</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>33.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>tirana, albania</td>\n",
              "      <td>albanian2</td>\n",
              "      <td>albanian</td>\n",
              "      <td>male</td>\n",
              "      <td>albania</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            age  age_onset  ...       country file_missing?\n",
              "speakerid                   ...                            \n",
              "1          27.0        9.0  ...  south africa         False\n",
              "2          40.0        5.0  ...  south africa         False\n",
              "3          25.0       15.0  ...   ivory coast         False\n",
              "4          19.0        6.0  ...        kosovo         False\n",
              "5          33.0       15.0  ...       albania         False\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0gDNEAffZr3",
        "outputId": "383f4f41-2332-494d-e9c0-c3f44e8132a0"
      },
      "source": [
        "meta.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2134, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9ON_j6ufccQ",
        "outputId": "a3468627-535e-4be1-cadf-46a429f8ba57"
      },
      "source": [
        "meta.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                0\n",
              "age_onset          0\n",
              "birthplace         0\n",
              "filename           0\n",
              "native_language    0\n",
              "sex                0\n",
              "country            0\n",
              "file_missing?      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDOdw5ML7p0R"
      },
      "source": [
        "# Data processing\n",
        "## Split into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWbf-iG-f4Fg"
      },
      "source": [
        "# Split data into training and testing sets for gender analysis\n",
        "data = meta[['filename','sex']]\n",
        "x_train_names, x_test_names, y_train, y_test = train_test_split(\n",
        "    data['filename'], data['sex'], test_size=0.25, random_state=38, \n",
        "    stratify=data['sex'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLFCykeWgYIE",
        "outputId": "a97b737e-7ce3-4fd3-aef4-9073369e317a"
      },
      "source": [
        "print(\"Number of training files: \", x_train_names.shape)\n",
        "print(\"Number of testing files: \", x_test_names.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (1600,)\n",
            "Number of testing files:  (534,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bqiGQgp43UG"
      },
      "source": [
        "## Segment the audio files into 10s segments\n",
        "This takes a bit of time, but should only need to be done once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMmLG7nmvrNR"
      },
      "source": [
        "# Check if training data has been segmented. If not, segment each audio file.\n",
        "train_file_list = os.listdir('data/gender/train')\n",
        "\n",
        "for i in range(len(x_train_names)):\n",
        "  # get a filename\n",
        "  filename = x_train_names.iloc[i]\n",
        "  # Check to see if the filename has already been segmented\n",
        "  if any(file.startswith(filename) for file in train_file_list):\n",
        "    pass\n",
        "  else: \n",
        "    augment.Augment.segment_audio(x_train_names.iloc[i], y_train.iloc[i], split='train', clf=CLF)\n",
        "    print('{} segmented'.format(filename))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cm0gVfT8BnX"
      },
      "source": [
        "# Check if testing data has been segmented. If not, segment each audio file.\n",
        "test_file_list = os.listdir('data/gender/test')\n",
        "for i in range(len(x_test_names)):\n",
        "  filename = x_test_names.iloc[i]\n",
        "  if any(file.startswith(filename) for file in test_file_list):\n",
        "    pass\n",
        "  else: \n",
        "    augment.Augment.segment_audio(x_test_names.iloc[i], y_test.iloc[i], split='test', clf=CLF)\n",
        "    print('{} segmented'.format(filename))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjCpxCi8zws0",
        "outputId": "7e91780a-890a-4931-ec29-798a506b35a6"
      },
      "source": [
        "# Generate a list training filenames + segment index to input to add_noise() function\n",
        "x_train_seg = [x.split('o.wav')[0] for x in os.listdir('data/gender/train') if x.endswith('o.wav')]\n",
        "print(len(x_train_seg))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1XxR0Cspo_3",
        "outputId": "cf50b5a4-db4d-41f7-e78f-505bbaafbd6e"
      },
      "source": [
        "print(x_train_seg[:BATCH_SIZE])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['russian31.M.0', 'portuguese34.M.0', 'portuguese34.M.1', 'danish3.F.0', 'taiwanese7.F.0', 'taiwanese7.F.1', 'taiwanese7.F.2', 'taiwanese7.F.3', 'swedish17.F.0', 'swedish17.F.1', 'spanish62.F.0', 'spanish62.F.1', 'spanish62.F.2', 'ngemba1.M.0', 'ngemba1.M.1', 'ngemba1.M.2', 'romanian4.F.0', 'romanian4.F.1', 'arabic23.M.0', 'arabic23.M.1', 'bengali13.F.0', 'bengali13.F.1', 'hungarian6.F.0', 'hungarian6.F.1', 'hungarian6.F.2', 'spanish122.F.0', 'spanish122.F.1', 'russian24.F.0', 'russian24.F.1', 'russian24.F.2', 'korean25.F.0', 'korean25.F.1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CP0XPay-E_P",
        "outputId": "2458733f-200d-4d75-ceed-4c25d044c3ed"
      },
      "source": [
        "# Generate a list testing filenames + segment index\n",
        "x_test_seg = [x.split('o.wav')[0] for x in os.listdir('data/gender/test') if x.endswith('o.wav')]\n",
        "print(len(x_test_seg))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5bb6bRr48DW"
      },
      "source": [
        "## Add noise to segments in training set\n",
        "Not necesary for testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF-Y8Cw5-Qw_"
      },
      "source": [
        "# Check if training data has been augmented with noise. If not, add noise to each segment.\n",
        "noise_train_list = os.listdir('data/gender/train')\n",
        "for i in range(len(x_train_seg)):\n",
        "  filename = x_train_seg[i]\n",
        "  if any((file.startswith(filename)& file.endswith('n.wav')) for file in noise_train_list):\n",
        "    pass\n",
        "  else: \n",
        "    augment.Augment.noisy_data(x_train_seg[i], split='train', clf=CLF)\n",
        "    print('{} augmented'.format(filename))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VjqfFBUsNC_",
        "outputId": "a55b7b46-2352-473e-9b03-5c02484add27"
      },
      "source": [
        "# Verify there are equal numbers for original segments and noisy segments.\n",
        "x_train_noise = [x.split('n.wav')[0] for x in os.listdir('data/gender/train') if x.endswith('n.wav')]\n",
        "print(len(x_train_seg) == len(x_train_noise))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHVgrYax8JH6"
      },
      "source": [
        "## Format input lists for generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvKTeG2Y5coZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a1b547-f899-499b-f448-e4e2c1f4da98"
      },
      "source": [
        "x_train_filenames = os.listdir('data/gender/train')\n",
        "x_train_filepaths = ['data/gender/train/{}'.format(i) for i in x_train_filenames]\n",
        "print(x_train_filepaths[:5])\n",
        "print(len(x_train_filepaths))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data/gender/train/english167.M.0n.wav', 'data/gender/train/english167.M.1n.wav', 'data/gender/train/english66.M.0n.wav', 'data/gender/train/english66.M.1n.wav', 'data/gender/train/hausa6.M.0n.wav']\n",
            "6920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwnbSFto6HE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f87b8a1e-e725-413e-b6ee-550b00debd2f"
      },
      "source": [
        "x_test_filenames = os.listdir('data/gender/test')\n",
        "x_test_filepaths = ['data/gender/test/{}'.format(i) for i in x_test_filenames]\n",
        "#print(x_test_filepaths[:5])\n",
        "print(len(x_test_filepaths))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79KyX8405PAA"
      },
      "source": [
        "## Load VGGish model\n",
        "Generate a dataset to check the funtionality of the generator before applying to the larger dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oMS5_gt5Wjw"
      },
      "source": [
        "# Using a SavedModel from the TFHub in Keras\n",
        "# https://www.tensorflow.org/hub/tf2_saved_model\n",
        "# VGGish model, from https://tfhub.dev/google/vggish/1\n",
        "\n",
        "# Link to the model on TFHub\n",
        "hub_url = 'https://tfhub.dev/google/vggish/1'\n",
        "\n",
        "# Load the model as a Keras model\n",
        "vggish_model = hub.KerasLayer(hub_url)\n",
        "vggish_model.trainable = False"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu1WdPXFfLbX",
        "outputId": "390af896-7036-4926-f399-5f315cbaa3b6"
      },
      "source": [
        "# Run one file through the model to get output shape\n",
        "#import librosa\n",
        "audio, sr = librosa.load(x_train_filepaths[0], SAMP_RATE)\n",
        "sample = vggish_model(audio)\n",
        "print(sample.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0exZz1a9bU5"
      },
      "source": [
        "## Create and test the data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I6lNqnLccZf"
      },
      "source": [
        "def tf_data_generator(file_list, batch_size=32):\n",
        "    \"\"\" Create a dataset generator. \n",
        "    Iterate through a list of filenames and process in batches.\n",
        "    Extract audio features from vggish model.\n",
        "    WARNING: This generator forms an infinite loop, \n",
        "    so you need to specify how long to run the generator \n",
        "    before fitting and evaluating a model.\n",
        "\n",
        "    Arguments:\n",
        "    file_list - list of filenames to iterate\n",
        "    vggish_model  - pass the instantiated model to the function\n",
        "    batch_size - how many files to process at a time\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    while True: #infinite loop\n",
        "        if i*batch_size >= len(file_list):\n",
        "            i=0\n",
        "            np.random.shuffle(file_list)\n",
        "        else:\n",
        "            file_chunk = file_list[i*batch_size:(i+1)*batch_size]\n",
        "            data = []\n",
        "            labels = []\n",
        "            label_classes = tf.constant(['M', 'F'])\n",
        "            for file in file_chunk:\n",
        "                # Read data\n",
        "                audio, sr = librosa.load(file, sr=16000)\n",
        "                # Apply transformations\n",
        "                embed = vggish_model(audio)\n",
        "                data.append(embed)\n",
        "                # Extract labels from filename\n",
        "                bytes_string = file\n",
        "                string_name = str(bytes_string, 'utf-8')\n",
        "                split_str = string_name.split('.')\n",
        "                #print(split_str)\n",
        "                pattern = tf.constant(split_str[1])\n",
        "                #print(pattern)\n",
        "                for j in range(len(label_classes)):\n",
        "                    if re.match(pattern.numpy(), label_classes[j].numpy()):\n",
        "                        labels.append(j)\n",
        "\n",
        "            data = np.asarray(data)\n",
        "            labels = np.asarray(labels)\n",
        "\n",
        "            yield data, labels\n",
        "            i += 1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyvCAY586sCe"
      },
      "source": [
        "dataset_check = tf.data.Dataset.from_generator(tf_data_generator,\n",
        "                                         args = [x_train_filepaths[:2*BATCH_SIZE], BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) )"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPTsMyTG62kr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76742133-9c82-443b-c9a9-c9c1fb708604"
      },
      "source": [
        "# Check shape and size of dataset batches\n",
        "for data, labels in dataset_check.take(2):\n",
        "  print(data.shape)\n",
        "  print(labels)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 10, 128)\n",
            "tf.Tensor(\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 0. 0. 1. 1. 1. 0.], shape=(32,), dtype=float32)\n",
            "(32, 10, 128)\n",
            "tf.Tensor(\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1.], shape=(32,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2ZFvHaj6_kZ"
      },
      "source": [
        "## Generate training, validation and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI4fDRxr6-y7"
      },
      "source": [
        "x_train, x_val = train_test_split(x_train_filepaths, test_size=.25, random_state=38)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2-6WLsx7Q_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "436a0979-cce2-44d4-959c-98701efbb470"
      },
      "source": [
        "# Print sizes of data splits\n",
        "print(\"Number of training samples: \", len(x_train))\n",
        "print(\"Number of validation samples: \", len(x_val))\n",
        "print(\"Number of testing samples: \", len(x_test_seg))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples:  5190\n",
            "Number of validation samples:  1730\n",
            "Number of testing samples:  1206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr-IEyoZ7XdK"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [x_train, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) ) \n",
        "validation_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [x_val, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) )\n",
        "test_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [x_test_filepaths, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,)) ) "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOR2NJG489J-"
      },
      "source": [
        "# Build and compile the classifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBsNAF7S9ApA"
      },
      "source": [
        "# Look for a GPU parameter in the model parameters, add to model.\n",
        "\n",
        "genderClf = tf.keras.models.Sequential([tf.keras.layers.Dense(128, activation = 'relu', input_shape=(10, 128)),\n",
        "                              tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "                              tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "                              tf.keras.layers.AveragePooling1D(pool_size=10, strides=None, padding=\"valid\", data_format=\"channels_last\")\n",
        "                              ])\n",
        "genderClf.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy'])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "967Oz0Ec9HaA"
      },
      "source": [
        "# Add early stopping to train classifier model; default is 10 epochs\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_monitor = EarlyStopping(patience=2)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkSjY9f8f6EH"
      },
      "source": [
        "# Add model checkpoints, in case training times out on the GPU\n",
        "ckpt_path = 'model/gender/genderClf_3layer.ckpt'\n",
        "ckpt_dir = os.path.dirname(ckpt_path)\n",
        "\n",
        "ckpt = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path, save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqxXmAXH2CvQ",
        "outputId": "2b441da9-da81-44e3-bdc9-6b71da5e5e83"
      },
      "source": [
        "# Load model weights from the most recent checkpoint\n",
        "latest = tf.train.latest_checkpoint(ckpt_dir)\n",
        "genderClf.load_weights(latest)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd5b7f5d898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_gicYd09NOd"
      },
      "source": [
        "**Important:**\n",
        "\n",
        "Before fitting model, specify the number of epochs and stept to fit, to avoid infinite looping of the generators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYz6G6YP9MvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a15b1e-fa17-467d-f2a7-5b4a97bff26d"
      },
      "source": [
        "# Calculate how many dataset batches to generate, since generator is infinite\n",
        "steps_per_epoch = np.int(np.ceil(len(x_train)/BATCH_SIZE))\n",
        "val_steps = np.int(np.ceil(len(x_val)/BATCH_SIZE))\n",
        "eval_steps = np.int(np.ceil(len(x_test_filepaths)/BATCH_SIZE))\n",
        "\n",
        "print(\"steps_per_epoch = \", steps_per_epoch)\n",
        "print(\"validation_steps = \", val_steps)\n",
        "print(\"evaluation_steps = \", eval_steps)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "steps_per_epoch =  163\n",
            "validation_steps =  55\n",
            "evaluation_steps =  38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-UcLPC-9gcx"
      },
      "source": [
        "# Fit the classifier\n",
        "# Load the saved model from HDFS\n",
        "# new_model = tf.keras.model.load_model('model/gender/genderClassifier.h5')\n",
        "# new_model.summary()\n",
        "\n",
        "if os.path.isdir('model/gender/genderClf_3layer'):\n",
        "  genderClf = tf.keras.models.load_model('/model/gender/genderClf_3layer')\n",
        "  history = pd.read_csv('model/gender/genderClf_3layer.history.csv')\n",
        "else:\n",
        "  history = genderClf.fit(train_dataset, \n",
        "                        steps_per_epoch=steps_per_epoch, \n",
        "                        epochs=5, \n",
        "                        validation_data=validation_dataset, \n",
        "                        validation_steps = val_steps,\n",
        "                        callbacks=[early_stopping_monitor, ckpt], \n",
        "                        batch_size=BATCH_SIZE)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_gp30nXjaNu"
      },
      "source": [
        "## Save the trained model for future use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PKWV9P36nKO",
        "outputId": "ef7c4d38-e792-4035-9381-d23a10ecf008"
      },
      "source": [
        "genderClf.save('model/gender/genderClf_3layer')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/gender/genderClf_3layer/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/gender/genderClf_3layer/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPl_xw78um3C"
      },
      "source": [
        "hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "# save to csv: \n",
        "hist_csv_file = 'model/gender/genderClf_3layer.history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ-ViISq9unG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b957790-859b-4f23-9bec-015d228cef1b"
      },
      "source": [
        "genderClf.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10, 128)           16512     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10, 64)            8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10, 1)             65        \n",
            "_________________________________________________________________\n",
            "average_pooling1d (AveragePo (None, 1, 1)              0         \n",
            "=================================================================\n",
            "Total params: 24,833\n",
            "Trainable params: 24,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLnQvJb79wkF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "cfe71f0e-2839-4924-be85-dcd3b1d14937"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-38c894c7c43f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RunVjc0E9ySu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "fb96a0e1-0555-4403-8755-d444c9751001"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nziXtEg692u_"
      },
      "source": [
        "## Evaluate the trained classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLuIzbBN0beD",
        "outputId": "a92bf7b5-3543-4675-d8b8-f13b383d3519"
      },
      "source": [
        "val_loss, val_acc = genderClf.evaluate(validation_dataset, steps=val_steps)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 1149s 21s/step - loss: 0.0515 - accuracy: 0.9902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CuvQGRQ-Bdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690c01c0-6fd3-4548-b770-9c76671b4284"
      },
      "source": [
        "test_loss, test_acc = genderClf.evaluate(test_dataset, steps=eval_steps)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38/38 [==============================] - 746s 20s/step - loss: 0.0788 - accuracy: 0.9768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv0n90pM-OpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "646ff37a-fff9-41ce-d9e5-589e342f5d20"
      },
      "source": [
        "y_pred = genderClf.predict(test_dataset, steps=eval_steps)\n",
        "print(y_pred.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1206, 1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI1TunDE-Y40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9465383-e104-4462-b78b-b77c33b2dbb7"
      },
      "source": [
        "# Probably need to reshape y_pred to format for classification report\n",
        "y_pred = tf.squeeze(y_pred)\n",
        "print(y_pred.shape)\n",
        "print(y_pred[:10])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1206,)\n",
            "tf.Tensor(\n",
            "[6.67009153e-04 4.68287726e-06 1.08570261e-02 9.74181574e-04\n",
            " 2.89576419e-04 1.06606975e-01 1.08457659e-03 1.93000915e-06\n",
            " 4.39342739e-06 9.99995708e-01], shape=(10,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GivRzbiK-q_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fddca98b-b5cf-40e6-e574-71e262b76513"
      },
      "source": [
        "gen_pred_3  = []\n",
        "for i in y_pred:\n",
        "  if i < 0.5:\n",
        "    gen_pred_3.append(0)\n",
        "  else: gen_pred_3.append(1)\n",
        "\n",
        "print(gen_pred_3[:25])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3NRbdwIB8dP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b8b1d8-b5fd-41b6-9eba-ad00fd981317"
      },
      "source": [
        "# Get 1D array of labels from test_dataset\n",
        "y_lab = np.concatenate([y for x, y in test_dataset.take(eval_steps)], axis=0)\n",
        "print(len(y_lab))\n",
        "print(y_lab[:25])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1206\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7DwygfW_NAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be31d84-6691-4868-8594-d9d706ec8f40"
      },
      "source": [
        "tf.math.confusion_matrix(y_lab, gen_pred_3)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[601,   9],\n",
              "       [ 19, 577]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-gD0xbu96O4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "555eae98-f8d5-4419-8829-57d0a6937bfc"
      },
      "source": [
        "classification_report(y_lab, gen_pred_3)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n         0.0       0.97      0.99      0.98       610\\n         1.0       0.98      0.97      0.98       596\\n\\n    accuracy                           0.98      1206\\n   macro avg       0.98      0.98      0.98      1206\\nweighted avg       0.98      0.98      0.98      1206\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGX1vdI0-ARp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9d5288-7463-45f2-c97d-679a6040ef40"
      },
      "source": [
        "confusion_matrix(y_lab, gen_pred_3)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[601,   9],\n",
              "       [ 19, 577]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT9XULYn0EWF"
      },
      "source": [
        "# Create a run a simpler, two layer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_7tXB580Iqj"
      },
      "source": [
        "genderClf_2layer = tf.keras.models.Sequential([\n",
        "                              tf.keras.layers.Dense(128, activation = 'relu', input_shape=(10, 128)),\n",
        "                              tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "                              tf.keras.layers.AveragePooling1D(pool_size=10, strides=None, padding=\"valid\", data_format=\"channels_last\")\n",
        "                              ])\n",
        "genderClf_2layer.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy'])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltrrMn0a00vR"
      },
      "source": [
        "# Add early stopping to train classifier model; default is 10 epochs\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_monitor = EarlyStopping(patience=2)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzqOIzYj01vV"
      },
      "source": [
        "# Add model checkpoints, in case training times out on the GPU\n",
        "ckpt_path = 'model/gender/genderClf_2layer.ckpt'\n",
        "ckpt_dir = os.path.dirname(ckpt_path)\n",
        "\n",
        "ckpt = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path, save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOb9R_Hh1hUE",
        "outputId": "58e32a87-4862-406a-fdb3-ad98c4cb1f78"
      },
      "source": [
        "# If a trained model already exists, load it.\n",
        "# If model checkpoints exist, load them.\n",
        "# Else train a new model\n",
        "\n",
        "if os.path.isdir('model/gender/genderClf_2layer'):\n",
        "  genderClf = tf.keras.models.load_model('/model/gender/genderClf_2layer')\n",
        "  hist_2df = pd.read_csv('model/gender/genderClf_2layer.history.csv')\n",
        "else:\n",
        "  if os.path.isfile('model/gender/genderClf_2layer.ckpt'):\n",
        "    # Load model weights from the most recent checkpoint\n",
        "    latest = tf.train.latest_checkpoint(ckpt_dir)\n",
        "    genderClf_2layer.load_weights(latest)\n",
        "  hist_2 = genderClf_2layer.fit(train_dataset, \n",
        "                        steps_per_epoch=steps_per_epoch, \n",
        "                        epochs=5, \n",
        "                        validation_data=validation_dataset, \n",
        "                        validation_steps = val_steps,\n",
        "                        callbacks=[early_stopping_monitor, ckpt], \n",
        "                        batch_size=BATCH_SIZE)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "163/163 [==============================] - 4283s 26s/step - loss: 0.1324 - accuracy: 0.9807 - val_loss: 0.0615 - val_accuracy: 0.9890\n",
            "Epoch 2/5\n",
            "163/163 [==============================] - 3011s 18s/step - loss: 0.0643 - accuracy: 0.9888 - val_loss: 0.0558 - val_accuracy: 0.9890\n",
            "Epoch 3/5\n",
            "163/163 [==============================] - 2844s 17s/step - loss: 0.0611 - accuracy: 0.9882 - val_loss: 0.0547 - val_accuracy: 0.9884\n",
            "Epoch 4/5\n",
            "163/163 [==============================] - 2810s 17s/step - loss: 0.0599 - accuracy: 0.9881 - val_loss: 0.0528 - val_accuracy: 0.9896\n",
            "Epoch 5/5\n",
            "163/163 [==============================] - 2790s 17s/step - loss: 0.0588 - accuracy: 0.9886 - val_loss: 0.0528 - val_accuracy: 0.9890\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAsqALzz8j7Q",
        "outputId": "9e422dd4-890f-4396-b74a-ae7ceea482ce"
      },
      "source": [
        "  hist_2 = genderClf_2layer.fit(train_dataset, \n",
        "                        steps_per_epoch=steps_per_epoch, \n",
        "                        epochs=10, \n",
        "                        validation_data=validation_dataset, \n",
        "                        validation_steps = val_steps,\n",
        "                        callbacks=[early_stopping_monitor, ckpt], \n",
        "                        batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "163/163 [==============================] - 2941s 18s/step - loss: 0.0583 - accuracy: 0.9892 - val_loss: 0.0521 - val_accuracy: 0.9902\n",
            "Epoch 2/10\n",
            "163/163 [==============================] - 2802s 17s/step - loss: 0.0576 - accuracy: 0.9892 - val_loss: 0.0518 - val_accuracy: 0.9902\n",
            "Epoch 3/10\n",
            "163/163 [==============================] - 2806s 17s/step - loss: 0.0571 - accuracy: 0.9892 - val_loss: 0.0514 - val_accuracy: 0.9908\n",
            "Epoch 4/10\n",
            "163/163 [==============================] - 2778s 17s/step - loss: 0.0572 - accuracy: 0.9898 - val_loss: 0.0527 - val_accuracy: 0.9890\n",
            "Epoch 5/10\n",
            " 77/163 [=============>................] - ETA: 18:52 - loss: 0.0546 - accuracy: 0.9919"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN5V6-m62rwW"
      },
      "source": [
        "# Save the trained model and model history for use later\n",
        "genderClf_2layer.save('model/gender/genderClf_2layer')\n",
        "\n",
        "hist2_df = pd.DataFrame(hist_2.history) \n",
        "\n",
        "# save to csv: \n",
        "hist_csv_file = 'model/gender/genderClf_2layer.history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist2_df.to_csv(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUkZSoVo3GGm"
      },
      "source": [
        "plt.plot(hist_2df['accuracy'])\n",
        "plt.plot(hist_2df['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhKOGPuT3WxR"
      },
      "source": [
        "plt.plot(hist_2df['loss'])\n",
        "plt.plot(hist_2df['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne6dxuAC3ut7"
      },
      "source": [
        "## Evaluate the 2 layer classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzE2Jvbd3uA5"
      },
      "source": [
        "val_loss, val_acc = genderClf_2layer.evaluate(validation_dataset, steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPqnY7AY3x_V"
      },
      "source": [
        "test_loss, test_acc = genderClf_2layer.evaluate(test_dataset, steps=eval_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdyilK0U4Acg"
      },
      "source": [
        "y_pred_2 = genderClf_2layer.predict(test_dataset, steps=eval_steps)\n",
        "print(y_pred_2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRvQsAnR4KO4"
      },
      "source": [
        "gen_pred_2  = []\n",
        "for i in y_pred_2:\n",
        "  if i < 0.5:\n",
        "    gen_pred_2.append(0)\n",
        "  else: gen_pred_2.append(1)\n",
        "\n",
        "print(gen_pred_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTAtRAPO66H2"
      },
      "source": [
        "tf.math.confusion_matrix(y_lab, gen_pred_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_fP2b7FiN8_"
      },
      "source": [
        "# Load model weights from a previous checkpoint\n",
        "# model.load_weights(checkpoint_filepath)\n",
        "\n",
        "# Load model weights from the most recent checkpoint\n",
        "# latest = tf.train.latest_checkpoint(ckpt_dir)\n",
        "# model.load_weights(latest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6reUPaePmJmV",
        "outputId": "fb8f6cce-f80b-4ba3-f361-f4be69d1f418"
      },
      "source": [
        "# Save the model using SavedModel format - default for tf2\n",
        "#genderClf.save('model/genderClassifier_3layer')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/genderClassifier/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/genderClassifier/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-Jo6TEvDKbs",
        "outputId": "f212f09f-d5f4-42eb-f0d0-144b78cb1f76"
      },
      "source": [
        "# Creates the directory 'model/gender/genderClassifier/'\n",
        "#!ls 'model/genderClassifier_3layer/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/genderClassifier/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/genderClassifier/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "assets\tsaved_model.pb\tvariables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNHJpkkinWCm"
      },
      "source": [
        "# Load the SavedModel\n",
        "# new_model = tf.keras.model.load_model('model/gender/genderClassifier')\n",
        "# new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLGTgiexhQaT"
      },
      "source": [
        "# Save the model - using HDFS\n",
        "# genderClf.save('model/gender/genderClassifier.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFu-pFoEhyoo"
      },
      "source": [
        "# Load the saved model from HDFS\n",
        "# new_model = tf.keras.model.load_model('model/gender/genderClassifier.h5')\n",
        "# new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}