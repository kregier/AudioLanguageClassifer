{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SampleModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kregier/AudioLanguageClassifer/blob/main/SampleModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVT8XsCv32cB"
      },
      "source": [
        "# What is this notebook?\n",
        "This is a notebook to load a few audio files and load the VGGish model. The idea is to make sure the model loads and runs before moving it to the larger notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8zGos0v4UR6",
        "outputId": "c356145e-1e63-4728-e51f-9b10829ba32c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Set up the environment\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"All set up!\")"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All set up!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dGOQZjp4nJo"
      },
      "source": [
        "# Load the data\n",
        "- Connect to google drive\n",
        "- Load a few sample audio files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ApAHR9O3vWT",
        "outputId": "463e60d3-577d-4d97-ad38-d2faf46f69ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Set up the data import using Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb8okVM44xzn",
        "outputId": "b4ae1e69-3409-443f-b3a0-c5b0cc34163a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "\n",
        "# Change working directory\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "!ls"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n",
            "data  kaggle.json  reading-passage.txt\trecordings  speakers_all.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogn8m4vzIizc",
        "outputId": "ff25b055-f12a-4b70-a675-3bbb46442191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "meta = pd.read_csv('speakers_all.csv')\n",
        "# Prepare the data based on previous exploration\n",
        "# Drop 3 end columns with NaN values\n",
        "meta.drop(['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11'], axis=1, inplace=True)\n",
        "\n",
        "# Set speakerid as index\n",
        "meta.set_index('speakerid', inplace=True)\n",
        "meta.sort_index(inplace=True)\n",
        "\n",
        "# Replace missing values and typos\n",
        "meta.loc[meta.country.isnull(), 'country'] = 'laos'\n",
        "type_idx = meta[meta.sex =='famale'].index\n",
        "meta.loc[type_idx, 'sex'] = 'female'\n",
        "\n",
        "# Delete records with missing audio files\n",
        "missingIdx = meta[meta['file_missing?']==True].index\n",
        "meta.drop(missingIdx, inplace=True )\n",
        "\n",
        "# Delete records with no birthplace - synthesized files\n",
        "meta.dropna(subset=['birthplace'], inplace=True)\n",
        "\n",
        "# Delete files not present in audiofiles database\n",
        "nica_index = meta[meta.filename == 'nicaragua'].index\n",
        "sinhalese_index = meta[meta.filename=='sinhalese1'].index\n",
        "meta.drop(nica_index, inplace=True, axis=0)\n",
        "meta.drop(sinhalese_index, inplace=True, axis=0)\n",
        "\n",
        "meta.head()"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>age_onset</th>\n",
              "      <th>birthplace</th>\n",
              "      <th>filename</th>\n",
              "      <th>native_language</th>\n",
              "      <th>sex</th>\n",
              "      <th>country</th>\n",
              "      <th>file_missing?</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speakerid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>virginia, south africa</td>\n",
              "      <td>afrikaans1</td>\n",
              "      <td>afrikaans</td>\n",
              "      <td>female</td>\n",
              "      <td>south africa</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>pretoria, south africa</td>\n",
              "      <td>afrikaans2</td>\n",
              "      <td>afrikaans</td>\n",
              "      <td>male</td>\n",
              "      <td>south africa</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>diekabo, ivory coast</td>\n",
              "      <td>agni1</td>\n",
              "      <td>agni</td>\n",
              "      <td>male</td>\n",
              "      <td>ivory coast</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>prishtina, kosovo</td>\n",
              "      <td>albanian1</td>\n",
              "      <td>albanian</td>\n",
              "      <td>male</td>\n",
              "      <td>kosovo</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>33.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>tirana, albania</td>\n",
              "      <td>albanian2</td>\n",
              "      <td>albanian</td>\n",
              "      <td>male</td>\n",
              "      <td>albania</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            age  age_onset  ...       country file_missing?\n",
              "speakerid                   ...                            \n",
              "1          27.0        9.0  ...  south africa         False\n",
              "2          40.0        5.0  ...  south africa         False\n",
              "3          25.0       15.0  ...   ivory coast         False\n",
              "4          19.0        6.0  ...        kosovo         False\n",
              "5          33.0       15.0  ...       albania         False\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXP_iw2KbPFG",
        "outputId": "17039416-1a01-4cf5-b6e0-cb099034162e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "meta.shape"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2134, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liE9qM3oMnhg",
        "outputId": "3519f5a3-3d32-4513-d4c8-40a30b3fae61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# Select 96 files at random from meta.filename\n",
        "data = np.random.choice(meta.filename, size=96, replace=False)\n",
        "\n",
        "idx = meta[meta.filename.isin(data)].index\n",
        "df = meta.loc[idx, ['filename', 'sex']]\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speakerid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>bosnian2</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>cantonese3</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>english101</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>english19</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>english33</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             filename     sex\n",
              "speakerid                    \n",
              "39           bosnian2    male\n",
              "47         cantonese3    male\n",
              "64         english101  female\n",
              "76          english19    male\n",
              "92          english33    male"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFOMQw3LNk_q"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(df['filename'], df['sex'], random_state=38, test_size=0.33)"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaypXpze5ScJ"
      },
      "source": [
        "#Filenames for initial sample set\n",
        "#x_train_name = ['afrikaans1', 'mandarin3','french38']\n",
        "#x_test_name = ['spanish94', 'lao2']"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh4pd8L1yAzU"
      },
      "source": [
        "### Format features for testing and training sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU4ef8HOZHvi"
      },
      "source": [
        "SAMP_RATE = 16000"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1etFje8TIrc"
      },
      "source": [
        "# Segment the files into 10s arrays to have consistent input dimensions\n",
        "def get_10s(audio, sr):\n",
        "  \"\"\" Load an audio file and get the first 10 seconds.\n",
        "  Arguments: audio - the audio file; sr = sampling rate of the file\n",
        "  Returns: first 10s of audio file.\n",
        "  \"\"\"\n",
        "  beginning = audio[0:10*sr]\n",
        "  return beginning"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDcrk9a1Lq1s"
      },
      "source": [
        "# Scale audio to fall between [-1, 1]\n",
        "def normalize(audio):\n",
        "  norm = audio/max(audio)\n",
        "  return norm"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx0kRPasN_EX"
      },
      "source": [
        "# Sample audio files\n",
        "def load_data(series,  sr):\n",
        "  output = []\n",
        "  for i in range(len(series)):\n",
        "    filename = series.iloc[i]  #For an input series\n",
        "    #filename = series[i]    # For an input list\n",
        "    filepath = 'recordings/recordings/' + filename + '.mp3'\n",
        "    soundfile, sr = librosa.load(filepath, sr=SAMP_RATE)\n",
        "    output.append(normalize(get_10s(soundfile, sr)))\n",
        "  return np.asarray(output)"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKFuMRgjSNGY",
        "outputId": "324231c0-3aa1-400c-cc60-3f25ae512cab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#x_train = load_data(x_train_name, SAMP_RATE) #For Initial small sample\n",
        "x_train = load_data(x_train, SAMP_RATE)\n",
        "print(x_train.shape)\n",
        "print(type(x_train))"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 160000)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRXPTC36ST8e",
        "outputId": "0517094c-7967-4d98-f4f8-c70e80d3ec3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#x_test = load_data(x_test_name, SAMP_RATE) #For Initial small sample\n",
        "x_test = load_data(x_test, SAMP_RATE)\n",
        "print(x_test.shape)\n",
        "print(type(x_test))"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 160000)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZoarEYCH_51"
      },
      "source": [
        "# Format label arrays\n",
        "def gender_str_to_int(labels):\n",
        "  y_label = []\n",
        "  for i in range(len(labels)):\n",
        "    gender = labels.iloc[i] # for input Series\n",
        "    #gender = labels[i]  # for input list\n",
        "    if gender == 'male':\n",
        "      y_label.append(1)\n",
        "    else: y_label.append(0)\n",
        "  return np.asarray(y_label)"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eptv8L48Sv4h"
      },
      "source": [
        "# Format label arrays\n",
        "def gender_int(labels):\n",
        "  y_label = []\n",
        "  for name in labels:\n",
        "    idx = meta[meta.filename == name].index\n",
        "    gender = meta.loc[idx, 'sex'].values[0]\n",
        "    if gender == 'male':\n",
        "      y_label.append(1)\n",
        "    else: y_label.append(0)\n",
        "    print(name, gender)\n",
        "  return np.asarray(y_label)"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0EAQRT-17hi",
        "outputId": "2b9db4ff-fc01-4f6d-8980-1c05d07fba0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train_label = gender_str_to_int(y_train)  # For pd.DF\n",
        "#y_train_label = gender_int(x_train_name) # For intial sample list\n",
        "print(type(y_train_label))\n",
        "print(y_train_label.shape)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(64,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aE0VMyPBstI",
        "outputId": "314fbc0f-8546-43cd-d470-1eae21efb63f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#y_train_label= y_train_label[None, :]\n",
        "print(y_train_label)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 0\n",
            " 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w56obK0M2I8R",
        "outputId": "cbc07b11-901d-4f01-acba-64ce4e2186c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test_label = gender_str_to_int(y_test)  # For pd.DF\n",
        "#y_test_label = gender_int(x_test_name) # For initial sample list\n",
        "print(type(y_test_label))\n",
        "print(y_test_label.shape)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(32,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJVjDLxOByW9",
        "outputId": "08be76ba-c670-4ab2-89a0-2b4e2abeba5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#y_test_label = y_test_label[None, :]\n",
        "# print(y_test_label.shape)\n",
        "print(y_test_label)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuqNdJEs6iqK"
      },
      "source": [
        "# Load the pre-trained VGGish model from Tensorflow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o4kgOsG6pol"
      },
      "source": [
        "# Link to the model on TFHub\n",
        "hub_url = 'https://tfhub.dev/google/vggish/1'\n",
        "\n",
        "# Load the model as a Keras model\n",
        "vggish_model = hub.KerasLayer(hub_url)\n",
        "vggish_model.trainable = False"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY0DWhij7fSF"
      },
      "source": [
        "## Use VGGish model to extract feature embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM41FqAsmjKA"
      },
      "source": [
        "def extract_embeddings(data):\n",
        "  embedding = []\n",
        "  for i in range(len(data)):\n",
        "    vggish_embed = vggish_model(data[i])\n",
        "    embedding.append(vggish_embed)\n",
        "  return np.asarray(embedding)"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIjXZVYk-zZ5"
      },
      "source": [
        "x_train_embed = extract_embeddings(x_train)"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsBaoT2_AYI3"
      },
      "source": [
        "x_test_embed = extract_embeddings(x_test)"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_syJHwc07xBt"
      },
      "source": [
        "# Create a binary gender classifier.\n",
        "The classifier takes the vggish embeddings (extracted features) as input and predicts the gender of the speaker. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq6I8CyR8fyM"
      },
      "source": [
        "genderClf = tf.keras.models.Sequential([#vggish_model,\n",
        "                                        #tf.keras.layers.InputLayer(input_shape=10*SAMP_RATE),\n",
        "                                        #hub.KerasLayer(hub_url, trainable = False),\n",
        "                              #tf.keras.layers.Dense(128*3, activation = 'relu'),# input_shape = (None,160000)),\n",
        "                              tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "                              tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "                              tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "                              tf.keras.layers.AveragePooling1D(pool_size=10, strides=None, padding=\"valid\", data_format=\"channels_last\")\n",
        "                              ])\n",
        "genderClf.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy'])"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQzj_Td_GmbS"
      },
      "source": [
        "# Add early stopping to train classifier model\n",
        "# default is 10 epochs\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\n",
        "\n",
        "#genderClf.fit(x_train_norm[0], y_train_label[0], epochs=10) #, callbacks=[early_stopping_monitor]) #validation_split=0.25,"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFD-emztWrH_",
        "outputId": "60cff5ab-c3fb-45fe-cc36-589614ec182e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = genderClf.fit(vggish_embedding, y_train_label, epochs=10, callbacks=[early_stopping_monitor], \n",
        "              validation_split=0.25, batch_size=32)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 0.6874 - accuracy: 0.5000 - val_loss: 0.5032 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6110 - accuracy: 0.5000 - val_loss: 0.4855 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5423 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4820 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4310 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3871 - accuracy: 1.0000 - val_loss: 0.4090 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3475 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3100 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2747 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2413 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBP2KTXFGMPy",
        "outputId": "48271e0e-3a48-455f-d602-e9fd93c3e42f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "#plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ghs8SW-G4Gq",
        "outputId": "486f538b-db95-4f96-8372-038e019000ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "#plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXRUVbr38e+TGUKYA2oCJiCgNMoUEQQB2wkcQEVRFGfFoWmHtn1b73vv7b72cO1XW1sBGVRstW1s26FFhXZoBGSUoKjMMybM8xwI4Xn/qAIjBAyQyklV/T5rsVbqnFOVJ7VI/bL3Pntvc3dERCR+JQRdgIiIBEtBICIS5xQEIiJxTkEgIhLnFAQiInFOQSAiEucUBCLlZGZ/MbPflfPa5WZ24Ym+jkhlUBCIiMQ5BYGISJxTEEhMCXfJPGJm35jZTjN7ycwamtlYM9tuZp+aWZ1S1/cyszlmtsXMxpvZGaXOtTWzL8PP+zuQdsj3utzMZoWfO8XMzjrOmu8ys8VmtsnMRpvZKeHjZmbPmNk6M9tmZt+aWavwuUvNbG64tpVm9svjesNEUBBIbOoDXAQ0B64AxgL/AWQS+j9/P4CZNQdGAQ+Gz40B3jezFDNLAf4JvAbUBf4Rfl3Cz20LjATuBuoBw4HRZpZ6LIWa2U+B/wX6AicDK4A3wqcvBrqGf45a4Ws2hs+9BNzt7hlAK2DcsXxfkdIUBBKLBrn7WndfCXwOTHf3r9y9CHgXaBu+7jrgQ3f/xN2LgaeAasC5QEcgGfizuxe7+1vAjFLfYwAw3N2nu3uJu78C7Ak/71jcCIx09y/dfQ/wGNDJzHKAYiADOB0wd5/n7qvDzysGWppZTXff7O5fHuP3FTlIQSCxaG2pr3eX8bhG+OtTCP0FDoC77wcKgKzwuZX+w1UZV5T6+lTg4XC30BYz2wI0Cj/vWBxaww5Cf/Vnufs4YDAwBFhnZiPMrGb40j7ApcAKM5tgZp2O8fuKHKQgkHi2itAHOhDqkyf0Yb4SWA1khY8d0LjU1wXA7929dql/1d191AnWkE6oq2klgLs/5+7tgZaEuogeCR+f4e69gQaEurDePMbvK3KQgkDi2ZvAZWZ2gZklAw8T6t6ZAkwF9gH3m1mymV0NdCj13BeAe8zsnPCgbrqZXWZmGcdYwyjgNjNrEx5f+AOhrqzlZnZ2+PWTgZ1AEbA/PIZxo5nVCndpbQP2n8D7IHFOQSBxy90XAP2BQcAGQgPLV7j7XnffC1wN3ApsIjSe8E6p5+YDdxHqutkMLA5fe6w1fAr8F/A2oVZIU+D68OmahAJnM6Huo43Ak+FzNwHLzWwbcA+hsQaR42LamEZEJL6pRSAiEucUBCIicU5BICIS5xQEIiJxLinoAo5V/fr1PScnJ+gyRESiysyZMze4e2ZZ56IuCHJycsjPzw+6DBGRqGJmK450LqJdQ2bWw8wWhFdWfLSM88+EV2+cZWYLw9P0RUSkEkWsRWBmiYTWSLkIKARmmNlod5974Bp3f6jU9T/n+8XARESkkkSyRdABWOzuS8OzNN8Aeh/l+n6EptuLiEgliuQYQRahhbkOKATOKetCMzsVyOUIa6qb2QBCy/7SuHHjw84XFxdTWFhIUVHRCZZctaWlpZGdnU1ycnLQpYhIDKkqg8XXA2+5e0lZJ919BDACIC8v77A1MQoLC8nIyCAnJ4cfLhYZO9ydjRs3UlhYSG5ubtDliEgMiWTX0EpCS/oekB0+VpbrOYFuoaKiIurVqxezIQBgZtSrVy/mWz0iUvkiGQQzgGZmlhve9u96YPShF5nZ6UAdQsv+HrdYDoED4uFnFJHKF7EgcPd9wEDgI2Ae8Ka7zzGzx82sV6lLrwfe8Agvg7qnuITVW3ej1VZFRH4oovMI3H2Muzd396bu/vvwsf9299GlrvmNux82x6CibSsqZv32PazcUvFhsGXLFp5//vljft6ll17Kli2aOiEiwYqbtYbq10ilQUYam3burfAwOFIQ7Nu376jPGzNmDLVr166wOkREjkdVuWso4syMhjVTAVi3PTTgmlW7WoX0uz/66KMsWbKENm3akJycTFpaGnXq1GH+/PksXLiQK6+8koKCAoqKinjggQcYMGAA8P1yGTt27KBnz5506dKFKVOmkJWVxXvvvUe1atVOuDYRkR8Tc0HwP+/PYe6qbUe9Zm/Jfor37ScpMYHUpB9vFLU8pSa/vuInRzz/xBNPMHv2bGbNmsX48eO57LLLmD179sHbPEeOHEndunXZvXs3Z599Nn369KFevXo/eI1FixYxatQoXnjhBfr27cvbb79N//79y/ETi4icmJgLgvJISQx9+BfvC+33XZ4wOBYdOnT4wb3+zz33HO+++y4ABQUFLFq06LAgyM3NpU2bNgC0b9+e5cuXV2hNIiJHEnNBcLS/3Etzd9Zu28O67UXUTU+psG4igPT09INfjx8/nk8//ZSpU6dSvXp1unfvXuZcgNTU1INfJyYmsnv37gqpRUTkx8RcEJRXRY4ZZGRksH379jLPbd26lTp16lC9enXmz5/PtGnTjr9oEZEIiNsggNJh4Kzbvgc4vjCoV68enTt3plWrVlSrVo2GDRsePNejRw+GDRvGGWecQYsWLejYsWNF/ggiIifMom2CVV5enh+6Mc28efM444wzjvs1Q91ERazbvqfCu4kq2on+rCISn8xsprvnlXUurlsEB4RaBmkAJ9QyEBGJRgqCMIWBiMSrmAkCdz/hD+2qHgbR1o0nItEhJpaYSEtLY+PGjRXyQXkgDBpkpEZkOYrjdWA/grS0tKBLEZEYExMtguzsbAoLC1m/fn2Fvu6u3cWsLdpHQWoitaqlEHTD4MAOZSIiFSkmgiA5OTkiu3a5O09+tIDnxy/hxnMa89verUhIqBrdRCIiFSUmgiBSzIxHLmmBA0PHLwFQGIhIzFEQ/Agz4/9c0gJQGIhIbFIQlMOhYWAGj/dSGIhIbFAQlFNZLQOFgYjEAgXBMTgQBu4wbILCQERig4LgGJkZv+oRahkcCIPf9m5VZSadiYgcKwXBcVAYiEgsURAcJ4WBiMQKBcEJOBAGjjN8wlJAYSAi0UdBcILMjEd7nA6gMBCRqKQgqACHhoFhPN77JwoDEYkKCoIKcjAMHIZPDLUMFAYiEg0UBBXIzHi0Z7hloDAQkSihIKhgCgMRiTYKgghQGIhINFEQRMiBMHBgxMSlmMH/9FIYiEjVoyCIIDPjsXDLYES4ZaAwEJGqRkEQYQoDEanqFASV4NAwcA+FgVYtFZGqQEFQSQ6EgVlo0tmmXXt5um9rUpMSgy5NROKcgqAShcLgDOqlp/CHMfPZtGMvw29uT8205KBLE5E4lhDJFzezHma2wMwWm9mjR7imr5nNNbM5Zva3SNZTVQzo2pSn+7ZmxvJNXDd8Guu2FQVdkojEsYgFgZklAkOAnkBLoJ+ZtTzkmmbAY0Bnd/8J8GCk6qlqrm6XzUu3ns2KjTu5eugUlq7fEXRJIhKnItki6AAsdvel7r4XeAPofcg1dwFD3H0zgLuvi2A9VU635pmMuqsju/eWcM2wqcwq2BJ0SSIShyIZBFlAQanHheFjpTUHmpvZZDObZmY9ynohMxtgZvlmlr9+/foIlRuM1o1q89a955Kemki/EdP4bEFcZaGIVAERHSMohySgGdAd6Ae8YGa1D73I3Ue4e56752VmZlZyiZGXWz+dt+89lyaZ6dz1Sj5vzywMuiQRiSORDIKVQKNSj7PDx0orBEa7e7G7LwMWEgqGuNMgI403BnTknCZ1efgfXzN0/BLcPeiyRCQORDIIZgDNzCzXzFKA64HRh1zzT0KtAcysPqGuoqURrKlKy0hL5uVbO9Cr9Sn88V/zefyDuezfrzAQkciK2DwCd99nZgOBj4BEYKS7zzGzx4F8dx8dPnexmc0FSoBH3H1jpGqKBilJCfz5ujbUr5HKyMnLWLd9jyaeiUhEWbR1P+Tl5Xl+fn7QZUScuzNi4lL+d+x8zm1aj+E3tSdDE89E5DiZ2Ux3zyvrXNCDxXIEZsbd3UITz75YpolnIhI5CoIq7up22bx4Sx7LNfFMRCJEQRAFurdowKi7OrIrPPHsa008E5EKpCCIEq0b1ebt8MSz60dMY7wmnolIBVEQRJEDE89y66dzpyaeiUgFURBEmQYZafz97o50yA1NPBs2QRPPROTEKAiiUEZaMi/fdjZXtD6FJ8Zq4pmInBhtTBOlUpMSefa6NmSGJ56t376HP2nimYgcBwVBFEtIMP7r8jNoUDOVJ8bOZ9POvZp4JiLHTF1DUc7MuKdbU/50bamJZ9s18UxEyk9BECP6tA9NPFu2YSd9hk5h2YadQZckIlFCQRBDurdowKgBHdm5p4Q+Q6do4pmIlIuCIMa0aVSbt+7pRPUUTTwTkfJREMSgJpk1eOe+7yeevfOlJp6JyJEpCGJU6Ylnv3hTE89E5MgUBDHswMSzy886mSfGzue3H8zTxDMROYzmEcS41KREnru+LZkZ4YlnO/bw1LVnaeKZiBykIIgDCQnGf1/ekoY108ITz/YwrL8mnolIiLqG4kTpiWfTlmrimYh8T0EQZ0pPPOs9eDKzNNdAJO4pCOLQ+S0a8I97OpFgRt9hU/n7jO+CLklEAqQgiFOtsmrxwc+7cE6Tuvzq7W957J1v2bOvJOiyRCQACoI4Vic9hb/c1oF7uzdl1Bff0Xf4NFZv3R10WSJSyRQEcS4xwfhVj9MZ1r8di9du5/LnJjF1ycagyxKRSqQgEAB6tDqZ9wZ2plb1ZPq/NJ0XP1+qmcgicUJBIAed1iCD937WmQtOb8DvPpzHA2/MYtfefUGXJSIRpiCQH8hIS2ZY//Y8ckkL3v9mFVc/P4Xl2ttAJKYpCOQwCQnGz84/jb/c1oE124q4YvAkxs1fG3RZIhIhCgI5om7NM3l/YBca1anOHa/k8+yni7RonUgMUhDIUTWqW5237z2Xq9pk8cynC7nr1Xy27i4OuiwRqUAKAvlR1VIS+VPf1vxPr58wYeF6rhwymQVrtgddlohUEAWBlIuZccu5OYwa0JEde/Zx1fOT+eCbVUGXJSIVQEEgx+TsnLp88PMunHFyTQb+7St+/+Fc9pXsD7osETkBCgI5Zg1rpjHqro7c3OlUXvh8GTe99AUbd+wJuiwROU4KAjkuKUkJPN67FU9d25ovv9vMFYMm8bWWtBaJShENAjPrYWYLzGyxmT1axvlbzWy9mc0K/7szkvVIxbumfTZv33suZsa1WtJaJCpFLAjMLBEYAvQEWgL9zKxlGZf+3d3bhP+9GKl6JHJaZdXi/Z93oUOulrQWiUaRbBF0ABa7+1J33wu8AfSO4PeTANVNT+GV27WktUg0imQQZAEFpR4Xho8dqo+ZfWNmb5lZo7JeyMwGmFm+meWvX78+ErVKBTiwpPXQG0NLWl8xaBLTlmpJa5GqLujB4veBHHc/C/gEeKWsi9x9hLvnuXteZmZmpRYox67nmaElrWtWS+bGF6fz0qRlWtJapAqLZBCsBEr/hZ8dPnaQu2909wP3Hb4ItI9gPVKJSi9p/dsP5vLg37WktUhVFckgmAE0M7NcM0sBrgdGl77AzE4u9bAXMC+C9UglK72k9eivQ0tar9ioJa1FqpqIBYG77wMGAh8R+oB/093nmNnjZtYrfNn9ZjbHzL4G7gdujVQ9EozSS1qv3lrEFYMm8dn8dUGXJSKlWLT13ebl5Xl+fn7QZchxKNi0i7tfm8m8Ndt46MLmDDz/NBISLOiyROKCmc1097yyzgU9WCxx5MCS1le2yeLpTxYy4LV8thVpSWuRoCkIpFJVS0nk6fCS1uMXrKf34MnMXbUt6LJE4pqCQCrdoUta9xo8iWc/XUSxVjEVCYSCQAJzdk5dPn6wK5eeeTLPfLqQK4dMZt5qtQ5EKlu5gsDMHjCzmhbykpl9aWYXR7o4iX110lN4rl9bhvVvz9ptRfQaPInn/q3WgUhlKm+L4HZ33wZcDNQBbgKeiFhVEnd6tDqJjx/qRo9WJ/P0Jwu56vnJzF+j1oFIZShvEBy4x+9S4DV3n1PqmEiFqJuewqB+bRnWvx2rt4TmHAwet0g7oIlEWHmDYKaZfUwoCD4yswxAv50SET1ancwnv+jGJT85iac+XshVz09hwZrtQZclErPKGwR3AI8CZ7v7LiAZuC1iVUncq5uewuAb2vH8je1YtWU3VwyaxJDPFqt1IBIB5Q2CTsACd99iZv2B/wS2Rq4skZBLzzyZjx/qykUtG/LkRwu4eugUFq5V60CkIpU3CIYCu8ysNfAwsAR4NWJViZRSr0YqQ25sx5Ab2lG4eTeXP6fWgUhFKm8Q7PPQokS9gcHuPgTIiFxZIoe77KxQ6+DClg148qMF9Bk6hUVqHYicsPIGwXYze4zQbaMfmlkCoXECkUpVv0Yqz9/YnsE3tOW7Tbu4bNAkho5fotaByAkobxBcB+whNJ9gDaFNZp6MWFUiP+Lys07hk19044LTG/DHf83nmmFTWbxuR9BliUSlcgVB+MP/daCWmV0OFLm7xggkUKHWQTue69eWFRt3culznzN8whJK9kfX0uoiQSvvEhN9gS+Aa4G+wHQzuyaShYmUh5nRq/UpfPxQN85vkcn/jp3PNcOmqHUgcgzKtTFNeAexi9x9XfhxJvCpu7eOcH2H0cY0ciTuzuivV/Hr0XPYtbeEX17cnDu6NCFRm9+IVMjGNAkHQiBs4zE8V6RSmBm922Tx8UNd6d48kz+Mmc+1w6awZL1aByJHU94P83+Z2UdmdquZ3Qp8CIyJXFkix69BRhrDb2rPs9e3Ycn6nVz67Oe8MHGpxg5EjqDcexabWR+gc/jh5+7+bsSqOgp1DcmxWLe9iP/77mw+mbuW9qfW4clrzqJJZo2gyxKpdEfrGtLm9RLz3J1/zlrJb0bPpai4hEcuacFtnXM1diBx5bjHCMxsu5ltK+PfdjPTYvESFcyMq9pm88lDXTmvWX1+9+E8rhs+lWUbdgZdmkiVcNQgcPcMd69Zxr8Md69ZWUWKVIQGNdN44eY8nu7bmoVrt9Pz2Ym8NGkZ+zV2IHFOd/5IXDEzrm6XzSe/6EbnpvX57QdzuW7EVJardSBxTEEgcalhzTRevCWPP13bmgVrttPj2YkMHreIouKSoEsTqXQKAolbZkaf9tnhWckNeOrjhVzwpwmM+XY10XYThciJUBBI3DupVhpD+7dn1F0dyUhL4r7Xv+S6EdOYs0p7L0l8UBCIhHVqWo8P7z+PP1x1JovX7eDyQZN47J1v2LBjT9CliUSUgkCklMQE44ZzGvPZL7tzR+dc/pFfyPlPjmfExCXs3ac9DyQ2KQhEylCrWjL/eXlLPnqoK2fn1uUPY+Zz8TMT+HTuWo0fSMxREIgcRdPMGoy89Wxeub0DSYkJ3PlqPjeP/IKF2iJTYoiCQKQcujXPZOwD5/HrK1rydcEWej77Of/93mw279wbdGkiJ0xBIFJOyYkJ3NY5lwmPnM+N5zTmr9NW0P2p8fxl8jKKtWeyRDEFgcgxqpOewuO9WzH2ga6cmVWL37w/l57Pfs6EheuDLk3kuCgIRI5Ti5MyeO2ODrxwcx77SvZzy8gvuOMvM1iqjXAkykQ0CMysh5ktMLPFZvboUa7rY2ZuZmUukSpSVZkZF7VsyEcPdeWxnqczfdkmLvnzRH73wVy27i4OujyRcolYEJhZIjAE6Am0BPqZWcsyrssAHgCmR6oWkUhLTUrk7m5N+eyX3bm6bTYvTV7GT58az9+mf6ed0aTKi2SLoAOw2N2Xuvte4A2gdxnX/Rb4I1AUwVpEKkVmRip/vOYs3h/YhaaZNfiPd7/l8kGTmLpkY9CliRxRJIMgCygo9bgwfOwgM2sHNHL3DyNYh0ila5VVi7/f3ZHBN7Rl2+5i+r0wjXv/OpOCTbuCLk3kMIENFptZAvA08HA5rh1gZvlmlr9+ve7MkOhgZlx+1in8++FuPHxRc8YvWM8FT0/gyY/ms3PPvqDLEzkokkGwEmhU6nF2+NgBGUArYLyZLQc6AqPLGjB29xHunufueZmZmREsWaTipSUn8vMLmvHZL7tz2ZknM+SzJZz/1Hjemlmo3dGkSohkEMwAmplZrpmlANcDow+cdPet7l7f3XPcPQeYBvRyd+1MLzHppFppPHNdG96571xOqV2NX/7ja656fjIzV2wOujSJcxELAnffBwwEPgLmAW+6+xwze9zMekXq+4pUde0a1+Gde8/l6b6tWbOtiD5Dp/DAG1+xeuvuoEuTOGXRtpJiXl6e5+er0SCxYeeefQwdv4QRny8lweCebk2567wmpKcmBV2axBgzm+nuZc7VUhCIVAEFm3bxxNj5fPjtauqlp3Bv96b073gqacmJQZcmMUJBIBIlvvpuM3/6eCGTFm/gpJpp/PyC0+ib14jkRK0GIydGQSASZaYu2chTHy9g5orNNK5bnQcvbEbvNlkkJljQpUmUOloQ6M8MkSqoU9N6vHVPJ16+9Wwy0pL4xZtfc8mfJzLm29W65VQqnIJApIoyM84/vQHvD+zC8ze2A+C+17/kisGT+Gz+Om2ZKRVGQSBSxSUkGJeeeTIfPdiVP13bmm1Fxdz2lxlcO2yq1jCSCqExApEoU1yynzfzCxj078Ws2VZEl9Pq88tLWtCmUe2gS5MqTIPFIjGoqLiEv05bwdDxS9i4cy8XntGQhy9uzhkn1wy6NKmCFAQiMWznnn28PHkZwycuZceefVx+1ik8eGEzmmbWCLo0qUIUBCJxYOuuYkZ8voSXJy+nqLiEPu2yeeDCZmTXqR50aVIFKAhE4siGHXt4/rMl/HX6Ctydfh0aM/D802hQMy3o0iRACgKROLR6624GjVvMmzMKSEo0bumUwz3dmlInPSXo0iQACgKROLZi406e/XQR785aSXpKEnd0yeXO83LJSEsOujSpRAoCEWHR2u08/clCxs5eQ+3qydzTrSm3dMqhWooWtosHCgIROWj2yq089fECxi9YT2ZGKgPPP43rOzQiNUmBEMsUBCJymPzlm3jyowVMX7aJrNrVuP+C0+jTLpskrXQak7TonIgcJi+nLm8M6Mhrd3SgfkYqv3r7Wy56ZiLvzVqphe3ijIJAJI6ZGec1y+Sf953LCzfnkZqUwANvzKLns5/zwTerKFEgxAUFgYhgZlzUsiFj7j+P5/q1pcSdgX/7ioufmcA/v1rJvpL9QZcoEaQxAhE5TMl+Z+zs1Qwet5j5a7aTWz+d+7o35cq2WdotLUppsFhEjsv+/c7Hc9cyaNwi5qzaRqO61bive2hQOSVJgRBNFAQickLcnXHz1/HcuMV8XbCFU2qlcW/3plyb14i0ZN12Gg0UBCJSIdydiYs28Ny/FzFzxWYa1kzl7q5NueGcxgqEKk5BICIVyt2ZumQjz41bxLSlm6hfI5W7uzbhxo6NqZ6SFHR5UgYFgYhEzPSlGxk0bjGTFm+gbnoKd56Xy82dcqiRqkCoShQEIhJxM1dsZtC4RYxfsJ5a1ZK5o0sut5ybQ61qWtyuKlAQiEil+bpgC4PGLebTeWvJSE3its453N4ll9rVtfx1kBQEIlLp5qzayuBxixk7ew3pKYncfG4Od3bJpV6N1KBLi0sKAhEJzII12xn82WI++GYVaUmJ9O/YmLu6NqFBhnZMq0wKAhEJ3OJ1Oxjy2WLem7WS5MQE+nVozD3dmnJSLQVCZVAQiEiVsXzDToZ8tph3v1pJghl9z87m3u6nkVW7WtClxTQFgYhUOQWbdvH8+CW8NbMAgD7tsrmv+2k0rlc94Mpik4JARKqsVVt2M2zCEt74ooASd65sk8XPzm9Kk8waQZcWUxQEIlLlrd1WxPAJS3l9+gqKS/ZzRetTGHj+aTRrmBF0aTFBQSAiUWPd9iJe/HwZr01dwe7iEi48owH3dGtKXk7doEuLagoCEYk6m3bu5ZUpy3ll6nK27Com79Q63N2tKRec3oCEBAu6vKgT2J7FZtbDzBaY2WIze7SM8/eY2bdmNsvMJplZy0jWIyLRo256Cg9d1Jwpj/6U31zRktVbi7jr1Xwu/vNE3swvYO8+7ZpWUSLWIjCzRGAhcBFQCMwA+rn73FLX1HT3beGvewH3uXuPo72uWgQi8am4ZD9jvl3NsAlLmbd6GyfVTOP2Ljn069CYjDStZ/RjgmoRdAAWu/tSd98LvAH0Ln3BgRAISweiq59KRCpNcmICvdtkMeb+Lrxyewdy66fzhzHzOfeJcfy/f81n3faioEuMWpFcJzYLKCj1uBA459CLzOxnwC+AFOCnZb2QmQ0ABgA0bty4wgsVkehhZnRrnkm35pl8XbCF4ROXMHTCEl6ctIw+7bIZ0LUJufXTgy4zqkSya+gaoIe73xl+fBNwjrsPPML1NwCXuPstR3tddQ2JyKGWbdjJC58v5a2ZhRSX7KfHT07i7m5NadOodtClVRlH6xqKZItgJdCo1OPs8LEjeQMYGsF6RCRG5dZP5w9XncmDFzbjlSnLeW3qCsbOXkPHJnW5u1tTujfPxEx3Gh1JJMcIZgDNzCzXzFKA64HRpS8ws2alHl4GLIpgPSIS4xpkpPHIJacz5bEL+M/LzmD5hl3c9vIMej77Of/8aiXFJbrTqCwRnUdgZpcCfwYSgZHu/nszexzId/fRZvYscCFQDGwGBrr7nKO9prqGRKS89u7bz+ivVzF8whIWrdtBVu1q3HleLted3Sju9lbWhDIRiWv79zvj5q9j+MQlzFi+mdrVk7m5Uw63dDo1bjbKURCIiITNXLGJYROW8snctaQlJ9A3rxF3ndeERnVje9VTBYGIyCEWr9vOiIlLeferlZTsdy476xTu7tqEVlm1gi4tIhQEIiJHsGZrESMnL+Nv079jx559nNesPvd0a8q5TevF1J1GCgIRkR+xdXcxr09fwchJy9mwYw9nZtXi7m5N6NnqZBJjYJE7BYGISDkVFZfw7lcrGTFxKcs27KRx3erceV4ufdplk54avXcaKQhERI5RyX7nk7lrGDZhKbMKtpCRlkS/Do25udOpZNeJvoFlBYGIyAn48rvNjJy0jLGz1+Du9Gh1Erd3znmux9wAAAagSURBVKX9qXWiZhwhqCUmRERiQrvGdWh3Qx1WbdnNq1NXMOqL7xjz7RrOyq7FHV1y6dnqZFKSIrq9S0SpRSAicox27d3H21+u5OXJy1i6ficNa6Zyc6fQ3gh101OCLq9M6hoSEYmA/fudCYvWM3LSMj5ftIHUpASubpfFbZ1zad4wI+jyfkBdQyIiEZCQYJzfogHnt2jAwrXbeXnyct75spBRXxRwXrP63N45l27NM6v8HstqEYiIVKDNO/fyty++49Wpy1m7bQ9N6qdzW+cc+rTPDnShO3UNiYhUsgN7LI+ctIyvC7dSMy2Jfuc05uZOOWTVrlbp9SgIREQC4u58+d0WRk5exr9mrwE4ePtpu8a1K+32U40RiIgExMxof2od2p9ah5VbdvPq1OWMmv4dH36zmtaNanN75xwuPfNkkhODu/1ULQIRkUp28PbTSctYuuH7209v6NCYOhG6/VRdQyIiVVDZt59mc3vnHJpV8O2n6hoSEamCDr/9dFn49tPvQrefdsmlW7PI336qFoGISBWyaedeRpW+/TQznds659KnXdYJ3X6qriERkSizd99+xs5ezUuTlvFN+PbT317Zit5tso7r9dQ1JCISZVKSEujdJoterU8Jr366PGL7KisIRESqsNDtp3Vpf2rdiH2P6F03VUREKoSCQEQkzikIRETinIJARCTOKQhEROKcgkBEJM4pCERE4pyCQEQkzkXdEhNmth5YcZxPrw9sqMByop3ejx/S+/E9vRc/FAvvx6nunlnWiagLghNhZvlHWmsjHun9+CG9H9/Te/FDsf5+qGtIRCTOKQhEROJcvAXBiKALqGL0fvyQ3o/v6b34oZh+P+JqjEBERA4Xby0CERE5hIJARCTOxU0QmFkPM1tgZovN7NGg6wmKmTUys8/MbK6ZzTGzB4KuqSows0Qz+8rMPgi6lqCZWW0ze8vM5pvZPDPrFHRNQTGzh8K/J7PNbJSZpQVdUyTERRCYWSIwBOgJtAT6mVnLYKsKzD7gYXdvCXQEfhbH70VpDwDzgi6iingW+Je7nw60Jk7fFzPLAu4H8ty9FZAIXB9sVZERF0EAdAAWu/tSd98LvAH0DrimQLj7anf/Mvz1dkK/5Me3G3aMMLNs4DLgxaBrCZqZ1QK6Ai8BuPted98SbFWBSgKqmVkSUB1YFXA9EREvQZAFFJR6XEicf/gBmFkO0BaYHmwlgfsz8H+A/UEXUgXkAuuBl8NdZS+aWXrQRQXB3VcCTwHfAauBre7+cbBVRUa8BIEcwsxqAG8DD7r7tqDrCYqZXQ6sc/eZQddSRSQB7YCh7t4W2AnE5ZiamdUh1HOQC5wCpJtZ/2Criox4CYKVQKNSj7PDx+KSmSUTCoHX3f2doOsJWGegl5ktJ9Rl+FMz+2uwJQWqECh09wOtxLcIBUM8uhBY5u7r3b0YeAc4N+CaIiJegmAG0MzMcs0shdCAz+iAawqEmRmh/t957v500PUEzd0fc/dsd88h9P9inLvH5F995eHua4ACM2sRPnQBMDfAkoL0HdDRzKqHf28uIEYHzpOCLqAyuPs+MxsIfERo5H+ku88JuKygdAZuAr41s1nhY//h7mMCrEmqlp8Dr4f/aFoK3BZwPYFw9+lm9hbwJaG77b4iRpea0BITIiJxLl66hkRE5AgUBCIicU5BICIS5xQEIiJxTkEgIhLnFAQilcjMumuFU6lqFAQiInFOQSBSBjPrb2ZfmNksMxse3q9gh5k9E16f/t9mlhm+to2ZTTOzb8zs3fAaNZjZaWb2qZl9bWZfmlnT8MvXKLXe/+vhWasigVEQiBzCzM4ArgM6u3sboAS4EUgH8t39J8AE4Nfhp7wK/MrdzwK+LXX8dWCIu7cmtEbN6vDxtsCDhPbGaEJotrdIYOJiiQmRY3QB0B6YEf5jvRqwjtAy1X8PX/NX4J3w+v213X1C+PgrwD/MLAPIcvd3Ady9CCD8el+4e2H48SwgB5gU+R9LpGwKApHDGfCKuz/2g4Nm/3XIdce7PsueUl+XoN9DCZi6hkQO92/gGjNrAGBmdc3sVEK/L9eEr7kBmOTuW4HNZnZe+PhNwITw7m+FZnZl+DVSzax6pf4UIuWkv0REDuHuc83sP4GPzSwBKAZ+RmiTlg7hc+sIjSMA3AIMC3/Ql16t8yZguJk9Hn6NayvxxxApN60+KlJOZrbD3WsEXYdIRVPXkIhInFOLQEQkzqlFICIS5xQEIiJxTkEgIhLnFAQiInFOQSAiEuf+P1nL8+cE54hxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFdxsZ7TqHzs"
      },
      "source": [
        "#genderClf.fit(train_dataset, epochs=10, callbacks=[early_stopping_monitor], \n",
        "#              validation_split=0.25, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_6hlUyS8pdN",
        "outputId": "e00e1f33-175e-4e59-c689-4f65684f868e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "genderClf.summary()"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_39 (Dense)             (None, 10, 128)           16512     \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 10, 64)            8256      \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 10, 1)             65        \n",
            "_________________________________________________________________\n",
            "average_pooling1d_3 (Average (None, 1, 1)              0         \n",
            "=================================================================\n",
            "Total params: 24,833\n",
            "Trainable params: 24,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U66xnpdmbOk",
        "outputId": "84e61819-afea-4086-a0aa-6b40f1ef86d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = genderClf.predict(x_test_embed)\n",
        "print(y_pred.shape)"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb83672d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb83672d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(32, 1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykSC2rumhJUW"
      },
      "source": [
        "def predict_to_int(array, threshold):\n",
        "  labels = []\n",
        "  for i in range(len(array)):\n",
        "    if array[i] > threshold:\n",
        "      labels.append(1)  #'male'\n",
        "    else: labels.append(0)  #'female'\n",
        "  return labels"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK-Ta-zShyvY",
        "outputId": "5dc30b79-5145-4edc-d08c-e97b95353fec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gen_pred = predict_to_int(y_pred, 0.5)\n",
        "print(gen_pred)"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS_twBdT7zkn",
        "outputId": "75fa24f9-8a36-43f9-b02e-21ff39ec1ca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "confusion_matrix(y_test_label, gen_pred)\n",
        "#print(y_pred)"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12,  1],\n",
              "       [ 0, 19]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLkHhbEl78Ug"
      },
      "source": [
        "# Next steps:\n",
        "Embed the vggish model into a trainable binary classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4WS8YRw7vtY"
      },
      "source": [
        "# enable fine-tuning with trainable argument\n",
        "#layer = hub.KerasLayer(..., trainable=True)\n",
        "\n",
        "# Reexport the fine-tuned model\n",
        "\n",
        "#loaded_obj = hub.load(\"https://tfhub.dev/...\")\n",
        "#hub_layer = hub.KerasLayer(loaded_obj, trainable=True, ...)\n",
        "\n",
        "#model = keras.Sequential([..., hub_layer, ...])\n",
        "#model.compile(...)\n",
        "#model.fit(...)\n",
        "\n",
        "#export_module_dir = os.path.join(os.getcwd(), \"finetuned_model_export\")\n",
        "#tf.saved_model.save(loaded_obj, export_module_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIcT-AjI-URx"
      },
      "source": [
        "Epoch - on complete pass through the dataset\n",
        "\n",
        "Batch size = divide dataset into smaller parts/sets\n",
        "\n",
        "Iterations - number of batches to complete one epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbVXZm8R_WmN"
      },
      "source": [
        "#model.fit(x, y, batch_size=n, epochs=n) # Batch size default is 32\n",
        "# Do not use batch size if the data is in the form of dataset, generators, or keras.utils.Sequence instances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkVMjj-9MZTB"
      },
      "source": [
        "# Don't run this - sample code for later\n",
        "## Import larger sample set\n",
        "- at least two batches, to see how model fits\n",
        "- a least one batch of testing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VhXxIXqVjX7"
      },
      "source": [
        "## Original (small samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r82d0Me88r9"
      },
      "source": [
        "## Attempt to expand model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S30BTYaXo4Qh"
      },
      "source": [
        "#train_dataset =  tf.data.Dataset.from_tensor_slices( (x_train, y_train_labels))\n",
        "#test_dataset = tf.data.Dataset.from_tensor_slices( (x_test, y_test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdLj5PuQplTH"
      },
      "source": [
        "#BATCH_SIZE=32\n",
        "#SHUFFLE_BUFFER_SIZE=100\n",
        "\n",
        "#train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "#test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKKdEYUto5Sw"
      },
      "source": [
        "## Convert data (np. arrays) to a TF Dataset"
      ]
    }
  ]
}