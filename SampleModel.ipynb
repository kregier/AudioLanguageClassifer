{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SampleModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPS9b5AWqTs0E4QiqHnJiUD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kregier/AudioLanguageClassifer/blob/main/SampleModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVT8XsCv32cB"
      },
      "source": [
        "# What is this notebook?\n",
        "This is a notebook to load a few audio files and load the VGGish model. The idea is to make sure the model loads and runs before moving it to the larger notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8zGos0v4UR6",
        "outputId": "9b128a14-0066-417f-c2cf-0df5d774edee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Set up the environment\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "print(\"All set up!\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All set up!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dGOQZjp4nJo"
      },
      "source": [
        "# Load the data\n",
        "- Connect to google drive\n",
        "- Load a few sample audio files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ApAHR9O3vWT",
        "outputId": "0479827d-547b-49b1-ee03-b4ce8f48f218",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Set up the data import using Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb8okVM44xzn",
        "outputId": "0c9d9e61-274c-4ef9-8248-7a65660f199e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "\n",
        "# Change working directory\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n",
            "data  kaggle.json  reading-passage.txt\trecordings  speakers_all.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogn8m4vzIizc"
      },
      "source": [
        "meta = pd.read_csv('speakers_all.csv')\n",
        "\n",
        "#Filenames\n",
        "x_train = ['afrikaans1', 'mandarin3','french38']\n",
        "x_test = ['spanish94', 'lao2']"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaypXpze5ScJ"
      },
      "source": [
        "# Sample audio files\n",
        "afrikaans = 'recordings/recordings/afrikaans1.mp3'\n",
        "mandarin = 'recordings/recordings/mandarin3.mp3'\n",
        "spanish = 'recordings/recordings/spanish94.mp3'\n",
        "french = 'recordings/recordings/french38.mp3'\n",
        "lao = 'recordings/recordings/lao2.mp3'\n",
        "\n",
        "SAMP_RATE = 16000\n",
        "\n",
        "afrikaans_raw, sr = librosa.load(afrikaans, sr=SAMP_RATE)\n",
        "mandarin_raw, sr = librosa.load(mandarin, sr=SAMP_RATE)\n",
        "spanish_raw, sr = librosa.load(spanish, sr=SAMP_RATE)\n",
        "french_raw, sr = librosa.load(french, sr=SAMP_RATE)\n",
        "lao_raw, sr = librosa.load(lao, sr=SAMP_RATE)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh4pd8L1yAzU"
      },
      "source": [
        "### Format features for testing and training sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-glpT5G3HRcN"
      },
      "source": [
        "# Results in np arrays of different lengths, since the audio files are different lengths\n",
        "x_train_features = np.asarray([afrikaans_raw, mandarin_raw, french_raw])\n",
        "# print(x_train_features.shape)\n",
        "# print(type(x_train_features))"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_A9yB2Mzp0R"
      },
      "source": [
        "x_test_features = np.asarray([spanish_raw, lao_raw])\n",
        "# print(x_test_features.shape)\n",
        "# print(type(x_test_features))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1etFje8TIrc"
      },
      "source": [
        "# Segment the files into 10s arrays to have consistent input dimensions\n",
        "def get_10s(audio, sr):\n",
        "  \"\"\" Load an audio file and get the first 10 seconds.\n",
        "  Arguments: audio - the audio file; sr = sampling rate of the file\n",
        "  Returns: first 10s of audio file.\n",
        "  \"\"\"\n",
        "  beginning = audio[0:10*sr]\n",
        "  return beginning"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYXp5DQmTIgx",
        "outputId": "6ad9bf5d-8b4c-48c1-946e-676ff84d7c79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#x_train_beg = np.asarray([get_10s(i, SAMP_RATE) for i in x_train_features])\n",
        "#print(x_train_beg.shape)\n",
        "#print(type(x_train_beg))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 160000)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDcrk9a1Lq1s"
      },
      "source": [
        "# Scale audio to fall between [-1, 1]\n",
        "def normalize(audio):\n",
        "  norm = audio/max(audio)\n",
        "  return norm"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hizagOhMx4o",
        "outputId": "1ffe5a1f-8c20-4bb6-ac95-107094cacc66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train_norm = np.asarray([normalize(get_10s(i, SAMP_RATE)) for i in x_train_features])\n",
        "#x_train_norm = np.asarray([normalize(i) for i in x_train_beg])\n",
        "print(x_train_norm.shape)\n",
        "#print(type(x_train_norm))\n",
        "#print(type(x_train_norm[0]))\n",
        "#print(type(x_train_norm[0][0]))\n",
        "\n",
        "# Reshape x_train_norm to have shape (None, 4, 16000)\n",
        "x_train_norm = x_train_norm[None, :,:]\n",
        "\n",
        "print(x_train_norm.shape)\n",
        "#print(type(x_train_norm))\n",
        "#print(type(x_train_norm[0]))\n",
        "#print(type(x_train_norm[0][0]))\n",
        "#print(type(x_train_norm[0][0][0]))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 160000)\n",
            "(1, 3, 160000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCqusdCvTmXU",
        "outputId": "c3ec780b-96e0-4f36-d403-dedf1dc26ec1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Format x_test array\n",
        "x_test_norm = np.asarray([normalize(get_10s(i, SAMP_RATE)) for i in x_test_features])\n",
        "print(x_test_norm.shape)\n",
        "\n",
        "x_test_norm = x_test_norm[None, :,:]\n",
        "print(x_test_norm.shape)\n",
        "# print(type(x_test_norm))\n",
        "# print(type(x_test_norm[0]))\n",
        "# print(type(x_test_norm[0][0]))\n",
        "# Need to reshape  this array!"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 160000)\n",
            "(1, 2, 160000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZoarEYCH_51"
      },
      "source": [
        "# Format label arrays\n",
        "def gender_str_to_int(labels):\n",
        "  y_label = []\n",
        "  for name in labels:\n",
        "    idx = meta[meta.filename == name].index\n",
        "    gender = meta.loc[idx, 'sex'].values[0]\n",
        "    if gender == 'male':\n",
        "      y_label.append(1)\n",
        "    else: y_label.append(0)\n",
        "  return np.asarray(y_label)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0EAQRT-17hi",
        "outputId": "34148873-c44a-4c81-c135-783ec0496d2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train_label = gender_str_to_int(x_train)\n",
        "print(type(y_train_label))\n",
        "print(y_train_label.shape)\n",
        "\n",
        "# Convert to tensor shape for model input\n",
        "y_train_label = y_train_label[None, :]\n",
        "print(type(y_train_label))\n",
        "print(y_train_label.shape)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(3,)\n",
            "<class 'numpy.ndarray'>\n",
            "(1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w56obK0M2I8R",
        "outputId": "7bdbb617-739d-4291-c317-952f3e6e3299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test_label = gender_str_to_int(x_test)\n",
        "print(type(y_test_label))\n",
        "print(y_test_label.shape)\n",
        "\n",
        "# Convert to tensor shape for model input\n",
        "y_test_label = y_test_label[None, :]\n",
        "print(type(y_test_label))\n",
        "print(y_test_label.shape)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(2,)\n",
            "<class 'numpy.ndarray'>\n",
            "(1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuqNdJEs6iqK"
      },
      "source": [
        "# Load the pre-trained VGGish model from Tensorflow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o4kgOsG6pol"
      },
      "source": [
        "# Link to the model on TFHub\n",
        "hub_url = 'https://tfhub.dev/google/vggish/1'\n",
        "\n",
        "# Load the model as a Keras model\n",
        "vggish_model = hub.KerasLayer(hub_url)\n",
        "#vggish_model.summary()"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY0DWhij7fSF"
      },
      "source": [
        "## Run sample audio through the model and examine the embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV5_LmZG7YFD",
        "outputId": "7822cc0c-4835-41c8-bca6-f82488fcef9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(len(x_train_norm)):\n",
        "  vggish_embed = vggish_model(x_train_norm[0][i])\n",
        "  print(vggish_embed.shape, vggish_embed.dtype)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 128) <dtype: 'float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_syJHwc07xBt"
      },
      "source": [
        "# Embed the vggish model/embeddings into a binary gender classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq6I8CyR8fyM"
      },
      "source": [
        "#classifier = tf.keras.Sequential([\n",
        "#    hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))\n",
        "#])\n",
        "\n",
        "genderClf = tf.keras.models.Sequential([ #vggish_model,\n",
        "                              tf.keras.layers.Dense(128, activation = 'relu', input_shape = (3, 160000)),\n",
        "                              tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "                              tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "                              ])\n",
        "genderClf.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy'])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQzj_Td_GmbS"
      },
      "source": [
        "# Add early stopping to train classifier model\n",
        "# default is 10 epochs\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\n",
        "\n",
        "#genderClf.fit(x_train_norm[0], y_train_label[0], epochs=10) #, callbacks=[early_stopping_monitor]) #validation_split=0.25,"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFD-emztWrH_",
        "outputId": "7194abf1-55a7-450a-ac74-90f1fba95a83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "genderClf.fit(x_train_norm, y_train_label, epochs=10, callbacks=[early_stopping_monitor]) #validation_split=0.25,"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7088 - accuracy: 0.3333WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7088 - accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3908e-06 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3908e-06 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f69f7b3c668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U66xnpdmbOk",
        "outputId": "cd9d7a94-8021-4207-d9f2-0750b2cdb997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = genderClf.predict(x_test_norm) #, y_test_label)\n",
        "#y_pred = genderClf.predict(normalize(get_10s(spanish_raw, SAMP_RATE)), y_test_label)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 3, 160000) for input Tensor(\"dense_12_input:0\", shape=(None, 3, 160000), dtype=float32), but it was called on an input with incompatible shape (None, 2, 160000).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 3, 160000) for input Tensor(\"dense_12_input:0\", shape=(None, 3, 160000), dtype=float32), but it was called on an input with incompatible shape (None, 2, 160000).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS_twBdT7zkn",
        "outputId": "24083f8b-fe13-4f79-fe91-842c41e6aec9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y_pred)\n",
        "\n",
        "print(y_test_label)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.97188115]\n",
            "  [0.42228356]]]\n",
            "[[1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_6hlUyS8pdN",
        "outputId": "ff0f27e3-c1cf-4a31-e0fd-9c93e18e1ca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "genderClf.summary()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 3, 128)            20480128  \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 3, 64)             8256      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3, 1)              65        \n",
            "=================================================================\n",
            "Total params: 20,488,449\n",
            "Trainable params: 20,488,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3HdnaMMVqB3"
      },
      "source": [
        "## Confirm the types and shapes of the input vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYEAV2O4-vUT",
        "outputId": "8c9de4cf-d350-4068-8120-42a58d9aedd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(type(x_train_norm))\n",
        "print(x_train_norm.shape)\n",
        "\n",
        "print(type(y_train_label))\n",
        "print(y_train_label.shape)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(1, 3, 160000)\n",
            "<class 'numpy.ndarray'>\n",
            "(1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvV2gfTcqEJ-",
        "outputId": "a082044e-a284-4bb0-8436-d1eda457db34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_test_norm.shape)\n",
        "print(type(x_test_norm))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 2, 160000)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4SiUrhV-06C"
      },
      "source": [
        "for i in range(len(x_train_norm)):\n",
        "  print(type(x_train_norm[i]))\n",
        "  print(x_train_norm[i].shape)\n",
        "  print(type(x_train_norm[i][0]))\n",
        "  print(\"- - - - - - - - -\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLkHhbEl78Ug"
      },
      "source": [
        "# Next steps:\n",
        "Embed the vggish model into a trainable binary classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4WS8YRw7vtY"
      },
      "source": [
        "# enable fine-tuning with trainable argument\n",
        "#layer = hub.KerasLayer(..., trainable=True)\n",
        "\n",
        "# Reexport the fine-tuned model\n",
        "\n",
        "#loaded_obj = hub.load(\"https://tfhub.dev/...\")\n",
        "#hub_layer = hub.KerasLayer(loaded_obj, trainable=True, ...)\n",
        "\n",
        "#model = keras.Sequential([..., hub_layer, ...])\n",
        "#model.compile(...)\n",
        "#model.fit(...)\n",
        "\n",
        "#export_module_dir = os.path.join(os.getcwd(), \"finetuned_model_export\")\n",
        "#tf.saved_model.save(loaded_obj, export_module_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIcT-AjI-URx"
      },
      "source": [
        "Epoch - on complete pass through the dataset\n",
        "\n",
        "Batch size = divide dataset into smaller parts/sets\n",
        "\n",
        "Iterations - number of batches to complete one epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbVXZm8R_WmN"
      },
      "source": [
        "#model.fit(x, y, batch_size=n, epochs=n) # Batch size default is 32\n",
        "# Do not use batch size if the data is in the form of dataset, generators, or keras.utils.Sequence instances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkVMjj-9MZTB"
      },
      "source": [
        "# Import larger sample set\n",
        "- at least two batches, to see how model fits\n",
        "- a least one batch of testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_mWvJbANcaf"
      },
      "source": [
        "meta.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liE9qM3oMnhg"
      },
      "source": [
        "# Select 96 files at random from meta.filename\n",
        "data = random.choice(meta.filename, size=96, replace=False)\n",
        "\n",
        "idx = meta[meta.filename.isin(data)].index\n",
        "df = meta.loc[idx, ['filename', 'sex']]\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFOMQw3LNk_q"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df['filename'], df['sex'], random=38, test_size=0.33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx0kRPasN_EX"
      },
      "source": [
        "# Sample audio files\n",
        "def load_data(series):\n",
        "  output = []\n",
        "  for file in range(len(series)):\n",
        "    filepath = 'recordings/recordings/' + file + '.mp3'\n",
        "    soundfile, sr = librosa.load(filepath, sr=SAMP_RATE)\n",
        "    output.append(normalize(get_10s(soundfile)))\n",
        "  return np.asarray(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKFuMRgjSNGY"
      },
      "source": [
        "x_train = load_data(x_train)\n",
        "print(x_train.shape)\n",
        "print(type(x_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRXPTC36ST8e"
      },
      "source": [
        "x_test = load_data(x_test)\n",
        "print(x_test.shape)\n",
        "print(type(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eptv8L48Sv4h"
      },
      "source": [
        "# Format label arrays\n",
        "#def gender_int(labels):\n",
        "#  y_label = []\n",
        "#  for name in labels:\n",
        "#    idx = meta[meta.filename == name].index\n",
        "#    gender = meta.loc[idx, 'sex'].values[0]\n",
        "#    if gender == 'male':\n",
        "#      y_label.append(1)\n",
        "#    else: y_label.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZjwfKP-TIvQ"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCxYtGRzTXJx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}