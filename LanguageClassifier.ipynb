{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LanguageClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5EPwQ75UMELA",
        "hI22HC6vObfA",
        "x9qy1QSq9y04"
      ],
      "authorship_tag": "ABX9TyP1GukVMyuDpdakA3mhC5OA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kregier/AudioLanguageClassifer/blob/main/LanguageClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EPwQ75UMELA"
      },
      "source": [
        "# Introduction\n",
        "This classifier identifies the native language of the speaker from an English reading.\n",
        "\n",
        "Only the top 10 langauges (in addition to English) from the Speech Sample archive are included.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Remaining steps:\n",
        "\n",
        "Load the VGGish model.\n",
        "\n",
        "Create dataset generators to process the files in batches. The data generator runs the segments through the VGGish model and extract the feature embeddings, which are used as input to the classifier model. Also, will need to encode labels as one-hot vectors, and figure out how to load from various folders in the train, validation and test directories.\n",
        "\n",
        "The classifier will return the native langauge of the speaker, from a list of 10 (plus English)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFFe4-bHL-Vv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "291c4a97-4418-467c-f152-8f1a41c5332b"
      },
      "source": [
        "# Set up the environment\n",
        "!pip install soundfile\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from keras.layers import Dense, Input\n",
        "from keras.models import Sequential\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"All set up!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n",
            "All set up!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UhmzjUR-ZNe"
      },
      "source": [
        "#https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVpYignFM10w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1579256d-0d48-42f3-e081-634f0c5f9cb3"
      },
      "source": [
        "# Set up the data import using Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsQGgd1XM2jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e354b8c-9786-408a-f3d3-24658aeb7e21"
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "\n",
        "# Change working directory\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n",
            "augment     genderClf_3layer  models\t\t   recordings\n",
            "data\t    kaggle.json       processed.csv\t   speakers_all.csv\n",
            "genderClf1  model\t      reading-passage.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68jAGi9XM423",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5192c805-d04e-4bb1-9f8c-426e706e976c"
      },
      "source": [
        "# Import custom functions that I wrote\n",
        "import augment\n",
        "from augment import Augment\n",
        "\n",
        "from imp import reload"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Module imported\n",
            "Augment scripts reloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ith_yV0xM-yE"
      },
      "source": [
        "# Set constants\n",
        "SAMP_RATE = 16000  #Defined in augment package\n",
        "BATCH_SIZE = 32  #Defined in augment package\n",
        "CLF = 'lang10'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NPgaHp7NEHD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "66c9a9cf-af99-4cc7-d198-10c7ce2b3902"
      },
      "source": [
        "meta = pd.read_csv('processed.csv', index_col='speakerid')\n",
        "meta.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>age_onset</th>\n",
              "      <th>birthplace</th>\n",
              "      <th>filename</th>\n",
              "      <th>native_language</th>\n",
              "      <th>sex</th>\n",
              "      <th>country</th>\n",
              "      <th>file_missing?</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speakerid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>virginia, south africa</td>\n",
              "      <td>afrikaans1</td>\n",
              "      <td>afrikaans</td>\n",
              "      <td>female</td>\n",
              "      <td>south africa</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>pretoria, south africa</td>\n",
              "      <td>afrikaans2</td>\n",
              "      <td>afrikaans</td>\n",
              "      <td>male</td>\n",
              "      <td>south africa</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>diekabo, ivory coast</td>\n",
              "      <td>agni1</td>\n",
              "      <td>agni</td>\n",
              "      <td>male</td>\n",
              "      <td>ivory coast</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>prishtina, kosovo</td>\n",
              "      <td>albanian1</td>\n",
              "      <td>albanian</td>\n",
              "      <td>male</td>\n",
              "      <td>kosovo</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>33.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>tirana, albania</td>\n",
              "      <td>albanian2</td>\n",
              "      <td>albanian</td>\n",
              "      <td>male</td>\n",
              "      <td>albania</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            age  age_onset  ...       country file_missing?\n",
              "speakerid                   ...                            \n",
              "1          27.0        9.0  ...  south africa         False\n",
              "2          40.0        5.0  ...  south africa         False\n",
              "3          25.0       15.0  ...   ivory coast         False\n",
              "4          19.0        6.0  ...        kosovo         False\n",
              "5          33.0       15.0  ...       albania         False\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOPac1ePOQH5"
      },
      "source": [
        "## Extract native English speakers\n",
        "Downsample the number of speakers, but keep the some of the variation in the distribution of countries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD_SYToFNTMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b24a32-189e-4700-8af4-58fd44c983e6"
      },
      "source": [
        "# Create dataframe of only native English speakers\n",
        "english = meta.loc[meta.native_language == 'english']\n",
        "# Look at the counts of countries\n",
        "english.country.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "usa                     373\n",
              "uk                       65\n",
              "canada                   44\n",
              "australia                32\n",
              "ireland                  11\n",
              "new zealand               8\n",
              "jamaica                   5\n",
              "south africa              4\n",
              "singapore                 4\n",
              "panama                    3\n",
              "india                     3\n",
              "malaysia                  2\n",
              "philippines               2\n",
              "guyana                    2\n",
              "pakistan                  1\n",
              "united arab emirates      1\n",
              "fiji                      1\n",
              "italy                     1\n",
              "us virgin islands         1\n",
              "germany                   1\n",
              "antigua and barbuda       1\n",
              "barbados                  1\n",
              "bolivia                   1\n",
              "switzerland               1\n",
              "nigeria                   1\n",
              "trinidad                  1\n",
              "lebanon                   1\n",
              "the bahamas               1\n",
              "papua new guinea          1\n",
              "ghana                     1\n",
              "spain                     1\n",
              "belize                    1\n",
              "virginia                  1\n",
              "liberia                   1\n",
              "isle of man               1\n",
              "Name: country, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd2nzyawp2BQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "febaa3b3-c802-4b05-ddd7-fd34f54590fb"
      },
      "source": [
        "# Convert country counts to weights for use in the random sampling function\n",
        "eng_country_pct = english.country.value_counts(normalize=True)\n",
        "eng_country_pct"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "usa                     0.644214\n",
              "uk                      0.112263\n",
              "canada                  0.075993\n",
              "australia               0.055268\n",
              "ireland                 0.018998\n",
              "new zealand             0.013817\n",
              "jamaica                 0.008636\n",
              "south africa            0.006908\n",
              "singapore               0.006908\n",
              "panama                  0.005181\n",
              "india                   0.005181\n",
              "malaysia                0.003454\n",
              "philippines             0.003454\n",
              "guyana                  0.003454\n",
              "pakistan                0.001727\n",
              "united arab emirates    0.001727\n",
              "fiji                    0.001727\n",
              "italy                   0.001727\n",
              "us virgin islands       0.001727\n",
              "germany                 0.001727\n",
              "antigua and barbuda     0.001727\n",
              "barbados                0.001727\n",
              "bolivia                 0.001727\n",
              "switzerland             0.001727\n",
              "nigeria                 0.001727\n",
              "trinidad                0.001727\n",
              "lebanon                 0.001727\n",
              "the bahamas             0.001727\n",
              "papua new guinea        0.001727\n",
              "ghana                   0.001727\n",
              "spain                   0.001727\n",
              "belize                  0.001727\n",
              "virginia                0.001727\n",
              "liberia                 0.001727\n",
              "isle of man             0.001727\n",
              "Name: country, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6io_ot6lpVZc"
      },
      "source": [
        "english = english.join(eng_country_pct, how = 'left', on='country', rsuffix='_weight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7YEV_pAMTKA"
      },
      "source": [
        "# Calculate country weights for random sampling, put in 'country_pct' column\n",
        "english['country_pct'] = english['country_weight']/sum(english['country_weight'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yTt1BY0SzEr",
        "outputId": "6ea36e71-3efd-41e7-e3eb-18a221460839"
      },
      "source": [
        "#  Find random seed that will provide the highest number of country samples\n",
        "max_count = 0\n",
        "max_idx = 0\n",
        "for i in range(200):\n",
        "  eng_samp_inx = english.sample(100, replace=False, weights=english.country_pct, random_state=i)\n",
        "  count = eng_samp_inx.country.nunique()\n",
        "  if max_count  < count:\n",
        "    max_count = count\n",
        "    max_idx = i\n",
        "\n",
        "print(max_idx, max_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "DuuqtYWZPMEN",
        "outputId": "7f2f049f-7f65-4b37-f9bd-868079fa6957"
      },
      "source": [
        "eng_samples = english.sample(100, replace=False, weights=english.country_pct , random_state=max_idx)\n",
        "eng_samples.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>age_onset</th>\n",
              "      <th>birthplace</th>\n",
              "      <th>filename</th>\n",
              "      <th>native_language</th>\n",
              "      <th>sex</th>\n",
              "      <th>country</th>\n",
              "      <th>file_missing?</th>\n",
              "      <th>country_weight</th>\n",
              "      <th>country_pct</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speakerid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>586</th>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>new eagle, pennsylvania, usa</td>\n",
              "      <td>english181</td>\n",
              "      <td>english</td>\n",
              "      <td>male</td>\n",
              "      <td>usa</td>\n",
              "      <td>False</td>\n",
              "      <td>0.644214</td>\n",
              "      <td>0.002544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1120</th>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>memphis, tennessee, usa</td>\n",
              "      <td>english314</td>\n",
              "      <td>english</td>\n",
              "      <td>female</td>\n",
              "      <td>usa</td>\n",
              "      <td>False</td>\n",
              "      <td>0.644214</td>\n",
              "      <td>0.002544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1554</th>\n",
              "      <td>37.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>lancashire, leyland, uk</td>\n",
              "      <td>english456</td>\n",
              "      <td>english</td>\n",
              "      <td>female</td>\n",
              "      <td>uk</td>\n",
              "      <td>False</td>\n",
              "      <td>0.112263</td>\n",
              "      <td>0.000443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1640</th>\n",
              "      <td>30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>myrtle beach, south carolina, usa</td>\n",
              "      <td>english468</td>\n",
              "      <td>english</td>\n",
              "      <td>male</td>\n",
              "      <td>usa</td>\n",
              "      <td>False</td>\n",
              "      <td>0.644214</td>\n",
              "      <td>0.002544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1884</th>\n",
              "      <td>47.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>st. paul, minnesota, usa</td>\n",
              "      <td>english520</td>\n",
              "      <td>english</td>\n",
              "      <td>female</td>\n",
              "      <td>usa</td>\n",
              "      <td>False</td>\n",
              "      <td>0.644214</td>\n",
              "      <td>0.002544</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            age  age_onset  ... country_weight country_pct\n",
              "speakerid                   ...                           \n",
              "586        68.0        0.0  ...       0.644214    0.002544\n",
              "1120       26.0        0.0  ...       0.644214    0.002544\n",
              "1554       37.0        0.0  ...       0.112263    0.000443\n",
              "1640       30.0        0.0  ...       0.644214    0.002544\n",
              "1884       47.0        0.0  ...       0.644214    0.002544\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvKjebF4tOvo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "9ab71f6e-81e5-4b29-ef41-6370365874f9"
      },
      "source": [
        "sns.countplot(x='country', data=eng_samples)\n",
        "plt.title('English samples: Count by country')\n",
        "plt.xticks(rotation=45)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5]), <a list of 6 Text major ticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "IYI1GuZiWpGm",
        "outputId": "8e5a5102-1f9e-4e31-9699-e444d6b96a8c"
      },
      "source": [
        "# Check that gender is still roughly distributed equally\n",
        "sns.countplot(x='sex', data=eng_samples)\n",
        "plt.title('English samples: Count by country')\n",
        "plt.xticks(rotation=45)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), <a list of 2 Text major ticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs0VB7yMW40-"
      },
      "source": [
        "### Split English files into training, validation and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enLD__sWW4Zz"
      },
      "source": [
        "eng_data = eng_samples[['filename','sex']]\n",
        "x_train_names, x_test_names, y_train, y_test = train_test_split(\n",
        "    eng_data['filename'], eng_data['sex'], test_size=0.25, random_state=38)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4aHTk_1Yjgb"
      },
      "source": [
        "x_train_names, x_val_names, y_train, y_val = train_test_split(\n",
        "    x_train_names, y_train, test_size = 0.25, random_state=38)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AnSNG0oYWME",
        "outputId": "3563e18b-60f7-4b37-e5cb-9011e1fd708c"
      },
      "source": [
        "print(\"Number of training files: \", x_train_names.shape)\n",
        "print(\"Number of training files: \", x_val_names.shape)\n",
        "print(\"Number of testing files: \", x_test_names.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (56,)\n",
            "Number of training files:  (19,)\n",
            "Number of testing files:  (25,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNThCt60YcoK"
      },
      "source": [
        "### Process English audio files and store in appropriate files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x5hugQMZS1N"
      },
      "source": [
        "# Check if training data has been segmented. If not, segment each audio file.\n",
        "train_file_list = os.listdir('data/lang10/train/english')\n",
        "\n",
        "for i in range(len(x_train_names)):\n",
        "  # get a filename\n",
        "  filename = x_train_names.iloc[i]\n",
        "  # Check to see if the filename has already been segmented\n",
        "  # if any(file.startswith(filename) for file in os.listdir('data/gender/train')):\n",
        "  if any(file.startswith(filename) for file in train_file_list):\n",
        "    pass\n",
        "  else: \n",
        "    augment.Augment.segment_audio(x_train_names.iloc[i], y_train.iloc[i], split='train/english', clf=CLF)\n",
        "    print('{} segmented'.format(filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Ze_jvnZWmU"
      },
      "source": [
        "# Check if training data has been segmented. If not, segment each audio file.\n",
        "val_file_list = os.listdir('data/lang10/validation/english')\n",
        "\n",
        "for i in range(len(x_val_names)):\n",
        "  # get a filename\n",
        "  filename = x_val_names.iloc[i]\n",
        "  # Check to see if the filename has already been segmented\n",
        "  # if any(file.startswith(filename) for file in os.listdir('data/gender/train')):\n",
        "  if any(file.startswith(filename) for file in val_file_list):\n",
        "    pass\n",
        "  else: \n",
        "    augment.Augment.segment_audio(x_val_names.iloc[i], y_val.iloc[i], split='validation/english', clf=CLF)\n",
        "    print('{} segmented'.format(filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXX-UY-YZU-E"
      },
      "source": [
        "# Check if testing data has been segmented. If not, segment each audio file.\n",
        "test_file_list = os.listdir('data/lang10/test/test_data')\n",
        "for i in range(len(x_test_names)):\n",
        "  filename = x_test_names.iloc[i]\n",
        "  # if any(file.startswith(filename) for file in os.listdir('data/gender/test')):\n",
        "  if any(file.startswith(filename) for file in test_file_list):\n",
        "    pass\n",
        "  else: \n",
        "    augment.Augment.segment_audio(x_test_names.iloc[i], y_test.iloc[i], split='test/test_data', clf=CLF)\n",
        "    print('{} segmented'.format(filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI22HC6vObfA"
      },
      "source": [
        "## Get top 10 languages after English."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hb--a9pNLmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76fcbd14-abfc-4564-8bd5-d14586b04a00"
      },
      "source": [
        "lang_counts = meta.native_language.value_counts().head(11)\n",
        "lang_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "english       579\n",
              "spanish       162\n",
              "arabic        102\n",
              "mandarin       65\n",
              "french         63\n",
              "korean         52\n",
              "portuguese     48\n",
              "russian        48\n",
              "dutch          47\n",
              "turkish        37\n",
              "german         36\n",
              "Name: native_language, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNYZ3ePiNWJy"
      },
      "source": [
        "lang_list = ['spanish', 'arabic', 'mandarin', 'french', 'korean', 'russian', \n",
        "             'portuguese', 'dutch', 'turkish', 'german']\n",
        "top_lang = meta.loc[meta.native_language.isin(lang_list)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy2_rDwuObAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa6bb6d-1c6b-4273-bc4f-a3b25fdd99f3"
      },
      "source": [
        "top_lang.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>age_onset</th>\n",
              "      <th>birthplace</th>\n",
              "      <th>filename</th>\n",
              "      <th>native_language</th>\n",
              "      <th>sex</th>\n",
              "      <th>country</th>\n",
              "      <th>file_missing?</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speakerid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>38.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>riyadh, saudi arabia</td>\n",
              "      <td>arabic1</td>\n",
              "      <td>arabic</td>\n",
              "      <td>female</td>\n",
              "      <td>saudi arabia</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>26.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>cairo, egypt</td>\n",
              "      <td>arabic10</td>\n",
              "      <td>arabic</td>\n",
              "      <td>male</td>\n",
              "      <td>egypt</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>30.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>monastir, tunisia</td>\n",
              "      <td>arabic11</td>\n",
              "      <td>arabic</td>\n",
              "      <td>female</td>\n",
              "      <td>tunisia</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>32.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>baghdad, iraq</td>\n",
              "      <td>arabic12</td>\n",
              "      <td>arabic</td>\n",
              "      <td>male</td>\n",
              "      <td>iraq</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>zabbougha, lebanon</td>\n",
              "      <td>arabic13</td>\n",
              "      <td>arabic</td>\n",
              "      <td>male</td>\n",
              "      <td>lebanon</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            age  age_onset  ...       country file_missing?\n",
              "speakerid                   ...                            \n",
              "11         38.0       12.0  ...  saudi arabia         False\n",
              "12         26.0        5.0  ...         egypt         False\n",
              "13         30.0       14.0  ...       tunisia         False\n",
              "14         32.0       11.0  ...          iraq         False\n",
              "15         25.0       15.0  ...       lebanon         False\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng-DJHTocZvA"
      },
      "source": [
        "## Split the data by language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZkR8NZ6diAS",
        "outputId": "53c6f452-069e-4076-a815-7093ca97e214"
      },
      "source": [
        "# Split Spanish data\n",
        "spanish = meta.loc[meta.native_language == 'spanish']\n",
        "spanish_train_names, spanish_test_names, spanish_y_train, spanish_y_test = train_test_split(\n",
        "    spanish['filename'], spanish['sex'], test_size=0.25, random_state=38)\n",
        "spanish_train_names, spanish_val_names, spanish_y_train, spanish_y_val = train_test_split(\n",
        "    spanish_train_names, spanish_y_train, test_size = 0.25, random_state=38)\n",
        "print(\"Number of training files: \", spanish_train_names.shape)\n",
        "print(\"Number of training files: \", spanish_val_names.shape)\n",
        "print(\"Number of testing files: \", spanish_test_names.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (90,)\n",
            "Number of training files:  (31,)\n",
            "Number of testing files:  (41,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxlCbQ-2ech_",
        "outputId": "53afb9bd-0768-45e6-c25b-1db86624cc43"
      },
      "source": [
        "# Split Arabic data\n",
        "arabic = meta.loc[meta.native_language == 'arabic']\n",
        "arabic_train_names, arabic_test_names, arabic_y_train, arabic_y_test = train_test_split(\n",
        "    arabic['filename'], arabic['sex'], test_size=0.25, random_state=38)\n",
        "arabic_train_names, arabic_val_names, arabic_y_train, arabic_y_val = train_test_split(\n",
        "    arabic_train_names, arabic_y_train, test_size = 0.25, random_state=38)\n",
        "print(\"Number of training files: \", arabic_train_names.shape)\n",
        "print(\"Number of training files: \", arabic_val_names.shape)\n",
        "print(\"Number of testing files: \", arabic_test_names.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (57,)\n",
            "Number of training files:  (19,)\n",
            "Number of testing files:  (26,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2Jny9F8eY1M",
        "outputId": "1671f317-3f01-4d67-9d83-c3a5d7e2fed8"
      },
      "source": [
        "# Split Mandarin data\n",
        "mandarin = meta.loc[meta.native_language == 'mandarin']\n",
        "mandarin_train_names, mandarin_test_names, mandarin_y_train, mandarin_y_test = train_test_split(\n",
        "    mandarin['filename'], mandarin['sex'], test_size=0.25, random_state=38)\n",
        "mandarin_train_names, mandarin_val_names, mandarin_y_train, mandarin_y_val = train_test_split(\n",
        "    mandarin_train_names, mandarin_y_train, test_size = 0.25, random_state=38)\n",
        "print(\"Number of training files: \", mandarin_train_names.shape)\n",
        "print(\"Number of training files: \", mandarin_val_names.shape)\n",
        "print(\"Number of testing files: \", mandarin_test_names.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (36,)\n",
            "Number of training files:  (12,)\n",
            "Number of testing files:  (17,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMaifZkJeZnw",
        "outputId": "3cc82f00-04ba-44f3-9ea3-f0791141f4c8"
      },
      "source": [
        "# Split French data\n",
        "french = meta.loc[meta.native_language == 'french']\n",
        "french_train_names, french_test_names, french_y_train, french_y_test = train_test_split(\n",
        "    french['filename'], french['sex'], test_size=0.25, random_state=38)\n",
        "french_train_names, french_val_names, french_y_train, french_y_val = train_test_split(\n",
        "    french_train_names, french_y_train, test_size = 0.25, random_state=38)\n",
        "print(\"Number of training files: \", french_train_names.shape)\n",
        "print(\"Number of training files: \", french_val_names.shape)\n",
        "print(\"Number of testing files: \", french_test_names.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (35,)\n",
            "Number of training files:  (12,)\n",
            "Number of testing files:  (16,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj8PDCvveZXf",
        "outputId": "711b13a4-680c-4e6c-e5d2-34b727cd871a"
      },
      "source": [
        "# Split Korean data\n",
        "korean = meta.loc[meta.native_language == 'korean']\n",
        "korean_train_names, korean_test_names, korean_y_train, korean_y_test = train_test_split(\n",
        "    korean['filename'], korean['sex'], test_size=0.25, random_state=38)\n",
        "korean_train_names, korean_val_names, korean_y_train, korean_y_val = train_test_split(\n",
        "    korean_train_names, korean_y_train, test_size = 0.25, random_state=38)\n",
        "print(\"Number of training files: \", korean_train_names.shape)\n",
        "print(\"Number of training files: \", korean_val_names.shape)\n",
        "print(\"Number of testing files: \", korean_test_names.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (29,)\n",
            "Number of training files:  (10,)\n",
            "Number of testing files:  (13,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hojN42JEeYrW",
        "outputId": "bddf4690-bb52-423d-ad25-cbf54bb37ffb"
      },
      "source": [
        "# Split Russian data\n",
        "russian = meta.loc[meta.native_language == 'russian']\n",
        "russian_train_names, russian_test_names, russian_y_train, russian_y_test = train_test_split(\n",
        "    russian['filename'], russian['sex'], test_size=0.25, random_state=38)\n",
        "russian_train_names, russian_val_names, russian_y_train, russian_y_val = train_test_split(\n",
        "    russian_train_names, russian_y_train, test_size = 0.25, random_state=38)\n",
        "print(\"Number of training files: \", russian_train_names.shape)\n",
        "print(\"Number of training files: \", russian_val_names.shape)\n",
        "print(\"Number of testing files: \", russian_test_names.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (27,)\n",
            "Number of training files:  (9,)\n",
            "Number of testing files:  (12,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDIT5pGugrh4",
        "outputId": "960ef04b-40d4-46ed-bc90-0824314c20ca"
      },
      "source": [
        "# Split Portuguese data\n",
        "portuguese = meta.loc[meta.native_language == 'portuguese']\n",
        "portuguese_train_names, portuguese_test_names, portuguese_y_train, portuguese_y_test = train_test_split(\n",
        "    portuguese['filename'], portuguese['sex'], test_size=0.25, random_state=38)\n",
        "portuguese_train_names, portuguese_val_names, portuguese_y_train, portuguese_y_val = train_test_split(\n",
        "    portuguese_train_names, portuguese_y_train, test_size = 0.25, random_state=38)\n",
        "print(\"Number of training files: \", portuguese_train_names.shape)\n",
        "print(\"Number of training files: \", portuguese_val_names.shape)\n",
        "print(\"Number of testing files: \", portuguese_test_names.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (27,)\n",
            "Number of training files:  (9,)\n",
            "Number of testing files:  (12,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ghz1J3fhgsIV",
        "outputId": "1ed58b03-2d9d-46f2-a7f4-9917f07b06f9"
      },
      "source": [
        "# Split Dutch data\n",
        "dutch = meta.loc[meta.native_language == 'dutch']\n",
        "\n",
        "dutch_train_names, dutch_test_names, dutch_y_train, dutch_y_test = train_test_split(\n",
        "    dutch['filename'], dutch['sex'], test_size=0.25, random_state=38)\n",
        "dutch_train_names, dutch_val_names, dutch_y_train, dutch_y_val = train_test_split(\n",
        "    dutch_train_names, dutch_y_train, test_size = 0.25, random_state=38)\n",
        "print(\"Number of training files: \", dutch_train_names.shape)\n",
        "print(\"Number of training files: \", dutch_val_names.shape)\n",
        "print(\"Number of testing files: \", dutch_test_names.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (26,)\n",
            "Number of training files:  (9,)\n",
            "Number of testing files:  (12,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ8hTRengr9A",
        "outputId": "04f8f831-631e-44f8-ee9a-7191daa9cb1e"
      },
      "source": [
        "# Split Turkish data\n",
        "turkish = meta.loc[meta.native_language == 'turkish']\n",
        "turkish_train_names, turkish_test_names, turkish_y_train, turkish_y_test = train_test_split(\n",
        "    turkish['filename'], turkish['sex'], test_size=0.25, random_state=38)\n",
        "turkish_train_names, turkish_val_names, turkish_y_train, turkish_y_val = train_test_split(\n",
        "    turkish_train_names, turkish_y_train, test_size = 0.25, random_state=38)\n",
        "print(\"Number of training files: \", turkish_train_names.shape)\n",
        "print(\"Number of training files: \", turkish_val_names.shape)\n",
        "print(\"Number of testing files: \", turkish_test_names.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (20,)\n",
            "Number of training files:  (7,)\n",
            "Number of testing files:  (10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e8KsvLsgrYF",
        "outputId": "4dd7d194-5a5a-4424-cada-7f4bbd7dc6dd"
      },
      "source": [
        "# Split German data\n",
        "german = meta.loc[meta.native_language == 'german']\n",
        "german_train_names, german_test_names, german_y_train, german_y_test = train_test_split(\n",
        "    german['filename'], german['sex'], test_size=0.25, random_state=38)\n",
        "german_train_names, german_val_names, german_y_train, german_y_val = train_test_split(\n",
        "    german_train_names, german_y_train, test_size = 0.25, random_state=38)\n",
        "print(\"Number of training files: \", german_train_names.shape)\n",
        "print(\"Number of training files: \", german_val_names.shape)\n",
        "print(\"Number of testing files: \", german_test_names.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training files:  (20,)\n",
            "Number of training files:  (7,)\n",
            "Number of testing files:  (9,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U3rGHjTcKhV"
      },
      "source": [
        "train_list = [spanish_train_names, arabic_train_names, mandarin_train_names, french_train_names, korean_train_names, \n",
        "             russian_train_names, portuguese_train_names, dutch_train_names, turkish_train_names, german_train_names]\n",
        "\n",
        "y_train_list = [spanish_y_train, arabic_y_train, mandarin_y_train, french_y_train, korean_y_train, \n",
        "             russian_y_train, portuguese_y_train, dutch_y_train, turkish_y_train, german_y_train]\n",
        "\n",
        "for lang, train, y_train in zip(lang_list, train_list, y_train_list):\n",
        "  # Check if training data has been segmented. If not, segment each audio file.\n",
        "  train_file_list = os.listdir('data/lang10/train/{}'.format(lang))\n",
        "\n",
        "  for i in range(len(train)):\n",
        "    # get a filename\n",
        "    filename = train.iloc[i]\n",
        "    # Check to see if the filename has already been segmented\n",
        "    # if any(file.startswith(filename) for file in os.listdir('data/gender/train')):\n",
        "    if any(file.startswith(filename) for file in train_file_list):\n",
        "      pass\n",
        "    else: \n",
        "     augment.Augment.segment_audio(train.iloc[i], y_train.iloc[i], split='train/{}'.format(lang), clf=CLF)\n",
        "     #print('{} segmented'.format(filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORHNPFOouPCN"
      },
      "source": [
        "val_list = [spanish_val_names, arabic_val_names, mandarin_val_names, french_val_names, korean_val_names, \n",
        "             russian_val_names, portuguese_val_names, dutch_val_names, turkish_val_names, german_val_names]\n",
        "\n",
        "y_val_list = [spanish_y_val, arabic_y_val, mandarin_y_val, french_y_val, korean_y_val, \n",
        "             russian_y_val, portuguese_y_val, dutch_y_val, turkish_y_val, german_y_val]\n",
        "\n",
        "for lang, val, y_val in zip(lang_list, val_list, y_val_list):\n",
        "  # Check if training data has been segmented. If not, segment each audio file.\n",
        "  val_file_list = os.listdir('data/lang10/validation/{}'.format(lang))\n",
        "\n",
        "  for i in range(len(val)):\n",
        "    # get a filename\n",
        "    filename = val.iloc[i]\n",
        "    # Check to see if the filename has already been segmented\n",
        "    # if any(file.startswith(filename) for file in os.listdir('data/gender/train')):\n",
        "    if any(file.startswith(filename) for file in val_file_list):\n",
        "      pass\n",
        "    else: \n",
        "     augment.Augment.segment_audio(val.iloc[i], y_val.iloc[i], split='validation/{}'.format(lang), clf=CLF)\n",
        "     #print('{} segmented'.format(filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFhnr1JivNnw"
      },
      "source": [
        "test_list = [spanish_test_names, arabic_test_names, mandarin_test_names, french_test_names, korean_test_names, \n",
        "             russian_test_names, portuguese_test_names, dutch_test_names, turkish_test_names, german_test_names]\n",
        "\n",
        "y_test_list = [spanish_y_test, arabic_y_test, mandarin_y_test, french_y_test, korean_y_test, \n",
        "             russian_y_test, portuguese_y_test, dutch_y_test, turkish_y_test, german_y_test]\n",
        "\n",
        "for lang, test, y_test in zip(lang_list, test_list, y_test_list):\n",
        "  # Check if training data has been segmented. If not, segment each audio file.\n",
        "  test_file_list = os.listdir('data/lang10/test/test_data')\n",
        "\n",
        "  for i in range(len(test)):\n",
        "    # get a filename\n",
        "    filename = test.iloc[i]\n",
        "    # Check to see if the filename has already been segmented\n",
        "    # if any(file.startswith(filename) for file in os.listdir('data/gender/train')):\n",
        "    if any(file.startswith(filename) for file in test_file_list):\n",
        "      pass\n",
        "    else: \n",
        "     augment.Augment.segment_audio(test.iloc[i], y_test.iloc[i], split='test/test_data', clf=CLF)\n",
        "     #print('{} segmented'.format(filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p82Lnmswkt8"
      },
      "source": [
        "###  Add noise to test and validation files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stki08cxw4MK"
      },
      "source": [
        "# Generate a list training filenames + segment index to input to add_noise() function\n",
        "train_dict = {}\n",
        "val_dict = {}\n",
        "\n",
        "for lang in lang_list:\n",
        "  train_dict[lang] = [x.split('o.wav')[0] for x in os.listdir('data/lang10/train/{}'.format(lang)) if x.endswith('o.wav')]\n",
        "  val_dict[lang] = [x.split('o.wav')[0] for x in os.listdir('data/lang10/validation/{}'.format(lang)) if x.endswith('o.wav')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3U451X4wjig"
      },
      "source": [
        "# Check if training data has been augmented with noise. If not, add noise to each segment.\n",
        "for key, val in train_dict.items():\n",
        "  # print(type(val))\n",
        "  noise_train_list = os.listdir('data/lang10/train/{}'.format(key))\n",
        "  for i in range(len(val)):\n",
        "    filename = val[i]\n",
        "  \n",
        "    if any((file.startswith(filename)& file.endswith('n.wav')) for file in noise_train_list):\n",
        "      pass\n",
        "    else: \n",
        "      augment.Augment.noisy_data(val[i], split='train/{}'.format(key), clf=CLF)\n",
        "      #print('{} augmented'.format(filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLN5YlNuw4n0"
      },
      "source": [
        "# Check if validation data has been augmented with noise. If not, add noise to each segment.\n",
        "for key, val in val_dict.items():\n",
        "  noise_train_list = os.listdir('data/lang10/validation/{}'.format(key))\n",
        "  for i in range(len(val)):\n",
        "    filename = val[i]\n",
        "  \n",
        "    if any((file.startswith(filename)& file.endswith('n.wav')) for file in noise_train_list):\n",
        "      pass\n",
        "    else: \n",
        "      augment.Augment.noisy_data(val[i], split='validation/{}'.format(key), clf=CLF)\n",
        "      #print('{} augmented'.format(filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9qy1QSq9y04"
      },
      "source": [
        "## Load the VGGish model\n",
        "Needs to be instantiated before dataset generation can be done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohD0F3OS5tXy"
      },
      "source": [
        "# Using a SavedModel from the TFHub in Keras\n",
        "# https://www.tensorflow.org/hub/tf2_saved_model\n",
        "# VGGish model, from https://tfhub.dev/google/vggish/1\n",
        "\n",
        "# Link to the model on TFHub\n",
        "hub_url = 'https://tfhub.dev/google/vggish/1'\n",
        "\n",
        "# Load the model as a Keras model\n",
        "vggish_model = hub.KerasLayer(hub_url)\n",
        "vggish_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgyKmvU49sjv"
      },
      "source": [
        "# Works up to here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phDb5lqe9_HA"
      },
      "source": [
        "## Generate datasets\n",
        "Following the example from https://keras.io/examples/audio/speaker_recognition_using_cnn/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGXpQIKRCBEi",
        "outputId": "43e6c15e-cdda-4805-a3f5-28e68d121ffe"
      },
      "source": [
        "# Dataset generation from Keras.IO example\n",
        "# https://keras.io/examples/audio/speaker_recognition_using_cnn/\n",
        "\n",
        "from pathlib import Path\n",
        "# Get the list of audio file paths along with their corresponding labels\n",
        "DATASET_ROOT = \"data/lang10\"\n",
        "TRAIN_SUBFOLDER = \"train\"\n",
        "VAL_SUBFOLDER = \"validation\"\n",
        "TEST_SUBFOLDER = \"test/test_data\"\n",
        "\n",
        "DATASET_TRAIN_PATH = os.path.join(DATASET_ROOT, TRAIN_SUBFOLDER)\n",
        "DATASET_VAL_PATH = os.path.join(DATASET_ROOT, VAL_SUBFOLDER)\n",
        "DATASET_TEST_PATH = os.path.join(DATASET_ROOT, TEST_SUBFOLDER)\n",
        "\n",
        "SHUFFLE_SEED = 38\n",
        "SAMP_RATE = 16000\n",
        "\n",
        "class_names = os.listdir(DATASET_TRAIN_PATH)\n",
        "print(\"Our class names: {}\".format(class_names,))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our class names: ['spanish', 'arabic', 'mandarin', 'french', 'korean', 'russian', 'portuguese', 'dutch', 'turkish', 'german', 'english']\n",
            "Processing language spanish\n",
            "Processing language arabic\n",
            "Processing language mandarin\n",
            "Processing language french\n",
            "Processing language korean\n",
            "Processing language russian\n",
            "Processing language portuguese\n",
            "Processing language dutch\n",
            "Processing language turkish\n",
            "Processing language german\n",
            "Processing language english\n",
            "Found 1929 files belonging to 11 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc5m5KDor-A2"
      },
      "source": [
        "# Process training data\n",
        "train_paths = []\n",
        "train_labels = []\n",
        "for label, name in enumerate(class_names):\n",
        "    print(\"Processing language {}\".format(name,))\n",
        "    dir_path = Path(DATASET_TRAIN_PATH) / name\n",
        "    language_sample_paths = [\n",
        "        os.path.join(dir_path, filepath)\n",
        "        for filepath in os.listdir(dir_path)\n",
        "        if filepath.endswith(\".wav\")\n",
        "    ]\n",
        "    train_paths += language_sample_paths\n",
        "    train_labels += [label] * len(language_sample_paths)\n",
        "\n",
        "print(\n",
        "    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwii0YwLSX5T",
        "outputId": "9b8b332b-a4f0-4154-fa2f-33b8d2f2aeac"
      },
      "source": [
        "print(train_labels[:2*BATCH_SIZE])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78dym3_rDXaI",
        "outputId": "83c3334a-d616-42d6-f41d-a94c0ab1ff64"
      },
      "source": [
        "# Process validation data\n",
        "validation_paths = []\n",
        "val_labels = []\n",
        "for label, name in enumerate(class_names):\n",
        "    print(\"Processing language {}\".format(name,))\n",
        "    dir_path = Path(DATASET_VAL_PATH) / name\n",
        "    language_sample_paths = [\n",
        "        os.path.join(dir_path, filepath)\n",
        "        for filepath in os.listdir(dir_path)\n",
        "        if filepath.endswith(\".wav\")\n",
        "    ]\n",
        "    validation_paths += language_sample_paths\n",
        "    val_labels += [label] * len(language_sample_paths)\n",
        "\n",
        "print(\n",
        "    \"Found {} files belonging to {} classes.\".format(len(validation_paths), len(class_names))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing language spanish\n",
            "Processing language arabic\n",
            "Processing language mandarin\n",
            "Processing language french\n",
            "Processing language korean\n",
            "Processing language russian\n",
            "Processing language portuguese\n",
            "Processing language dutch\n",
            "Processing language turkish\n",
            "Processing language german\n",
            "Processing language english\n",
            "Found 652 files belonging to 11 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFWanBGxtiW8"
      },
      "source": [
        "# Process validation data\n",
        "testing_paths = []\n",
        "test_labels = []\n",
        "for label, name in enumerate(class_names):\n",
        "    print(\"Processing language {}\".format(name,))\n",
        "    dir_path = Path(DATASET_TEST_PATH) / name\n",
        "    language_sample_paths = [\n",
        "        os.path.join(dir_path, filepath)\n",
        "        for filepath in os.listdir(dir_path)\n",
        "        if filepath.endswith(\".wav\")\n",
        "    ]\n",
        "    testing_paths += language_sample_paths\n",
        "    test_labels += [label] * len(language_sample_paths)\n",
        "\n",
        "print(\n",
        "    \"Found {} files belonging to {} classes.\".format(len(testing_paths), len(class_names))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEO_EI3fD4m7"
      },
      "source": [
        "# Shuffle the order of the traning and validation datasets and labels\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(train_paths)\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(train_labels)\n",
        "\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(validation_paths)\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(val_labels)\n",
        "\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(testing_paths)\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj0DAd_vtdpV"
      },
      "source": [
        "train_onehot = tf.keras.backend.one_hot(train_labels, num_classes = len(class_names))\n",
        "val_onehot = tf.keras.backend.one_hot(val_labels, num_classes = len(class_names))\n",
        "test_onehot = tf.keras.backend.one_hot(test_labels, num_classes = len(class_names))\n",
        "\n",
        "print(type(train_onehot) )\n",
        "print(train_onehot.shape)\n",
        "print(train_onehot[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkpHUMnj6UU9",
        "outputId": "ac3f177c-2a1e-40ac-d870-fa69758486bc"
      },
      "source": [
        "# Print sizes of data splits\n",
        "print(\"Number of training samples: \", len(train_paths))\n",
        "print(\"Number of validation samples: \", len(validation_paths))\n",
        "testing_paths = os.listdir('data/lang10/test/test_data')\n",
        "print(\"Number of testing samples: \", len(testing_paths))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples:  1929\n",
            "Number of validation samples:  652\n",
            "Number of testing samples:  446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35YWIPqd7BCK",
        "outputId": "b0bdcd59-ab10-400c-b0cf-ef60be20cc64"
      },
      "source": [
        "# Calculate how many dataset batches to generate\n",
        "# May not be needed with this new generator. Still, I want to know how many steps per epoch\n",
        "train_steps = np.int(np.ceil(len(train_paths)/BATCH_SIZE))\n",
        "val_steps = np.int(np.ceil(len(validation_paths)/BATCH_SIZE))\n",
        "eval_steps = np.int(np.ceil(len(testing_paths)/BATCH_SIZE))\n",
        "\n",
        "print(\"training_steps_per_epoch = \", train_steps)\n",
        "print(\"validation_steps = \", val_steps)\n",
        "print(\"evaluation_steps = \", eval_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "steps_per_epoch =  61\n",
            "validation_steps =  21\n",
            "evaluation_steps =  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6C7mMUKtDwu"
      },
      "source": [
        "## Dataset generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Luq-GPtDeS"
      },
      "source": [
        "def tf_data_generator(file_list, label_list, batch_size=32):\n",
        "    \"\"\" Create a dataset generator. \n",
        "    Iterate through a list of filenames and process in batches.\n",
        "    Extract audio features from vggish model.\n",
        "    WARNING: This generator forms an infinite loop, \n",
        "    so you need to specify how long to run the generator \n",
        "    before fitting and evaluating a model.\n",
        "\n",
        "    Arguments:\n",
        "    file_list - list of filenames to iterate\n",
        "    vggish_model  - pass the instantiated model to the function\n",
        "    batch_size - how many files to process at a time\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    while True: #infinite loop\n",
        "        if i*batch_size >= len(file_list):\n",
        "            i=0\n",
        "            np.random.shuffle(file_list)\n",
        "        else:\n",
        "            file_chunk = file_list[i*batch_size:(i+1)*batch_size]\n",
        "            labels = label_list[i*batch_size:(i+1)*batch_size, :]\n",
        "            data = []\n",
        "\n",
        "            for file in file_chunk:\n",
        "                # Read data\n",
        "                audio, sr = librosa.load(file, sr=16000)\n",
        "                # Apply transformations\n",
        "                embed = vggish_model(audio)\n",
        "                data.append(embed)\n",
        "                # Extract labels from filename\n",
        "\n",
        "            data = np.asarray(data)\n",
        "            labels = np.asarray(labels)\n",
        "\n",
        "            yield data, labels\n",
        "            i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm1zl_dAuyFM"
      },
      "source": [
        "dataset_check = tf.data.Dataset.from_generator(tf_data_generator,\n",
        "                                         args = [train_paths[:2*BATCH_SIZE], train_onehot[:2*BATCH_SIZE], BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,11)) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4emugYzuu-Dc"
      },
      "source": [
        "# Check shape and size of dataset batches\n",
        "for data, labels in dataset_check.take(2):\n",
        "  print(data.shape)\n",
        "  print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuQam7y2vF1U"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [train_paths, labels_onehot, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,11)) ) \n",
        "validation_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [validation_paths, val_onehot, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,11)) )\n",
        "test_dataset = tf.data.Dataset.from_generator(tf_data_generator, \n",
        "                                         args = [test_paths, test_onehot, BATCH_SIZE],\n",
        "                                         output_types=(tf.float32, tf.float32),\n",
        "                                         output_shapes= ((None, 10, 128),(None,11)) ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g66DQhNW_YIn"
      },
      "source": [
        "# Build the model\n",
        "\n",
        "Going to start with a simple, two-layer model, but I expect I will need to try  more complicated architectures.\n",
        "\n",
        "Input - vggish embeddings\n",
        "Input shape = (None, 10, 128)\n",
        "\n",
        "Output - prediction for each class; use softmax, so they add up to 1 and scores are probabilities?\n",
        "Output shape (None, 10)\n",
        "\n",
        "Can use Keras in sklearn - see tutorial for details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgMTKhyK_XxF"
      },
      "source": [
        "from keras.layers import Input\n",
        "\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  #Input shape (None, 10, 128)\n",
        "  model.add(Input(shape=(1, 10, 128), batch_size=BATCH_SIZE )) \n",
        "  model.add(Dense(128, activation = 'relu' ) ) #, input_shape=(10, 128) ) )\n",
        "  model.add(Flatten()),\n",
        "  # Output\n",
        "  model.add(Dense(11, activation='softmax') )\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "lang_2dense = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFJRKtRoc-A5"
      },
      "source": [
        "Add checkpoint callback to model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn7K3T8bdCx8"
      },
      "source": [
        "ckpt_path = 'model/lang10/checkpoints/lang_2dense.ckpt'\n",
        "ckpt_dir = os.path.dirname(ckpt_path)\n",
        "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=ckpt_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyoJodP1_We0"
      },
      "source": [
        "# Add early stopping to train classifier model; default is 10 epochs\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_monitor = EarlyStopping(patience=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "sTbPBpD6_pn0",
        "outputId": "6183ec0b-ff1b-495a-ac5f-abb1088e3b16"
      },
      "source": [
        "# Fit the classifier\n",
        "if os.path.isdir('model/lang10/lang_2dense'):\n",
        "  lang_2dense = tf.keras.models.load_model('/model/lang10/lang_2dense')\n",
        "  hist_2df = pd.read_csv('model/lang10/lang_2dense.history.csv')\n",
        "else:\n",
        "  if os.path.isfile(ckpt_dir):\n",
        "    # Load model weights from the most recent checkpoint\n",
        "    latest = tf.train.latest_checkpoint(ckpt_dir)\n",
        "    genderClf_2layer.load_weights(latest)\n",
        "  hist_2dense = lang_2dense.fit(train_dataset, \n",
        "                        steps_per_epoch=train_steps, \n",
        "                        epochs=10, \n",
        "                        validation_data=validation_dataset, \n",
        "                        validation_steps = val_steps,\n",
        "                        callbacks=[early_stopping_monitor, ckpt], \n",
        "                        batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-3521e987b989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang_2layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearly_stopping_monitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:168 assert_input_compatibility\n        layer_name + ' is incompatible with the layer: '\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: its rank is undefined, but the layer requires a defined rank.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgzNVlNgAcQd"
      },
      "source": [
        "# Save the trained model and model history for use later\n",
        "lang_2dense.save('model/lang10/lang_2dense')\n",
        "\n",
        "hist_2dense_df = pd.DataFrame(hist_2dense.history) \n",
        "\n",
        "# save to csv: \n",
        "hist_csv_file = 'model/lang10/lang_2dense.history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_2dense_df.to_csv(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfsuMMaPAyfd",
        "outputId": "06af47e3-539e-448a-a068-35641dd6d041"
      },
      "source": [
        "lang_2dense.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (32, 1, 10, 128)          16512     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (32, 1, 10, 11)           1419      \n",
            "=================================================================\n",
            "Total params: 17,931\n",
            "Trainable params: 17,931\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdPE3eWEAwJG"
      },
      "source": [
        "# Model information after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXVj9KIaAkT4"
      },
      "source": [
        "lang_2dense.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o-Li_1MAzUW"
      },
      "source": [
        "plt.plot(hist_2dense_df.history['accuracy'])\n",
        "#plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qv6QlKFA5UM"
      },
      "source": [
        "plt.plot(hist_2dense_df.history['loss'])\n",
        "#plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP-Qhpm9BDlO"
      },
      "source": [
        "## Evaluate the trained classifier\n",
        "Based on the methods used fro the Gender classifier; probably need to be refined, but let's look for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns36EM_4BVB5"
      },
      "source": [
        "# Evaluate on validation set\n",
        "val_loss, val_acc = lang_2dense.evaluate(valid_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_79D7njByKs"
      },
      "source": [
        "# Evaluate on testing set\n",
        "test_loss, test_acc = lang_2dense.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgDWJX0DB02h"
      },
      "source": [
        "# Predict testing set\n",
        "y_pred = lang_2dense.predict(test_dataset)\n",
        "print(y_pred.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Wr_yHt0Kk6"
      },
      "source": [
        "# Probably need to reshape y_pred to format for classification report\n",
        "#y_pred = tf.squeeze(y_pred)\n",
        "#print(y_pred.shape)\n",
        "#print(y_pred[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67Zdnqm50TBY"
      },
      "source": [
        "# Get np.argmax from each prediction as label prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQGfQ-Mz-1eH"
      },
      "source": [
        "##  Format the data\n",
        "One-hot encode the labels (native language names)\n",
        "\n",
        "Use sklearn label encoder - LabelEncoder.\n",
        "\n",
        "Use Keras function to_categorical() for one-hot-encoding\n",
        "\n",
        "\n",
        "sklearn notes:\n",
        "- from sklearn import preprocesing\n",
        "- le = preprocessing.LabelEncoder()\n",
        "- le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
        "- << LabelEncoder()\n",
        "- list(le.classes_)\n",
        "- << ['amsterdam', 'paris', 'tokyo']\n",
        "- le.transform([\"tokyo\", \"tokyo\", \"paris\"])\n",
        "- << array([2, 2, 1]...)\n",
        "- list(le.inverse_transform([2, 2, 1]))\n",
        "- << ['tokyo', 'tokyo', 'paris']\n",
        "\n",
        "Methods =\n",
        "\n",
        "le.fit(y)\n",
        "\n",
        "le.fit_transform(y)\n",
        "\n",
        "le.inverse_transform(y)\n",
        "\n",
        "le.transform(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R01cb_L2-y44"
      },
      "source": [
        "# https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
        "\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcHsgwmOsdoI"
      },
      "source": [
        "# Generator code\n",
        "Can't get it working "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNZHEX5r_qjf"
      },
      "source": [
        "# https://keras.io/examples/audio/speaker_recognition_using_cnn/\n",
        "\n",
        "# Dataset generation from Keras.IO example\n",
        "\n",
        "# Dataset generation - Original functions\n",
        "def paths_and_labels_to_dataset(audio_paths, labels):\n",
        "    \"\"\"Constructs a dataset of audios and labels.\"\"\"\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    return tf.data.Dataset.zip((audio_ds, label_ds))\n",
        "\n",
        "def path_to_audio(path):\n",
        "    \"\"\"Reads and decodes an audio file.\"\"\"\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1, SAMP_RATE)\n",
        "    return audio\n",
        "\n",
        "# Modified functions, to include vggish model\n",
        "def vggish_and_labels_to_dataset(audio_paths, labels):\n",
        "    \"\"\"Constructs a dataset of audios and labels.\"\"\"\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "    audio_ds = path_ds.map(lambda x: tf_get_embed(x))\n",
        "    print(\"Element_spec: \", audio_ds.element_spec)\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    return tf.data.Dataset.zip((audio_ds, label_ds))\n",
        "\n",
        "def vggish_path_to_audio(path):\n",
        "    \"\"\"Reads and decodes an audio file.\"\"\"\n",
        "    file_path = path.numpy()\n",
        "    #print(\"file_path: \",bytes.decode(file_path)) #,type(bytes.decode(file_path))\n",
        "    audio, sr = librosa.load(file_path, sr=SAMP_RATE)\n",
        "    embed = vggish_model(audio)\n",
        "#    print(\"Embed: \", embed.shape)\n",
        "#    embed_tensor = tf.convert_to_tensor(embed, dtype=tf.float32, dtype_hint=None, name=None)\n",
        "#    print(\"Tensor: \", embed_tensor.shape, type(embed_tensor))\n",
        "    return embed\n",
        "\n",
        "def tf_get_embed(path):\n",
        "  embed_tensor = tf.py_function(vggish_path_to_audio, [path], [tf.float32])\n",
        "  print(\"Tensor 1: \",  type(embed_tensor), len(embed_tensor))\n",
        "#  print(embed_tensor.shape)\n",
        "  final_tensor = tf.convert_to_tensor(embed_tensor, dtype=tf.float32, dtype_hint=None, name=None)\n",
        "  print(\"Tensor 2: \",  type(final_tensor), final_tensor.shape)\n",
        "  return final_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6j69McTEcMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d304fe27-aacf-421b-c847-ff8aabb37eda"
      },
      "source": [
        "# Create dataset\n",
        "audio_train_ds = paths_and_labels_to_dataset(audio_paths, labels)\n",
        "audio_train_ds = audio_train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
        "    BATCH_SIZE\n",
        ")\n",
        "\n",
        "embed_train_ds = vggish_and_labels_to_dataset(audio_paths, labels)\n",
        "train_ds = embed_train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
        "    BATCH_SIZE\n",
        ")\n",
        "\n",
        "#valid_ds = paths_and_labels_to_dataset(validation_paths, val_labels)\n",
        "valid_ds = vggish_and_labels_to_dataset(validation_paths, val_labels)\n",
        "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=SHUFFLE_SEED).batch(32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor 1:  <class 'list'> 1\n",
            "Tensor 2:  <class 'tensorflow.python.framework.ops.Tensor'> <unknown>\n",
            "Element_spec:  TensorSpec(shape=<unknown>, dtype=tf.float32, name=None)\n",
            "Tensor 1:  <class 'list'> 1\n",
            "Tensor 2:  <class 'tensorflow.python.framework.ops.Tensor'> <unknown>\n",
            "Element_spec:  TensorSpec(shape=<unknown>, dtype=tf.float32, name=None)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}